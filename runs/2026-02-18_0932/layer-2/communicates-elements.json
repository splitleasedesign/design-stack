{
  "lens": {
    "host_call": "anthony-call.txt",
    "book_extract": "wisdomofcrowds-collective-intelligence.txt"
  },
  "elements": [
    {
      "id": "communicates-0932-001",
      "type": "info_architecture",
      "title": "SMS-First Information Hierarchy: Structure Platform Communications for One-Glance Consumption",
      "journey_phases": ["onboarding", "listing_creation", "proposal_mgmt", "active_lease"],
      "problem": "The platform's information architecture assumes hosts will read screens, navigate menus, and process multi-element layouts. Anthony will do none of this. His entire communication pattern is monosyllabic: 'Yes.' 'Okay.' '3000.' The platform's information hierarchy (headers, subheaders, body text, CTAs, secondary links) is designed for a scanning-then-reading user. Anthony is a glancing-then-deciding user whose maximum information intake is one sentence, one number, or one yes/no question. Surowiecki's experiment evidence shows that the most effective aggregation mechanisms match the participants' cognitive style: in the ox-weight contest, participants wrote a single number on a ticket. They did not fill out a form explaining their reasoning. The platform's information architecture must support ticket-stub-level simplicity for passive hosts, while retaining full depth for engaged hosts.",
      "solution": "Design a dual-layer information architecture: (1) The SMS layer presents every critical communication as a single sentence with a single required action. Proposal received: 'Ariel wants to stay Jun 1-Aug 30, $3,000/mo. Reply OK to accept or ? for details.' Listing incomplete: 'Your listing needs photos. Reply with photos or SKIP to list without.' Monthly check-in: 'How are things with your guests? Reply 1-5.' (2) The platform layer retains full information depth for hosts who want it. The SMS layer links to the platform layer but never requires it. (3) Every platform notification, email, and in-app message must have an SMS-equivalent format: one sentence, one action, one reply option. (4) The information hierarchy principle: the most important information comes first, the required action comes second, and everything else is optional depth.",
      "evidence": [
        {
          "source": "anthony-call.txt, entire transcript",
          "type": "host_call",
          "quote": "Anthony's responses across the entire 6-minute call: 'Yes.' 'Okay.' 'Got it.' '3000.' 'Two women. Okay.' 'No, no, no payment.' His maximum response length is ~9 words ('Yes, there's an offsite. There's a laundry bag.').",
          "insight": "Anthony's information processing bandwidth is approximately 5-10 words per interaction. Any communication that exceeds this will be ignored or delegated to the agent. The information architecture must fit within this bandwidth for passive hosts."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Introduction (Galton's ox)",
          "type": "book",
          "quote": "For sixpence, you could buy a stamped and numbered ticket, where you filled in your name, your address, and your estimate.",
          "insight": "Galton's aggregation mechanism was a ticket stub: name, address, one number. This is the information architecture gold standard for passive participants. The platform's SMS-layer communications should be structured like Galton's tickets: identify the host, state the context, capture one data point."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Ch 1 (Millionaire audience)",
          "type": "book",
          "quote": "Those random crowds of people picked the right answer 91 percent of the time... the audiences had nothing better to do than sit in a TV studio and press a button.",
          "insight": "The Millionaire audience's aggregation mechanism was a single button press -- A, B, C, or D. Despite the simplicity of the input, the crowd was right 91% of the time. For passive hosts, a single-tap SMS response (OK/NO, 1-5, Y/N) can capture meaningful data if the question is well-framed."
        }
      ],
      "priority": "high",
      "hierarchy_principle": "Primary: the one thing the host needs to know (status change, action required, amount). Secondary: the one thing the host needs to do (reply OK, send photos, confirm). Tertiary: the link to full details (optional, never required). Everything else is noise for the passive archetype.",
      "disclosure_pattern": "Immediate disclosure of the single critical fact via SMS. Progressive disclosure of details only if the host requests them (replies '?' or clicks a link). Never front-load detail -- front-load the decision point.",
      "cognitive_load_constraint": "Maximum 15 words per SMS notification. Maximum 1 decision per message. Maximum 1 action per message. If a communication requires more, split into sequential messages spaced 24 hours apart.",
      "scan_order": ["The number or status (e.g., '$3,000', 'New Proposal', 'Lease Complete')", "The action required (e.g., 'Reply OK', 'Send photos', 'Reply 1-5')", "The optional detail link (e.g., 'Details: split.lease/p/123')"],
      "exclude": ["Multi-paragraph explanations of platform features", "Navigation instructions ('Go to Dashboard > Listings > Edit')", "Legal disclaimers in the body of the SMS (link to them instead)", "Multiple CTAs in a single message"]
    },
    {
      "id": "communicates-0932-002",
      "type": "info_architecture",
      "title": "Pre-Populated Listing Review: Confirmation Architecture Over Creation Architecture",
      "journey_phases": ["onboarding", "listing_creation"],
      "problem": "The listing wizard's information architecture is creation-oriented: it presents empty fields and asks the host to fill them in across 6 steps (Space Snapshot, Features, Lease Styles, Pricing, Rules, Photos). For hosts like Anthony, who already conveyed all this data in a phone call, this architecture forces re-entry of known information. Surowiecki's submarine example shows that the best aggregate answer came from combining data that already existed in different people's heads -- Craven did not ask experts to generate new data, he asked them to confirm what they already knew. The listing wizard should work the same way for post-call hosts: present data already collected and ask for confirmation, not creation.",
      "solution": "Restructure the listing wizard's information architecture from creation mode to confirmation mode for hosts with prior agent contact. (1) The first screen the host sees shows a listing summary pre-filled from call data, formatted as a simple card: address, price, deposit, utilities status, parking, laundry, availability dates, and a prominent 'Photos needed' indicator. (2) Each data point has a simple 'Correct' / 'Edit' toggle -- not an open field. This reduces the cognitive load from 'What should I type here?' to 'Is this right?' (3) The confirmation flow is a single scrollable page, not a 6-step wizard. The wizard's step-by-step architecture is designed for creation; confirmation needs a scan-and-approve architecture. (4) Only fields with missing data (e.g., photos) are presented as action items. Everything else defaults to confirmed if the host takes no action within 48 hours.",
      "evidence": [
        {
          "source": "anthony-call.txt, 0:40-1:47",
          "type": "host_call",
          "quote": "Bryant systematically confirms: availability (June 1-Aug 30), price ($3,000), utilities (included), deposit ($3,000), laundry (offsite), parking (street + paid garage). Each confirmed by Anthony in 1-3 words.",
          "insight": "The call IS a confirmation flow -- Bryant states data, Anthony confirms. The platform's listing review should mirror this exact pattern: state pre-filled data, host confirms. The information architecture should replicate the call's structure, not replace it with a different one."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Introduction (Scorpion submarine)",
          "type": "book",
          "quote": "Instead of asking them to consult with each other to come up with an answer, he asked each of them to offer his best guess about how likely each of the scenarios was.",
          "insight": "Craven's method was confirmation-oriented: he presented scenarios and asked for likelihood ratings, not open-ended analysis. The listing confirmation flow should present pre-filled data and ask for correctness ratings (Correct/Edit), not open-ended input."
        },
        {
          "source": "split-lease-journey-map.md, Listing Wizard",
          "type": "usability",
          "quote": "The first section of the wizard asks the Host to describe the physical space. They fill out: Type of Space, Bedrooms, Kitchen Type, Parking, Bathrooms, Address.",
          "insight": "The wizard assumes the host is describing their space for the first time. For post-call hosts, this is redundant -- they already described it to the agent. The information architecture must detect 'already-described' hosts and switch to confirmation mode."
        }
      ],
      "priority": "high",
      "hierarchy_principle": "Primary: the pre-filled listing summary (one card, all key facts). Secondary: 'Correct/Edit' toggles on each data point. Tertiary: 'Photos needed' call-to-action. The host should see their listing as a finished product that needs approval, not a blank canvas that needs creation.",
      "disclosure_pattern": "All confirmed data shown in compact form on one screen. Edit interfaces revealed only on toggle. Photo upload prompted only after all other data is confirmed. The pattern is: show everything confirmed first, then show what's missing.",
      "cognitive_load_constraint": "Maximum 8 data points on the confirmation screen. Each data point: label + value + Correct/Edit toggle. No dropdowns, no multi-select, no text fields unless Edit is toggled. Total time to scan and confirm: under 60 seconds.",
      "scan_order": ["Listing summary card (address, price, availability -- the 'headline' of the listing)", "Amenity confirmations (utilities, parking, laundry -- 'Correct' pre-checked for data from call)", "Missing items indicator (photos needed, description optional)", "Submit/Confirm button"],
      "exclude": ["Empty form fields for data already collected in the call", "Step-by-step wizard navigation for post-call hosts", "Optional fields that create decision fatigue (e.g., 'Add a catchy description')", "Feature suggestions ('Load Common', 'Load Template') -- the call data is the template"]
    },
    {
      "id": "communicates-0932-003",
      "type": "info_architecture",
      "title": "Crowd Context Pricing Display: Show the Host Where They Stand in the Collective",
      "journey_phases": ["pricing", "listing_creation"],
      "problem": "Anthony set his price ($3,000/month) without any visible context about how it compares to the market. The platform has collective pricing data across all its listings but does not surface this data to hosts during pricing decisions. Surowiecki shows that individuals make better decisions when they have access to the crowd's aggregate judgment -- not as instruction, but as context. Currently, the pricing step of the listing wizard presents an empty field or a default value, with no crowd-sourced context. The host is pricing blind, which Surowiecki's framework identifies as a diversity problem: if each host prices without seeing the range, some will overprice and some will underprice, but the platform cannot help calibrate because it doesn't show its own data.",
      "solution": "Add a simple crowd-context display to the pricing interface that shows the host where their price sits relative to comparable listings. (1) Display format: a horizontal bar showing the price range for similar spaces in the same area, with the host's price marked on the bar. No numbers beyond the host's price and the range endpoints need to be shown. (2) A single sentence of context: 'Similar 2-bedroom spaces near W 80th St list for $2,600-$3,400/mo.' (3) No recommendation, no optimal price suggestion, no 'You should charge...' language. The crowd data is presented as fact, not advice. (4) For hosts who set prices via agent calls, the agent can verbally convey the same range. (5) The display appears only during price-setting and price-editing, not as a persistent dashboard widget.",
      "evidence": [
        {
          "source": "anthony-call.txt, 0:52-1:00",
          "type": "host_call",
          "quote": "It would be 3000 for the month... Is that right? Yes.",
          "insight": "Anthony's price was stated and confirmed without any calibration context. If Bryant had said 'That's right in the middle of what similar spaces charge,' it would have reinforced Anthony's confidence. If he had said 'That's a bit high -- most are around $2,500,' it would have prompted adjustment. The platform should provide this context automatically."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Introduction (crowd accuracy principle)",
          "type": "book",
          "quote": "If you ask a large enough group of diverse, independent people to make a prediction or estimate a probability, and then average those estimates, the errors each of them makes in coming up with an answer will cancel themselves out.",
          "insight": "The crowd average for pricing is likely more accurate than any individual host's price. Showing this average as context (not as instruction) allows hosts to benefit from collective intelligence while maintaining pricing independence."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Ch 1 (IEM prediction markets)",
          "type": "book",
          "quote": "The IEM's market price on the day each of those polls was released was more accurate three-fourths of the time... the traders are also adding information to what's in the polls.",
          "insight": "The IEM succeeds because it surfaces crowd judgment as a visible price signal. The platform's pricing display should work the same way: surface the crowd's collective pricing judgment as a visible signal that individual hosts can use to calibrate their own estimates."
        }
      ],
      "priority": "medium",
      "hierarchy_principle": "Primary: the host's price, prominently displayed. Secondary: the crowd range, shown as a subtle bar or range below the host's price. Tertiary: the area/comparability context ('Similar spaces near W 80th St'). The host's price is always dominant -- the crowd data is supporting context, never competing for attention.",
      "disclosure_pattern": "Crowd data visible immediately when the host enters or views the pricing field. No click required to see it. Detailed breakdowns (by bedroom count, by season, by lease length) available on expansion but never required.",
      "cognitive_load_constraint": "Maximum 3 numbers visible at once: the host's price and the range endpoints. Maximum 1 sentence of context. No charts, no tables, no percentage comparisons.",
      "scan_order": ["Host's price (large, centered)", "Crowd range bar (positioned below the price, showing where the host's price falls)", "Context sentence (small text below the bar)"],
      "exclude": ["Specific competitor listing prices", "Price optimization recommendations ('You could earn 12% more by lowering your price')", "Historical price trend data (too complex for the pricing moment)", "Dynamic pricing suggestions (undermines host autonomy and independence)"]
    },
    {
      "id": "communicates-0932-004",
      "type": "info_architecture",
      "title": "Agent Dashboard: Make Passive Host Signals Visible to Agents as Aggregated Intelligence",
      "journey_phases": ["onboarding", "listing_creation", "proposal_mgmt", "active_lease", "retention"],
      "problem": "Agents like Bryant manage multiple hosts, some passive (Anthony), some active. Currently, the platform provides no aggregated view of host engagement levels, listing completeness, or passive host risks. The agent must remember which hosts need follow-up, which listings lack photos, and which proposals await passive host confirmation. Surowiecki's framework identifies this as a failed aggregation problem: the agent has fragmented data across individual host interactions, but no mechanism to see the collective picture. Craven succeeded because he aggregated individual data points into a composite picture. The agent needs a composite picture of their host portfolio.",
      "solution": "Build an agent-facing dashboard that aggregates host signals into a collective intelligence view. (1) Host Engagement Spectrum: a visual indicator showing each host's engagement level (Active/Moderate/Passive/Silent) based on platform login frequency, message response time, and listing completeness. Anthony would show as 'Silent' with 0 platform logins. (2) Action Queue: a prioritized list of tasks the agent needs to handle for passive hosts, auto-generated from platform data: 'Anthony - photos needed (3 days overdue)', 'Anthony - proposal awaiting response (sent 48h ago, no reply)'. (3) Listing Completeness Scores: aggregate view of all managed listings with missing-data flags. (4) Crowd Comparison: how the agent's portfolio of hosts compares to platform averages on listing quality, fill rate, and response time. This is collective intelligence applied to agent workflow: the dashboard aggregates many hosts' data into a single actionable view.",
      "evidence": [
        {
          "source": "anthony-call.txt, 3:48-4:02 and 4:58",
          "type": "host_call",
          "quote": "Bryant: 'I see that there isn't any pictures here.' Later: Anthony will text photos instead of uploading. Bryant must now track this manually -- remember to follow up on photo receipt, then manually upload them.",
          "insight": "Without an agent dashboard, Bryant must mentally track Anthony's incomplete listing alongside all other hosts' tasks. This is a classic failure of aggregation: the data (listing incomplete, photos pending via SMS) exists but is not surfaced in any systematic way."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Introduction (Craven's Bayesian aggregation)",
          "type": "book",
          "quote": "Craven took all the guesses, and used a formula called Bayes's theorem to estimate the Scorpion's final location... The final estimate was a genuinely collective judgment that the group as a whole had made.",
          "insight": "Craven's dashboard was Bayes's theorem -- a mechanism for combining individual data points into a composite picture. The agent dashboard is the equivalent: it takes individual host signals (engagement level, listing completeness, response patterns) and combines them into a composite view of the agent's portfolio health."
        }
      ],
      "priority": "medium",
      "hierarchy_principle": "Primary: hosts requiring immediate action (overdue tasks, unanswered proposals, incomplete listings). Secondary: host engagement levels (sorted by risk, with 'Silent' hosts flagged). Tertiary: portfolio-level metrics (fill rates, completion rates, average response times).",
      "disclosure_pattern": "Action items surfaced immediately on dashboard load. Engagement details available on per-host drill-down. Portfolio metrics available as a summary bar, expandable for detail.",
      "cognitive_load_constraint": "Maximum 5 action items visible without scrolling. Each action item: host name + task description + days overdue. No more than 3 metrics in the portfolio summary bar.",
      "scan_order": ["Action queue (what needs doing now)", "Host engagement spectrum (who is at risk)", "Portfolio health metrics (how am I doing overall)"],
      "exclude": ["Individual host communication logs (too granular for dashboard level)", "Platform-wide metrics that don't relate to the agent's specific portfolio", "Historical data older than 30 days (focus on current state and near-term actions)", "Host comparison rankings (agents should not be gamified against each other)"]
    },
    {
      "id": "communicates-0932-005",
      "type": "info_architecture",
      "title": "Silence Interpretation Framework: Distinguish Satisfied Silence from Disengaged Silence",
      "journey_phases": ["active_lease", "retention"],
      "problem": "Anthony's silence throughout the call -- and predicted silence during active lease and retention -- is ambiguous. It could mean satisfaction ('everything is fine, I don't need anything') or disengagement ('I don't care about this platform and will leave at first opportunity'). The platform currently has no mechanism to distinguish between these two states. Surowiecki notes that crowd wisdom depends on every participant contributing their signal. When a participant is silent, their signal is missing -- and missing data is not the same as negative data or positive data. The platform's retention and satisfaction models will misinterpret silence if they treat 'no engagement' as a single category rather than distinguishing between satisfied passivity and disengaged passivity.",
      "solution": "Implement a minimal Silence Interpretation Framework that categorizes host silence into actionable types using minimal-touch data collection. (1) After each lease milestone (first month, mid-lease, lease end), send a single SMS: 'Everything going well with your guests? Reply YES or NO.' This one-bit signal distinguishes satisfied silence (YES) from troubled silence (NO) without requiring engagement. (2) If no response after 48 hours, send one follow-up: 'We haven't heard from you. Reply GOOD if all is well.' (3) If still no response, categorize as 'Ambiguous Silence' -- a distinct state from 'Satisfied' or 'Dissatisfied' in the retention model. (4) Track the response pattern over time: a host who always replies YES but never engages further is 'Satisfied-Passive.' A host who never replies at all is 'Unknown' and should receive higher-touch agent outreach. (5) Feed these silence categories into retention predictions: 'Satisfied-Passive' hosts have a different churn probability than 'Unknown' hosts.",
      "evidence": [
        {
          "source": "anthony-call.txt, KEY BEHAVIORAL OBSERVATIONS",
          "type": "host_call",
          "quote": "Flat emotional affect throughout. Passive engagement - no relationship building.",
          "insight": "Anthony's silence is not hostility -- it's his natural communication mode. But the platform cannot tell whether his future silence during active lease means 'I'm happy' or 'I've mentally checked out.' Without a mechanism to distinguish, the platform treats both states identically, leading to either over-intervention (annoying satisfied hosts) or under-intervention (losing disengaged hosts)."
        },
        {
          "source": "wisdomofcrowds-collective-intelligence.txt, Introduction (aggregation requirement)",
          "type": "book",
          "quote": "If you ask a large enough group of diverse, independent people to make a prediction... the errors each of them makes will cancel themselves out. Each person's guess has two components: information and error. Subtract the error, and you're left with the information.",
          "insight": "Silence contains zero information for the crowd model -- it's pure missing data, not even error. The platform needs to convert silence into at least one bit of information (satisfied/not-satisfied) to include passive hosts in its collective intelligence about host experience."
        }
      ],
      "priority": "medium",
      "hierarchy_principle": "Primary: the one question the host must answer ('Everything going well?'). Secondary: the response options (YES/NO -- nothing more). Tertiary: the follow-up if no response ('Reply GOOD if all is well'). No additional information, no context, no links.",
      "disclosure_pattern": "One question per milestone. No additional information unless the host requests it. The question is the entire communication. Responses feed the model silently -- the host never sees the categorization or the retention analysis.",
      "cognitive_load_constraint": "Maximum 8 words per SMS question. Maximum 2 response options (YES/NO or GOOD/HELP). Maximum 3 milestone check-ins per lease (first month, mid-lease, end-of-lease).",
      "scan_order": ["The question (first and only line of SMS)", "The response instruction (implicitly clear: reply YES or NO)"],
      "exclude": ["Satisfaction surveys with more than 2 options", "Open-ended feedback requests ('Tell us how things are going')", "Links to platform-based survey forms", "Any communication that requires more than 5 seconds to read and respond to"]
    }
  ]
}