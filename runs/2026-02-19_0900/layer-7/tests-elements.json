{
  "lens": {
    "host_call": "mahesh-call.txt",
    "book_extract": "coldstart-tipping-point.txt"
  },
  "tests": [
    {
      "id": "tests-0900-001",
      "element_id": "works-001",
      "element_title": "Absorb the Hard Side's Risk Completely Before Asking for Commitment",
      "layer": 1,
      "validation_type": "usability_test",
      "method": "Moderated task-based usability test with 6-8 host prospects who match Mahesh's profile (property owners with management companies, considering multiple platforms). Show a prototype of the evaluation-to-proposal flow where the guarantee appears proactively before any commitment request. Measure: (a) whether participants ask about payment guarantees unprompted, (b) time to first commitment action (proceed to proposal), (c) qualitative: do they mention feeling 'safe' or 'protected' before being asked?",
      "success_criteria": "Fewer than 20% of participants ask about payment guarantees during the task (the platform answered the question before they needed to ask). Mean time to first commitment action is under 90 seconds from screen load. At least 5 of 8 participants use language related to safety or protection in the think-aloud without prompting.",
      "risk_if_skipped": "The platform continues to surface guarantees reactively, requiring agent intervention for guarantee-related questions. Hard-side conversion stalls because hosts cannot find the differentiating information (risk absorption) before their attention shifts to the competitor.",
      "priority": "high"
    },
    {
      "id": "tests-0900-002",
      "element_id": "works-002",
      "element_title": "Design for the Institutional Gatekeeper as a First-Class Network Participant",
      "layer": 1,
      "validation_type": "workflow_validation",
      "method": "Conduct a structured walkthrough with 4-6 hosts who have management companies or HOAs. Present the end-to-end gatekeeper workflow: (1) flag management company at onboarding, (2) generate the Management Company Package from the proposal screen, (3) track approval status as a visible pipeline stage. Have participants attempt to share the generated package with a simulated management company contact. Measure: (a) task completion rate, (b) whether the exported document matches what their specific management company would accept, (c) qualitative: does the host feel the platform is handling the management company burden?",
      "success_criteria": "Task completion rate above 85% (host successfully generates and would share the package). At least 4 of 6 participants confirm the document format is recognizable as a standard rental application. Zero participants express the feeling of needing to 'figure out' the management company bridge themselves (Mahesh's exact phrase at 09:34).",
      "risk_if_skipped": "Management-company-gated hosts cannot convert, blocking an entire segment of the hard side. Each management company left unapproached is a missed domino that could have unlocked adjacent networks.",
      "priority": "high"
    },
    {
      "id": "tests-0900-003",
      "element_id": "works-003",
      "element_title": "Surface the Ghost Roommate Economic Upside Without Hiding the Operational Complexity",
      "layer": 1,
      "validation_type": "concept_test",
      "method": "A/B concept test with 12-16 host prospects, randomly assigned to two conditions. Condition A: ghost roommate presented as a single all-at-once disclosure (economics + operations + opt-in terms in one view). Condition B: ghost roommate presented using the three-stage progressive model (evaluation whisper, match preview, active operations). After exposure, measure: (a) willingness to opt-in (1-7 scale), (b) anxiety level about managing two guests (1-7 scale), (c) comprehension of the opt-out mechanism, (d) qualitative: does the host feel the platform was transparent about complexity?",
      "success_criteria": "Condition B (progressive) produces at least 1.5 points higher willingness to opt-in than Condition A (all-at-once) on the 7-point scale. Condition B produces at least 1.0 points lower anxiety. At least 80% of Condition B participants can correctly describe the opt-out mechanism. No participant in Condition B uses the word 'complicated' or synonyms in the qualitative debrief (Mahesh's anxiety trigger at 08:31).",
      "risk_if_skipped": "Ghost roommate adoption remains low because hosts are overwhelmed by upfront complexity disclosure, or ghost roommate churn is high because hosts feel misled when operational complexity surfaces after the economic pitch.",
      "priority": "high"
    },
    {
      "id": "tests-0900-004",
      "element_id": "works-004",
      "element_title": "Define and Instrument the Three-Month Atomic Network Stability Threshold",
      "layer": 1,
      "validation_type": "data_analysis",
      "method": "Retrospective cohort analysis of all completed 3-month initial leases. Segment hosts into two groups: (a) those who extended beyond 3 months, (b) those who did not extend. Compare engagement signals during the 3-month period: dashboard login frequency, payment on-time rate, agent contact frequency, date change requests, and any disputes filed. Identify which combination of signals at week 8 predicts the renewal decision with the highest accuracy.",
      "success_criteria": "Identify a set of engagement signals that predicts lease extension with at least 80% accuracy at week 8 (4 weeks before the renewal decision). Confirm that hosts who pass the stability threshold (defined by the signal set) extend at a rate above 70%. If insufficient historical data exists, define the measurement framework and instrument the signals for prospective tracking.",
      "risk_if_skipped": "The platform cannot identify at-risk leases before the renewal decision, losing hosts who could have been retained with proactive intervention. The stability threshold remains undefined, preventing data-driven retention strategy.",
      "priority": "high"
    },
    {
      "id": "tests-0900-005",
      "element_id": "works-005",
      "element_title": "Scale Agent-Mediated Trust by Encoding It Into Platform Artifacts",
      "layer": 1,
      "validation_type": "usability_test",
      "method": "Moderated first-visit simulation with 6-8 host prospects who have completed a simulated agent call (recorded script matching Bryant's information density). Half the participants see the personalized handoff screen (agent note, pre-populated data, guest profile, guarantee summary). Half see a standard onboarding wizard (empty form fields, generic welcome, multi-step setup). Measure: (a) time to first platform action (view proposal vs. complete form), (b) number of questions directed to the agent after the platform visit, (c) qualitative: does the host describe the platform as an extension of the agent conversation or as a separate experience?",
      "success_criteria": "Handoff screen group completes first platform action in under 60 seconds; wizard group takes over 3 minutes. Handoff group generates 40% fewer post-visit agent questions. At least 5 of 8 handoff group participants describe the platform as 'continuing the conversation' or use language indicating continuity.",
      "risk_if_skipped": "Agent capacity remains the bottleneck for host acquisition. Every new host requires a personal call AND follow-up clarification because the platform does not carry the call's trust forward. The tipping point speed is limited by Bryant's calendar.",
      "priority": "high"
    },
    {
      "id": "tests-0900-006",
      "element_id": "works-006",
      "element_title": "Use the First Successful Lease to Tip Adjacent Networks Within the Same Building or Management Company",
      "layer": 1,
      "validation_type": "metric_tracking",
      "method": "Instrument the adjacent network conversion funnel: (1) for each management company that approves the first Split Lease host, track how many additional hosts under the same management company inquire within 6 months, (2) track whether the second host's conversion time is materially shorter than the first's, (3) track referral prompt engagement rate at the 3-month milestone. Compare conversion rates for hosts under management companies with a prior Split Lease approval vs. hosts under management companies with no prior approval.",
      "success_criteria": "At least 1 additional host converts within 6 months per management company that approves the first host. The second host's time from inquiry to listing is at least 30% shorter than the first host's. Referral prompt engagement rate (tap 'Share Split Lease') above 25% among hosts who reach the 3-month milestone with positive Lease Health scores.",
      "risk_if_skipped": "Each management company approval is a one-time event that does not propagate. The domino effect described in Cold Start Theory fails to materialize because the platform does not store or leverage the approval pathway. Adjacent networks remain cold.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-007",
      "element_id": "communicates-001",
      "element_title": "Risk-Absorption-First Information Hierarchy",
      "layer": 2,
      "validation_type": "eye_tracking",
      "method": "Eye-tracking study with 8-10 host prospects viewing three critical screens: (1) proposal card, (2) pricing confirmation, (3) active lease dashboard. For each screen, compare two layouts: Layout A places guest details first and guarantee below; Layout B places guarantee at the top (risk-absorption-first hierarchy). Track: (a) first fixation point on each screen, (b) time to first fixation on guarantee information, (c) total dwell time on guarantee vs. guest details, (d) scan path sequence.",
      "success_criteria": "In Layout B, at least 80% of participants' first fixation lands on the guarantee area. Time to first fixation on guarantee information is under 500ms (within the first visual intake). Dwell time on guarantee information is at least 1.5x longer in Layout B than Layout A, indicating the hierarchy actually captures and holds attention.",
      "risk_if_skipped": "The IA places guarantees in the wrong scan position. Hosts scroll past the differentiating information, the gating question ('am I safe?') goes unanswered, and the hard side defaults to the competitor where they already feel safe.",
      "priority": "high"
    },
    {
      "id": "tests-0900-008",
      "element_id": "communicates-002",
      "element_title": "Gatekeeper-Ready Information Export Layer",
      "layer": 2,
      "validation_type": "content_validation",
      "method": "Present the generated Management Company Package (PDF/link) to 5-7 property management professionals (not Split Lease hosts, but actual management company employees). Ask them to evaluate: (a) whether the document contains the information they would need to process a guest application, (b) whether the format matches what they typically receive, (c) whether Split Lease's guarantee terms are clear in their role as co-signer/guarantor, (d) what additional information, if any, they would require.",
      "success_criteria": "At least 4 of 7 management professionals confirm the document contains all required fields for their approval process. At least 5 of 7 confirm the format is immediately recognizable as a standard application. Zero professionals need to contact the host for additional information that should have been in the document. Any missing fields identified by more than 2 professionals are added to the template.",
      "risk_if_skipped": "The export document is designed from the platform's perspective rather than the management company's perspective. Hosts share it and receive requests for additional information, forcing them back into the intermediary role the pattern was designed to eliminate.",
      "priority": "high"
    },
    {
      "id": "tests-0900-009",
      "element_id": "communicates-003",
      "element_title": "Layered Novelty Disclosure for Ghost Roommate Concept",
      "layer": 2,
      "validation_type": "comprehension_test",
      "method": "Sequential comprehension test with 8-10 host prospects. Walk participants through the three disclosure layers in order: Layer 1 (evaluation: single-line economic teaser), Layer 2 (match found: full preview card with schedule, cleaning, income), Layer 3 (active: operational dashboard with tabs). After each layer, ask comprehension questions specific to that layer. Measure: (a) correct understanding of concept at each layer, (b) emotional valence (positive/negative/neutral) after each layer, (c) whether the participant feels they received the right amount of information at each stage.",
      "success_criteria": "Comprehension accuracy above 90% at each layer for the information presented at that layer. Emotional valence remains neutral or positive after Layer 1, and does not drop below neutral after Layer 2 (where operational detail is introduced). At least 80% of participants rate the information quantity as 'about right' at each layer (not 'too much' and not 'not enough'). No participant requests operational detail at Layer 1 (premature) or economic rationale at Layer 3 (too late).",
      "risk_if_skipped": "The three-layer model is deployed without validating that each layer is self-contained and appropriately paced. Some layers may overload while others under-inform, creating the same anxiety the model was designed to prevent.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-010",
      "element_id": "communicates-004",
      "element_title": "Agent-to-Platform Trust Transfer Architecture",
      "layer": 2,
      "validation_type": "usability_test",
      "method": "First-visit recall test with 6-8 host prospects who listen to a 5-minute excerpt of the Mahesh call (simulating their own agent conversation). After a 30-minute delay, they visit the platform prototype. Group A sees the personalized handoff screen (agent note, pre-populated data, guest profile). Group B sees a standard welcome screen. After viewing, participants are asked: 'What do you remember from your phone call that you can now see on the platform?' Measure: (a) number of call data points correctly identified on the platform, (b) trust rating of the platform (1-7), (c) willingness to proceed to the proposal (yes/no/need more info).",
      "success_criteria": "Group A correctly identifies at least 4 of 5 call data points on the platform (property details, guest name, vetting status, guarantee, agent name). Group A's mean trust rating is at least 2.0 points higher than Group B. At least 6 of 8 Group A participants proceed to the proposal without requesting additional information.",
      "risk_if_skipped": "The handoff screen is built without validating that it actually creates the trust transfer it is designed for. The host arrives, sees the handoff, but does not recognize it as a continuation of the call because the information does not match their recall.",
      "priority": "high"
    },
    {
      "id": "tests-0900-011",
      "element_id": "communicates-005",
      "element_title": "Cumulative Evidence Dashboard for Stability Threshold",
      "layer": 2,
      "validation_type": "prototype_test",
      "method": "Show 8-10 hosts (or host prospects) a simulated 'Lease Health' dashboard at three time points: week 4 (month 1), week 8 (month 2), and week 12 (month 3). At each point, present the cumulative KPIs (income, on-time rate, incidents) and the progress bar. After each time point, ask: 'Based on what you see, would you extend this lease?' Also ask: 'Is this information sufficient for your decision, or do you need something else?' Measure: (a) extension willingness at each time point, (b) information sufficiency rating, (c) which KPIs the host references when explaining their decision.",
      "success_criteria": "Extension willingness increases monotonically across the three time points (week 4 < week 8 < week 12), demonstrating that cumulative evidence builds conviction. At least 70% of participants at week 12 say they would extend. Information sufficiency rating is above 4.0/5.0 at week 12. The most frequently referenced KPI is total income received (validating the hierarchy principle that income is the primary aggregate).",
      "risk_if_skipped": "The dashboard is built with the wrong KPI prioritization or the wrong level of aggregation. Hosts arrive at the renewal decision with insufficient evidence, or with evidence presented in a way that does not support confident decision-making.",
      "priority": "high"
    },
    {
      "id": "tests-0900-012",
      "element_id": "communicates-006",
      "element_title": "Decision-Tree-Aligned Vetting Disclosure",
      "layer": 2,
      "validation_type": "card_sort",
      "method": "Card sort study with 8-10 host prospects. Present 12 information cards representing all guest vetting data points (name, profession, credit result, employment status, income ratio, references, stay pattern, vetting date, checks performed, agent endorsement, city of origin, reason for stay). Ask participants to sort the cards into the order they would want to see them when evaluating a guest proposal. Compare the participant-generated order to the prescribed decision tree (identity > financial reliability > platform process > export).",
      "success_criteria": "At least 70% of participants place identity-related cards (name, profession, city) in the top 4 positions, validating that identity is the first information need. Credit/employment cards cluster together in positions 4-7. At least 60% of participants place vetting process details (checks performed, date) after financial data. The average Spearman rank correlation between participant sort order and the prescribed decision tree is above 0.6.",
      "risk_if_skipped": "The vetting disclosure hierarchy is based on one host's question sequence (Mahesh). Without validation, the prescribed order may not match the broader host population's decision tree, leading to a proposal card that presents information in the wrong sequence.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-013",
      "element_id": "communicates-007",
      "element_title": "Agreement Counterparty Clarity Architecture",
      "layer": 2,
      "validation_type": "comprehension_test",
      "method": "Present 8-10 host prospects with the 'Arrangement Summary' card (three-column layout: Host | Split Lease | Guest, with responsibility dots). Without allowing them to study it for more than 10 seconds, ask four rapid questions: 'Who handles your payment?' 'Who do you contact about property damage?' 'Who do you message about a schedule change?' 'Who is named on the agreement?' Measure: (a) accuracy on each question, (b) response time, (c) whether participants reference the card or recall from memory.",
      "success_criteria": "Accuracy above 90% on all four questions after 10 seconds of viewing. Mean response time under 3 seconds per question. The card must be parseable at a glance, not requiring study. If accuracy drops below 80% on any question, the visual layout needs refinement (dot positioning, column labels, or responsibility row labels).",
      "risk_if_skipped": "The counterparty map looks clear to designers but is not actually parseable by hosts under time pressure. Mahesh's confusion (11:27) is not resolved because the visual solution does not match the cognitive processing pattern of the target user.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-014",
      "element_id": "looks-001",
      "element_title": "Guarantee-First Visual Anchor",
      "layer": 3,
      "validation_type": "visual_comparison_test",
      "method": "Rapid-exposure visual comparison with 10-12 host prospects. Show two versions of the proposal card at 3-second exposure each (too fast for full reading, captures System 1 visual processing): Version A uses the deep purple (#31135D) solid-fill protection bar at the top; Version B uses a standard card layout with a green badge. After exposure, ask: 'What was the first thing you noticed?' and 'How protected did you feel?' (1-7 scale). Also validate WCAG AAA: measure white text on #31135D contrast with automated tooling.",
      "success_criteria": "At least 80% of participants identify the guarantee/protection as the first thing noticed in Version A (vs. typically guest photo or name in Version B). Mean 'protected' rating is at least 1.5 points higher for Version A. WCAG contrast ratio of white on #31135D confirmed at 13.5:1 or above, exceeding AAA threshold.",
      "risk_if_skipped": "The guarantee visual treatment does not actually capture first-look attention. The host's eye bypasses the guarantee and lands on guest details, repeating the reactive pattern where the host must hunt for protection information.",
      "priority": "high"
    },
    {
      "id": "tests-0900-015",
      "element_id": "looks-002",
      "element_title": "Agent-to-Platform Trust Transfer Visual Bridge",
      "layer": 3,
      "validation_type": "first_impression_test",
      "method": "5-second first-impression test with 10-12 host prospects. Show the handoff screen for 5 seconds, then ask three questions: (a) 'What kind of page is this?' (b) 'Who prepared this for you?' (c) 'What should you do next?' Compare responses between the personalized handoff design (warm off-white, agent note with purple accent bar, pre-populated data) and a standard SaaS onboarding screen. Measure whether the handoff design communicates personalization and continuity within 5 seconds.",
      "success_criteria": "At least 80% of participants identify the handoff screen as 'prepared for them personally' or 'from their agent' (vs. standard onboarding identified as 'generic setup'). At least 70% correctly name the agent or reference 'the person I spoke with.' At least 60% identify the correct next action ('review the proposal' or similar) without reading the CTA text carefully.",
      "risk_if_skipped": "The handoff screen looks personalized to the design team but reads as 'just another dashboard' to the host. The warm off-white, purple accent, and agent note do not create the intended emotional warmth, and the trust-transfer moment is lost.",
      "priority": "high"
    },
    {
      "id": "tests-0900-016",
      "element_id": "looks-003",
      "element_title": "Ghost Roommate Progressive Disclosure Visual Layers",
      "layer": 3,
      "validation_type": "visual_hierarchy_test",
      "method": "Visual weight perception test with 8-10 participants. Show all three ghost roommate visual layers (Layer 1 inline callout, Layer 2 preview card, Layer 3 tab/toggle) on the same screen mockup set. Ask participants to rank each layer on 'How much attention does this demand?' (1-5 scale) and 'How much commitment does this ask for?' (1-5 scale). The visual weights should increase monotonically from Layer 1 to Layer 3.",
      "success_criteria": "Attention demand ratings increase across layers: Layer 1 mean below 2.0, Layer 2 mean between 2.5-4.0, Layer 3 mean above 3.5. Commitment perception follows the same monotonic increase. No participant rates Layer 1 higher than Layer 2 on either dimension (the whisper must feel quieter than the card). The 7-column week strip in Layer 2 is correctly interpreted by at least 80% of participants as 'weekday/weekend guest split.'",
      "risk_if_skipped": "The visual layers do not actually communicate progressive weight. If Layer 1 is visually too prominent, it triggers anxiety prematurely. If Layer 2 is visually too light, the host does not recognize it as a decision moment requiring attention.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-017",
      "element_id": "looks-004",
      "element_title": "Gatekeeper Export Document Visual Authority",
      "layer": 3,
      "validation_type": "cross_audience_test",
      "method": "Present the Management Company Package PDF to two audiences: (a) 5 management company professionals who evaluate rental applications daily, and (b) 5 host prospects who would be sharing this document. For management professionals: 'Does this look like a legitimate rental application?' (yes/no + reasoning). For hosts: 'Would you feel confident sharing this with your management company?' (1-7 scale). Also validate print legibility by printing the PDF and checking grayscale readability.",
      "success_criteria": "At least 4 of 5 management professionals accept the document as a legitimate application format. Mean host confidence rating above 5.5 out of 7. The guarantee terms section is identified as noteworthy by at least 3 of 5 management professionals ('this is unusual and valuable'). The document is fully legible when printed in grayscale (purple header renders as dark gray).",
      "risk_if_skipped": "The export document is rejected by management companies because it does not match their expected format, or hosts hesitate to share it because it looks too 'platform-specific' and not enough like a standard application. The gatekeeper barrier remains unresolved.",
      "priority": "high"
    },
    {
      "id": "tests-0900-018",
      "element_id": "looks-005",
      "element_title": "Cumulative Lease Health Visual Meter",
      "layer": 3,
      "validation_type": "prototype_test",
      "method": "Interactive prototype test with 8-10 host prospects. Show the Lease Health meter at three states: (a) week 3 (early), (b) week 8 (midway), (c) week 12 (complete). For each state, ask: 'How is your lease going?' and 'How far through are you?' Measure whether the progress bar communicates both status (things are going well) and position (how far through the lease). Test the current-week pulse animation on both desktop and mobile to ensure it reads as 'active' without being distracting.",
      "success_criteria": "At least 80% of participants correctly estimate their lease progress within 1 week of the actual position. At least 70% use positive language about lease health when the bar shows completed segments with no incidents. The pulse animation is perceived as 'active period' by at least 80% (not 'error' or 'notification'). Total income KPI is the first number participants reference when asked 'How is your lease going?'",
      "risk_if_skipped": "The progress bar does not communicate journey position or health status at a glance. Hosts look at the dashboard and cannot quickly answer 'Am I on track?' -- the core question the meter was designed to address.",
      "priority": "high"
    },
    {
      "id": "tests-0900-019",
      "element_id": "looks-006",
      "element_title": "Counterparty Clarity Visual Map",
      "layer": 3,
      "validation_type": "rapid_comprehension_test",
      "method": "Present the three-column dot-matrix Arrangement Summary card to 10-12 participants for exactly 5 seconds, then hide it. Ask: 'Who handles payments? Who handles property protection? Who do you message about scheduling?' Measure response accuracy and speed. Also test with a text-only version (no columns, no dots -- just a paragraph describing the same structure) as a control condition.",
      "success_criteria": "Dot-matrix version achieves at least 85% accuracy across all three questions after 5-second exposure. Text-only control achieves accuracy below 60%. The visual map must be at least 25 percentage points more effective than text for conveying counterparty structure. Mean response time under 2 seconds per question for the dot-matrix version.",
      "risk_if_skipped": "The counterparty map is implemented as a visual component but does not actually resolve the comprehension problem Mahesh demonstrated at 11:27. The host still needs to read text or call the agent to understand who handles what.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-020",
      "element_id": "behaves-001",
      "element_title": "Preemptive Risk Absorption Reveal on Commitment Surfaces",
      "layer": 4,
      "validation_type": "interaction_timing_test",
      "method": "Performance-instrumented prototype test with 6-8 participants. Measure the actual render sequence on commitment-adjacent screens: does the protection status bar render within 200ms before other content? Test three scenarios: (a) normal network conditions, (b) slow network (3G simulation), (c) guarantee data API failure. For each scenario, observe: does the host attempt to interact with the commitment CTA before the guarantee bar resolves? If the guarantee bar enters the error state ('Protection status unavailable'), does the disabled CTA prevent premature commitment?",
      "success_criteria": "Protection bar renders within 200ms in normal conditions. Under 3G simulation, the skeleton placeholder holds position and the host does not scroll past it. Zero participants click the commitment CTA while the guarantee is in loading state. In the error scenario, 100% of participants notice the disabled CTA and read the error message before attempting to proceed.",
      "risk_if_skipped": "The render-first interaction pattern is specified but not validated for real-world timing. Under slow network conditions, the guarantee bar may appear after the content below it, reversing the emotional sequence (host processes the decision before feeling safe).",
      "priority": "high"
    },
    {
      "id": "tests-0900-021",
      "element_id": "behaves-002",
      "element_title": "Management Company Handoff State Machine",
      "layer": 4,
      "validation_type": "state_machine_walkthrough",
      "method": "End-to-end state machine walkthrough with 6-8 hosts who have management companies. Walk through every state transition: Package Not Yet Shared -> Package Shared -> Awaiting Management Approval -> Follow-Up Nudge -> Approved or Denied. At each state, confirm: (a) the host understands what happened, (b) the host knows what action to take next, (c) the pipeline visualization accurately reflects the current status. Test the 5-business-day nudge notification: does the host find it helpful or nagging?",
      "success_criteria": "100% of participants correctly identify the current pipeline status at each state. At least 80% correctly identify the next action at each state without guidance. The follow-up nudge at day 5 is rated as 'helpful' by at least 5 of 8 participants (not 'annoying' or 'too soon'). Zero participants express confusion about whether the platform or the management company should take the next action.",
      "risk_if_skipped": "The state machine is implemented but hosts cannot interpret the states or do not understand their role at each transition. The management approval process remains a black hole despite having a visible pipeline, because the pipeline labels are confusing or the transitions are unclear.",
      "priority": "high"
    },
    {
      "id": "tests-0900-022",
      "element_id": "behaves-003",
      "element_title": "Ghost Roommate Progressive Engagement Ladder",
      "layer": 4,
      "validation_type": "sequential_interaction_test",
      "method": "Sequential task test with 8-10 host prospects. Walk participants through the three-rung engagement ladder across sessions simulating different journey phases. Rung 1: show the inline evaluation teaser and measure interaction (do they tap to learn more, or ignore?). Rung 2: simulate a match notification and present the preview card -- measure decision time and opt-in/decline split. Rung 3: for those who opted in, show the active tab/toggle operational view -- measure whether they can complete a task (check the weekend guest's cleaning status). Between rungs, confirm the host's emotional state via brief self-report.",
      "success_criteria": "At least 60% of participants interact with the Rung 1 teaser (tap to learn more). Decision time on Rung 2 (accept or decline) is under 60 seconds with the full preview card. At least 70% of those who reach Rung 3 can complete the cleaning status check task in under 15 seconds using the tab/toggle. Emotional self-report does not show anxiety increasing between rungs -- it should remain stable or decrease.",
      "risk_if_skipped": "The progressive ladder is deployed but the transition between rungs feels disjointed. Hosts who were curious at Rung 1 drop off at Rung 2 because the preview is too complex, or hosts who accepted at Rung 2 cannot navigate the operational view at Rung 3.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-023",
      "element_id": "behaves-004",
      "element_title": "Agent Trust Handoff Continuity Bridge",
      "layer": 4,
      "validation_type": "a_b_test",
      "method": "A/B test with 12-16 host prospects who have listened to a simulated agent call. Group A sees the personalized handoff screen (agent note, pre-populated property, guest profile, single CTA). Group B sees a standard multi-step onboarding wizard. Track: (a) time from first login to first meaningful platform action (view proposal), (b) platform return rate within 48 hours, (c) number of post-visit agent contacts for clarification, (d) qualitative first-impression rating.",
      "success_criteria": "Group A completes first meaningful action in under 60 seconds (vs. Group B over 180 seconds). Group A's 48-hour return rate is at least 20 percentage points higher than Group B. Group A generates at least 40% fewer agent clarification contacts. Qualitative: at least 75% of Group A participants rate their first impression as 'the platform knew what I discussed with my agent.'",
      "risk_if_skipped": "The handoff screen is built but its impact on trust transfer is assumed rather than measured. If the handoff does not materially reduce agent dependence or increase first-action speed, the development investment is misallocated.",
      "priority": "high"
    },
    {
      "id": "tests-0900-024",
      "element_id": "behaves-005",
      "element_title": "Lease Health Accumulation Pulse",
      "layer": 4,
      "validation_type": "notification_cadence_test",
      "method": "Simulated lease experience over a compressed timeline (12 'weeks' compressed into 12 days) with 6-8 active hosts or host proxies. Each 'day,' deliver the weekly pulse notification and make the Lease Health dashboard accessible. Measure: (a) notification open rate over the 12-day period (does it decline, hold steady, or increase?), (b) dashboard visit rate after each notification, (c) at 'week 12,' deliver the Lease Performance Summary and ask for the renewal decision. Compare outcomes for hosts who received pulses vs. a control group that received no pulses.",
      "success_criteria": "Notification open rate remains above 50% throughout the 12-day period (does not fatigue). Dashboard visit rate after notification is above 30%. At 'week 12,' the pulse group's extension willingness is at least 20 percentage points higher than the control group. Milestone notifications (weeks 4, 8, 12) show higher open rates than standard weekly pulses.",
      "risk_if_skipped": "The weekly pulse is deployed at a cadence that either causes notification fatigue (too frequent, too much content) or fails to register (too sparse, too minimal). The accumulation narrative does not build because the host stops opening the notifications by week 4.",
      "priority": "high"
    },
    {
      "id": "tests-0900-025",
      "element_id": "behaves-006",
      "element_title": "Counterparty Role Disambiguation on Interaction Surfaces",
      "layer": 4,
      "validation_type": "contextual_comprehension_test",
      "method": "Task-based comprehension test with 8-10 host prospects. Present four action surfaces (message compose, damage claim form, payment history, agreement screen) and ask participants to identify who they are interacting with for each action. Test two conditions: (a) with inline counterparty labels ('Message to Ariel (Guest)', 'File with Split Lease'), (b) without labels (just 'Send Message', 'File Claim'). Measure accuracy and speed.",
      "success_criteria": "Labeled condition achieves 95%+ accuracy on counterparty identification across all four surfaces. Unlabeled condition accuracy drops below 70%. Response time with labels is under 2 seconds per surface. No participant in the labeled condition asks 'who am I talking to?' or 'where does this go?'",
      "risk_if_skipped": "Counterparty labels are omitted as 'obvious' during implementation, leaving the same structural ambiguity that confused Mahesh. Hosts file claims with the wrong party or hesitate to take action because they are unsure of the counterparty.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-026",
      "element_id": "behaves-007",
      "element_title": "Adjacent Network Seed Prompt at Stability Threshold",
      "layer": 4,
      "validation_type": "timing_and_framing_test",
      "method": "Present the referral prompt to 8-10 hosts at three different timing points: (a) at week 6 (mid-lease, before stability threshold), (b) at week 12 alongside the Lease Performance Summary (at stability threshold), (c) at week 14 (after renewal decision). Measure: engagement rate (tap 'Share Split Lease'), qualitative sentiment ('does this feel like the right time?'), and whether the prompt feels transactional or natural. Test with two framings: benefit-focused ('your referral gets them $X off') vs. evidence-focused ('your management company has already approved -- their path will be faster').",
      "success_criteria": "Week 12 timing produces the highest engagement rate (above 25%), with week 6 and week 14 significantly lower. At least 70% of participants rate week 12 as 'the right time.' Evidence-focused framing produces at least 15% higher engagement than benefit-focused framing (validating that hosts respond to their own track record, not incentives). Zero participants describe the prompt as 'pushy' or 'salesy.'",
      "risk_if_skipped": "The referral prompt is deployed at the wrong time or with the wrong framing, producing either low engagement (too early/too late) or negative sentiment (feels transactional). The domino effect fails to activate because the trigger moment is misaligned with the host's emotional state.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-027",
      "element_id": "feels-001",
      "element_title": "Preemptive Safety Before the Ask",
      "layer": 5,
      "validation_type": "emotional_response_test",
      "method": "Emotional response measurement with 8-10 host prospects. Show commitment-adjacent screens (proposal card, pricing confirmation) and collect emotional self-reports using a validated affect grid (valence + arousal) at two moments: (a) 500ms after screen load (captures first emotional impression), (b) after completing the screen review. Test two conditions: protection-status-first (guarantee renders before content) vs. content-first (guest details render first, guarantee below). Compare emotional trajectories between conditions.",
      "success_criteria": "Protection-status-first condition produces higher valence (more positive) at the 500ms mark by at least 1.0 point on a 7-point scale. The emotional trajectory in the protection-status-first condition shows an initial positive set that maintains or increases; the content-first condition shows a neutral or negative initial set that may or may not recover. At least 6 of 8 participants in the protection-first condition describe their initial feeling as 'safe,' 'secure,' or 'protected' in open-ended response.",
      "risk_if_skipped": "The emotional design assumes that guarantee-first rendering produces safety, but the assumption is untested. If hosts do not emotionally register the guarantee bar (e.g., because dark-purple reads as 'header decoration' rather than 'protection confirmation'), the entire emotional foundation of the evaluation phase is undermined.",
      "priority": "high"
    },
    {
      "id": "tests-0900-028",
      "element_id": "feels-002",
      "element_title": "Institutional Belonging for the Gatekept Host",
      "layer": 5,
      "validation_type": "tension_relief_test",
      "method": "Scenario-based emotional assessment with 6-8 hosts who have management companies. Walk through a scripted scenario: 'You have just spoken with an agent about a guest for your property. Your management company requires an application. You open the platform.' Present the management-aware workflow: the platform detects the management company requirement and offers 'Share with Management' with the pre-formatted package. After the walkthrough, ask: 'How much of the management company bridge did you expect to handle yourself?' (1-7 scale, 1=all of it, 7=none of it). Then reveal the platform's handling and ask: 'How much does the platform actually handle?' (same scale). The gap between expectation and reality measures the relief magnitude.",
      "success_criteria": "Mean expectation score is below 3.0 (hosts expect to handle most of the bridge themselves). Mean reality score after seeing the platform's handling is above 5.5. The gap (relief magnitude) is at least 2.5 points. At least 5 of 8 participants spontaneously use the word 'relief' or 'easy' in their qualitative response. Zero participants say 'I still need to figure out' (echoing Mahesh's anxiety phrase at 09:34).",
      "risk_if_skipped": "The management company workflow is built but the emotional impact (relief vs. burden) is unmeasured. The host may use the export feature but still feel burdened because the platform's handling does not match their expectation of comprehensive institutional support.",
      "priority": "high"
    },
    {
      "id": "tests-0900-029",
      "element_id": "feels-003",
      "element_title": "Graduated Confidence for Novel Complexity",
      "layer": 5,
      "validation_type": "longitudinal_emotion_tracking",
      "method": "Multi-session emotional tracking with 6-8 host prospects exposed to the ghost roommate concept over three sessions (simulating evaluation, match-found, and active-lease phases). Before and after each session, collect: (a) confidence level about managing a ghost roommate arrangement (1-7 scale), (b) anxiety level about the arrangement (1-7 scale), (c) open-ended description of their feelings. Track whether confidence increases and anxiety decreases monotonically across the three sessions.",
      "success_criteria": "Confidence increases by at least 1.5 points from session 1 to session 3. Anxiety decreases by at least 1.5 points from session 1 to session 3. No session produces an anxiety spike (session-over-session increase greater than 0.5 points). At least 5 of 8 participants describe feeling 'in control' or 'prepared' by session 3. Zero participants describe feeling 'overwhelmed' at any session.",
      "risk_if_skipped": "The graduated confidence model is deployed without validating that confidence actually builds across the three disclosure layers. A poorly calibrated layer could produce an anxiety spike that undoes the work of prior layers, resulting in lower ghost roommate adoption than the all-at-once approach.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-030",
      "element_id": "feels-004",
      "element_title": "Warm Recognition at Platform First Contact",
      "layer": 5,
      "validation_type": "first_impression_emotional_test",
      "method": "First-impression emotional assessment with 8-10 host prospects. After listening to a simulated agent call, participants wait 30 minutes (simulating the real-world gap between call and platform visit). They then open the platform prototype. Capture: (a) immediate emotional response via rapid affect self-report, (b) whether they feel 'recognized' or 'expected' (yes/no), (c) first verbal utterance (think-aloud). Test both the personalized handoff screen and a standard onboarding as control.",
      "success_criteria": "At least 80% of handoff-screen participants answer 'yes' to feeling recognized (vs. below 30% for standard onboarding). First verbal utterances in the handoff group contain references to the call, the agent, or the specific data ('that is what we talked about'). Mean emotional valence is at least 1.5 points higher for the handoff group at the immediate-response measurement. Zero participants in the handoff group describe a sense of 'starting over.'",
      "risk_if_skipped": "The warm-recognition emotional target is assumed to be produced by the handoff screen design, but the actual first-contact emotion may be different (e.g., confusion at unfamiliar layout, or indifference to the agent note). Without measurement, the most critical emotional moment in the host journey -- the transition from human trust to digital trust -- is designed on assumption.",
      "priority": "high"
    },
    {
      "id": "tests-0900-031",
      "element_id": "feels-005",
      "element_title": "Visible Accumulation During the Stability Test",
      "layer": 5,
      "validation_type": "emotional_accumulation_test",
      "method": "Compressed longitudinal test with 6-8 hosts receiving simulated weekly pulse notifications over 12 days (representing 12 weeks). At days 1, 4, 8, and 12, collect emotional self-reports: (a) 'How confident are you that this arrangement is working?' (1-7), (b) 'How likely are you to continue?' (1-7), (c) brief qualitative: 'What is driving your confidence level?' Track whether visible accumulation (progress bar filling, income total growing) is cited as the driver of confidence.",
      "success_criteria": "Confidence rating increases monotonically across the four measurement points, from below 4.0 at day 1 to above 5.5 at day 12. Continuation likelihood follows the same pattern. At least 5 of 8 participants cite specific cumulative data (total income, zero incidents, progress bar position) as the driver of their confidence at day 12 -- not abstract feelings. The emotional state at day 12 is described as 'calm,' 'steady,' or 'confident' rather than 'excited' or 'nervous.'",
      "risk_if_skipped": "The weekly pulse and progress bar are deployed but do not actually produce the intended emotional accumulation. The host receives notifications but does not register them as evidence building toward a positive outcome. At renewal, the decision still feels abstract and uncertain.",
      "priority": "high"
    },
    {
      "id": "tests-0900-032",
      "element_id": "feels-006",
      "element_title": "Structural Clarity for the Three-Party Arrangement",
      "layer": 5,
      "validation_type": "emotional_comparison_test",
      "method": "Before-and-after emotional measurement with 8-10 host prospects. Before: ask participants to describe in their own words who is involved in a Split Lease arrangement and who handles what. Rate their emotional state: anxiety about the arrangement structure (1-7), clarity about who to contact for issues (1-7). Then present the counterparty-labeled interfaces (action surfaces with role labels, Arrangement Summary card). After: repeat the same questions and ratings. Measure the shift.",
      "success_criteria": "Anxiety decreases by at least 2.0 points after exposure to the counterparty-labeled interfaces. Clarity increases by at least 2.5 points. Post-exposure verbal descriptions of the arrangement structure are accurate (correctly identify Split Lease's role for payments, protection, and disputes) for at least 80% of participants. Zero participants use fragmented or uncertain phrasing like Mahesh's at 11:27 ('is it with you guys or it's a, the record?').",
      "risk_if_skipped": "The structural clarity emotional target is assumed to be produced by counterparty labels, but the labels may not actually resolve the underlying emotional confusion. The three-party arrangement may require more than labels -- it may require a mental model that the current design does not build.",
      "priority": "medium"
    },
    {
      "id": "tests-0900-033",
      "element_id": "journey-level",
      "element_title": "End-to-End Host Journey Coherence: Evaluation Through Active Lease",
      "layer": "cross-layer",
      "validation_type": "journey_walkthrough",
      "method": "Full journey walkthrough with 4-6 host prospects who match Mahesh's profile (first-time platform user, property with management company, considering competitor). Simulate the entire journey from agent call through active lease (compressed timeline): (1) Listen to a 5-minute agent call excerpt, (2) first platform visit (handoff screen), (3) review proposal with guarantee, (4) share Management Company Package, (5) receive management approval, (6) accept lease, (7) receive 4 weekly pulse notifications, (8) view Lease Health dashboard at 'month 1.' At each transition, collect: emotional state, trust rating, and intention to continue. Identify any moment where trust drops, confusion arises, or the host wants to contact the agent.",
      "success_criteria": "Trust rating never drops below the post-call baseline at any journey point (the platform maintains or builds on the agent's trust). Emotional state remains positive or neutral throughout. Zero journey-breaking moments (points where the host would abandon the platform and call the agent or switch to a competitor). At least 4 of 6 participants reach the 'month 1' pulse with an extension willingness above 5.0 on a 7-point scale. The management company step does not produce an anxiety spike greater than 1.0 point on the trust scale.",
      "risk_if_skipped": "Individual elements are validated in isolation but the end-to-end journey has undetected gaps, particularly at transition points between layers (e.g., the trust transfer from agent call to platform, the management company approval wait, the shift from evaluation excitement to active lease calm). These transition gaps are where the most hosts are lost.",
      "priority": "high"
    },
    {
      "id": "tests-0900-034",
      "element_id": "journey-level",
      "element_title": "Token Drift Resolution Validation",
      "layer": "cross-layer",
      "validation_type": "visual_consistency_audit",
      "method": "Visual consistency audit across all screens in this run's elements. Compare every specified token (colors, typography, spacing) against both tokens.json and the production Style-guide.md. Create a conflict matrix showing: (a) tokens specified in elements that match production, (b) tokens specified in elements that match tokens.json, (c) tokens specified that match neither. Validate that 100% of this run's visual specifications use the production purple palette, not the tokens.json green palette. Flag any element that inadvertently references green (#2d5a3d), Instrument Serif, or Outfit.",
      "success_criteria": "100% of visual tokens in this run's L3 elements (looks-001 through looks-006) map to the production purple palette. Zero references to #2d5a3d (green accent), Instrument Serif, or Outfit appear in any element. The conflict matrix identifies all tokens that need to be added to tokens.json to resolve the drift. A specific tokens.json update proposal is produced as an artifact of this audit.",
      "risk_if_skipped": "The token drift continues to propagate. New runs use production tokens while old runs use tokens.json tokens, creating an incoherent visual library where guarantee badges are sometimes green and sometimes purple, and typography shifts unpredictably between runs.",
      "priority": "high"
    },
    {
      "id": "tests-0900-035",
      "element_id": "journey-level",
      "element_title": "Ghost Roommate Opt-Out Safety Net Validation",
      "layer": "cross-layer",
      "validation_type": "edge_case_walkthrough",
      "method": "Edge case walkthrough with 6-8 participants testing ghost roommate opt-out scenarios: (a) decline the match at Rung 2 preview, (b) accept and then opt out during active lease, (c) opt out of all future ghost roommate interactions via settings. For each scenario, verify: the base guarantee remains visibly active and unchanged, no penalty language appears, and the host can return to single-guest mode without calling the agent. Measure: (a) host confidence that the base guarantee is unaffected, (b) time to complete the opt-out action, (c) whether the host perceives any negative consequence.",
      "success_criteria": "100% of participants confirm the base guarantee remains active after opt-out in all three scenarios. Opt-out action completion in under 15 seconds for each scenario. Zero participants perceive a penalty, reduced coverage, or negative consequence. At least 80% describe the opt-out as 'easy' or 'straightforward.' Mahesh's core concern ('I'm still getting paid whatever first month' at 10:45) is validated as preserved in all opt-out states.",
      "risk_if_skipped": "Hosts accept ghost roommate matches but cannot easily opt out, or feel their guarantee is at risk when opting out. This converts a revenue-maximizing feature into a trust-destroying one, as the host feels locked into an arrangement they do not fully control.",
      "priority": "medium"
    }
  ]
}