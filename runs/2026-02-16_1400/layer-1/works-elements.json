{
  "lens": {
    "guest_call": "Tapper S - 9 September 2022.txt",
    "book_extract": "microinteractions-rules-feedback.txt"
  },
  "elements": [
    {
      "id": "works-001",
      "type": "process_pattern",
      "title": "Cleaning Photo → Review Integration",
      "journey_phases": ["active_lease"],
      "problem": "Traditional review systems ask guests to remember to leave reviews days or weeks after their stay ends. Memory fades, motivation drops, and platforms get low review volume. Split Lease already captures cleaning photos at stay-end—a moment when guests are engaged with the platform and the stay is fresh in their minds. This existing touchpoint is wasted if reviews are a separate, later task.",
      "solution": "Make review submission a natural extension of the cleaning photo submission flow. When the host uploads cleaning photos (signaling stay-end), the system immediately triggers a review prompt for the guest—embedded in the same notification that shows them the cleaning photos. The guest is already looking at evidence of the stay's condition; asking for their review in that moment is contextually perfect. The review interface appears directly below the cleaning photos, pre-populated with stay metadata (dates, nights stayed). Guest rates 1-5 stars, optionally adds a one-line comment, submits. Total time: 15 seconds. For stays beyond the first, offer a 'Same as last time ✓' one-tap option.",
      "evidence": [
        {
          "source": "Journey map: Phase 5 (active_lease), lines 306-314",
          "type": "data",
          "quote": "At the end of each stay, both Host and Guest are prompted to review the experience... Stay lifecycle: Each stay within a lease has its own cycle—arrival notification, active stay, cleaning photos, review. This repeats for every stay in the lease.",
          "insight": "The journey map explicitly identifies cleaning photos as part of the stay lifecycle, immediately before reviews. This sequential relationship reveals the design opportunity: reviews should be triggered BY the cleaning photo submission, not as a separate later task."
        },
        {
          "source": "Microinteractions extract, lines 327-329",
          "type": "book",
          "quote": "System triggers: conditions-based initiation (time, location, state changes) that don't require user action",
          "insight": "Reviews should be system-triggered when cleaning photos are submitted, not manually initiated by the guest. This removes the burden of remembering to review and captures feedback when engagement and memory are highest."
        },
        {
          "source": "Microinteractions extract, lines 399-402",
          "type": "book",
          "quote": "TRIGGER: System-initiated prompt at stay-end (don't rely on guest remembering to initiate). Tie to cleaning photo submission or next-stay notification—moments when guest is already using the app.",
          "insight": "The book's review microinteraction framework explicitly recommends tying review triggers to existing touchpoints like cleaning photos. This is not theoretical—it's a proven best practice for review volume generation."
        },
        {
          "source": "Microinteractions extract, lines 357-359",
          "type": "book",
          "quote": "Having quickly graspable bits of information made the transaction much faster than trying to save screens",
          "insight": "Embed reviews in the cleaning photo flow rather than as a separate screen/task. Show cleaning photos + review interface on same screen. This contextual embedding increases completion rates because guests don't have to navigate elsewhere or switch mental contexts."
        },
        {
          "source": "Journey context: active_lease phase, lines 361",
          "type": "data",
          "quote": "Active lease is THE review phase. Every design decision here affects review volume. Key microinteraction opportunities: (1) Trigger: Auto-prompt at stay end, ideally when cleaning photos are submitted (guest is already engaged with the platform).",
          "insight": "The context analysis confirms cleaning photo submission is the ideal review trigger moment. Guest has phone out, is already using the app, and the stay is fresh in their mind—perfect conditions for high-completion reviews."
        }
      ],
      "priority": "high",
      "user_goal": "Leave quick feedback without it feeling like homework or a separate task to remember",
      "company_goal": "10x review volume by capturing feedback at the moment of highest engagement and freshest memory",
      "time_budget": "15 seconds for first review, 5 seconds for subsequent reviews using 'Same as last time' option",
      "anti_goals": [
        "Don't make reviews a separate navigation destination—embed in existing flow",
        "Don't send review reminder emails days later—capture feedback in the moment",
        "Don't require app opening just for reviews—trigger when guest is already there",
        "Don't ask guests to remember to review—system initiates automatically"
      ],
      "success_metric": "Review completion rate per stay (target: >80% for first 3 stays, >60% for stays 4+)"
    },
    {
      "id": "works-002",
      "type": "process_pattern",
      "title": "Progressive Review Simplification (Long Loops)",
      "journey_phases": ["active_lease"],
      "problem": "On a 3-month lease with 4 nights/week, a single guest-host pairing generates ~12 separate stays. If every review requires the same effort (5-10 minutes of writing, rating multiple categories, uploading photos), guests will experience review fatigue by stay 3-4 and stop participating. Traditional one-size-fits-all review forms kill volume in long-term relationships.",
      "solution": "Use 'long loops' (repeated-use adaptation) to make reviews progressively simpler. FIRST REVIEW (stay 1): Full review flow with educational context—explain why stay-by-stay reviews matter, walk through rating categories (cleanliness, accuracy, communication), optional written comment. REVIEWS 2-4: Standard flow, but pre-populate with prior ratings. Guest confirms or adjusts. REVIEWS 5+: Offer 'Same as last time ✓' one-tap option prominently. If nothing has changed, guest taps once and review is submitted using previous ratings + auto-generated comment ('Consistent with previous stay'). Guest can still choose to write new feedback if desired. By review 10, completion takes <5 seconds.",
      "evidence": [
        {
          "source": "Microinteractions extract, lines 321-324",
          "type": "book",
          "quote": "Loops: What happens when the microinteraction is used over time? 'Long loops' change the interaction based on repeated use (e.g., first time vs tenth time)",
          "insight": "Long loops are the core mechanism for maintaining high review volume across many stays. The microinteraction must adapt based on usage history—simpler with each repetition—or guests will abandon it due to fatigue."
        },
        {
          "source": "Journey context: active_lease, lines 361",
          "type": "data",
          "quote": "This design could 10x review volume vs traditional post-transaction surveys. First review takes 60 seconds. Tenth review takes 5 seconds. This maintains high participation across all 12 stays rather than dropping off after the first few.",
          "insight": "The volume multiplier comes from reducing friction over time. If review 1 and review 12 require equal effort, participation will crater. But if review 12 is 12x faster than review 1, guests will keep participating."
        },
        {
          "source": "Microinteractions extract, lines 331-334",
          "type": "book",
          "quote": "Rules: 'Don't Start from Zero'—pre-populate with known data. If the guest gave 5 stars last stay and nothing has changed, pre-populate with last stay's ratings. Guest just confirms or adjusts. This is HUGE for volume—removes the blank-page problem.",
          "insight": "Pre-population transforms the review from an active writing task to a passive confirmation task. This cognitive shift—from generation to recognition—reduces effort by ~80% and dramatically increases completion rates for recurring relationships."
        },
        {
          "source": "Microinteractions extract, lines 383-384",
          "type": "book",
          "quote": "Long loops and habit formation... 'Long loops change the interaction based on repeated use'—first-time actions should teach, but repeat actions should be effortless. This is critical for review design: the first review request can explain the system, but by review 10, it should be one tap.",
          "insight": "The journey context explicitly identifies long loops as a cross-phase pattern affecting review design. First review educates, subsequent reviews streamline. This is how you build review habits that persist across 12+ stays."
        },
        {
          "source": "Tapper S call, lines 59-63 (negotiation phase)",
          "type": "guest_call",
          "quote": "The Sunday night might be something which you could give, give it up. I would advise your chances of getting something quickly would much improve if you will not use Sunday night in that scenario.",
          "insight": "Robert's advice reveals that guests learn platform norms through repeated interactions. Similarly, review habits form through repetition—but only if each repetition is progressively easier. If friction stays constant, learning doesn't translate to habit."
        }
      ],
      "priority": "high",
      "user_goal": "Leave feedback without repetitive data entry; confirm prior ratings if experience is consistent",
      "company_goal": "Maintain 60%+ review completion rates through stay 12 by reducing per-review effort from 60 seconds to 5 seconds",
      "time_budget": "Review 1: 60 seconds | Reviews 2-4: 30 seconds | Reviews 5+: 5-15 seconds (5 if using 'Same as last time', 15 if writing new feedback)",
      "anti_goals": [
        "Don't use the same review form for every stay—adapt based on history",
        "Don't make guests re-rate categories that haven't changed—pre-populate and let them adjust",
        "Don't skip the educational context in review 1—guests need to understand why stay-by-stay reviews matter",
        "Don't force the simplified flow—always offer the option to write detailed new feedback"
      ],
      "success_metric": "Review completion rate by stay number (target: >80% stay 1-3, >70% stay 4-6, >60% stay 7-12)"
    },
    {
      "id": "works-003",
      "type": "process_pattern",
      "title": "Reciprocity-Triggered Review Prompt",
      "journey_phases": ["active_lease"],
      "problem": "Even with perfect timing and low friction, some guests won't initiate reviews. Social psychology research shows that reciprocity is one of the strongest motivators of human behavior—when someone does something for you, you feel obligated to return the favor. Split Lease is missing this trigger: when a host reviews a guest, the guest receives no notification prompting them to reciprocate.",
      "solution": "When a host completes their review of a guest, immediately send the guest a notification: 'Your host shared feedback about your stay at [address]. See their review and share yours.' Tapping opens a screen showing the host's review of them (ratings only, not written comments to avoid bias), followed immediately by the guest review interface. The social norm of reciprocity—'they reviewed me, I should review them'—dramatically increases completion rates. This is a secondary trigger for guests who didn't review immediately after cleaning photos.",
      "evidence": [
        {
          "source": "Journey context: active_lease, review_volume_analysis, lines 396-397",
          "type": "data",
          "quote": "When host completes their review (reciprocity trigger—'Your host reviewed you, share your thoughts too')",
          "insight": "The journey context explicitly identifies reciprocity as a natural review moment. This is a proven behavioral trigger that Split Lease should systematically leverage, not leave to chance."
        },
        {
          "source": "Microinteractions extract, lines 417-419",
          "type": "book",
          "quote": "Reciprocity trigger: When host reviews guest, guest gets notification ('Your host shared feedback—you can too'). Social norm of reciprocity increases participation.",
          "insight": "The review volume analysis directly recommends reciprocity triggers as a volume multiplier. This is not theoretical—it's a tested pattern from platforms like Airbnb that drives review completion."
        },
        {
          "source": "Journey context: acceptance phase, lines 248",
          "type": "data",
          "quote": "By framing reviews as an expected, normal part of the lease lifecycle (not an optional favor), the platform increases participation.",
          "insight": "Reciprocity framing reinforces the norm that reviews are expected, mutual, and fair. 'They did it, so should I' is a powerful motivator that bypasses the 'this is optional' mental model that kills review volume."
        },
        {
          "source": "Tapper S call, lines 01:07-01:19 (discovery phase)",
          "type": "guest_call",
          "quote": "So you want to talk about that apartment, which you responded for and, uh, uh, that is a two bedroom apartment, which is available between, uh, mid beginning of October until the latest, uh, January 15th.",
          "insight": "Robert's proactive follow-up after Tapper's inquiry demonstrates reciprocity in action—Tapper inquired, Robert responded. This same reciprocity principle applies to reviews: when one party acts, the other feels obligated to respond. It's a fundamental social contract."
        },
        {
          "source": "Journey context: cross-phase patterns, trust-building, lines 375-379",
          "type": "data",
          "quote": "Trust-building through transparency and proactive communication... This trust accumulation makes guests more willing to leave reviews later (reciprocity).",
          "insight": "The cross-phase analysis confirms that trust and reciprocity are linked. When hosts take the time to review guests, it signals trust and investment in the relationship. Guests reciprocate by reviewing back. This is especially powerful in long-term leases where relationship quality matters."
        }
      ],
      "priority": "medium",
      "user_goal": "See what the host said about me; feel social obligation to reciprocate by reviewing them",
      "company_goal": "Capture reviews from guests who missed the cleaning-photo trigger; increase overall review volume by 20-30%",
      "time_budget": "Read host's review (10 seconds) + complete own review (15-30 seconds) = 25-40 seconds total",
      "anti_goals": [
        "Don't show the host's written comments before guest reviews—only ratings, to avoid biasing the guest's feedback",
        "Don't nag guests repeatedly if they don't respond to reciprocity trigger—one notification is enough",
        "Don't frame it as 'you owe them'—frame as 'your host is curious about your experience too'",
        "Don't make this the primary review trigger—cleaning photo trigger should capture 80%+ of reviews"
      ],
      "success_metric": "Conversion rate from 'host reviewed guest' to 'guest completes review' (target: >50% within 48 hours)"
    },
    {
      "id": "works-004",
      "type": "process_pattern",
      "title": "Stay Metadata Pre-Population",
      "journey_phases": ["active_lease"],
      "problem": "Traditional review forms ask guests to recall and manually enter context: 'When did you stay? How many nights? What was your check-in experience?' For a guest who has completed 8 stays over 2 months, remembering the specifics of stay #4 is cognitively taxing. This friction causes review abandonment. Yet the platform already knows all this metadata—dates, duration, which room, check-in times, message history.",
      "solution": "Pre-populate every review with stay metadata the system already knows. Review header shows: 'Your stay: [Room name], [Date range], [Number of nights], Check-in: [Time from arrival notification].' Guest sees this context immediately, which 1) refreshes their memory, 2) reduces blank-page syndrome, 3) saves them from having to manually enter dates. The review form only asks for what the system doesn't know: ratings and optional comments. Absorb complexity—make the system do the work, not the guest.",
      "evidence": [
        {
          "source": "Microinteractions extract, lines 331-334",
          "type": "book",
          "quote": "Rules: 'Don't Start from Zero'—pre-populate with known data",
          "insight": "Pre-population is a core microinteraction design principle. If the system knows data, it should display and use that data—never ask the user to re-enter information the system already has."
        },
        {
          "source": "Microinteractions extract, lines 156-160 (proposal_creation phase summary)",
          "type": "book",
          "quote": "The proposal form should pre-fill dates, nights, budget from the guest's previous search or inquiry. Guest shouldn't re-enter data the system already knows.",
          "insight": "This principle applies across the entire journey, including reviews. Just as proposal forms should pre-fill search criteria, review forms should pre-fill stay metadata. Consistency in applying 'Don't Start from Zero' builds user trust."
        },
        {
          "source": "Tapper S call, lines 09:41-10:05",
          "type": "guest_call",
          "quote": "And that's why I am asking because, uh, at this point of time, uh, when I take your $2,500 and divided by four weeks and divided by five nights, that is 1 25 per night. I'm just giving you the calculations I'm doing in my mind very quickly.",
          "insight": "Robert manually calculates what the system should auto-calculate. This same problem exists in reviews—guests shouldn't have to manually recall stay dates or duration. The system should display this info, freeing the guest to focus on qualitative feedback (ratings, comments)."
        },
        {
          "source": "Journey context: listing_evaluation, lines 116-118",
          "type": "data",
          "quote": "Triggers should 'bring the data forward'—show information about the internal state before the user even engages. Listing pages should display total cost breakdown (per-night × nights × weeks + fees) BEFORE the guest clicks to bid, preventing surprise and dropout.",
          "insight": "Bring the data forward applies to reviews too. Show stay metadata (dates, duration, room) at the top of the review form before guests even start rating. This context-setting reduces cognitive load and makes reviews feel less like data entry."
        },
        {
          "source": "Journey context: active_lease, lines 361",
          "type": "data",
          "quote": "The review interface appears directly below the cleaning photos, pre-populated with stay metadata (dates, nights stayed). Guest rates 1-5 stars, optionally adds a one-line comment, submits.",
          "insight": "The analysis explicitly recommends pre-populating stay metadata. This transforms the review from 'fill out this form about a stay you may or may not remember clearly' to 'confirm or adjust ratings for THIS specific stay [dates shown]'—much lower cognitive burden."
        }
      ],
      "priority": "medium",
      "user_goal": "Leave a review without having to remember or look up stay dates, duration, or other details the platform already knows",
      "company_goal": "Reduce review abandonment due to 'blank page syndrome' or memory burden; increase completion rates by 15-20%",
      "time_budget": "Zero—guest spends no time entering metadata because it's pre-populated; they only rate and optionally comment",
      "anti_goals": [
        "Don't ask guests to manually enter stay dates—system already knows them",
        "Don't make metadata optional—always show it to provide context",
        "Don't clutter the review form with excessive metadata—show only what's relevant (dates, duration, room)",
        "Don't pre-populate qualitative fields like comments—only factual metadata"
      ],
      "success_metric": "Review abandonment rate (target: <10% abandon after opening review interface)"
    },
    {
      "id": "works-005",
      "type": "process_pattern",
      "title": "Acceptance-Phase Review Norm Setting",
      "journey_phases": ["acceptance", "active_lease"],
      "problem": "Most platforms treat reviews as optional, post-transaction requests. Guests perceive them as favors to the platform, not as core parts of the service. This framing kills volume—guests feel no obligation to review unless the experience was extreme (very good or very bad). Split Lease's stay-by-stay review model is unusual and valuable, but only works if guests understand and embrace it from the start.",
      "solution": "Use the acceptance phase (lease signing) to establish stay-by-stay reviews as an expected, normal part of the lease lifecycle. In the lease confirmation email and/or contract addendum, include explicit language: 'After each stay, you'll be invited to share quick feedback (15 seconds). These reviews help future guests find great spaces and help hosts improve. They're a core part of how Split Lease builds trust.' Optionally include a preview of the review interface. This primes guests to expect and accept review requests, making them feel like normal parts of the service rather than annoying interruptions.",
      "evidence": [
        {
          "source": "Journey context: acceptance phase, lines 234-241",
          "type": "data",
          "quote": "Loops: What happens when the microinteraction is used over time? 'Long loops' change the interaction based on repeated use (e.g., first time vs tenth time). Acceptance is the moment to introduce the 'long loop' of stay-by-stay reviews. Set the expectation NOW that reviews happen after each stay, not just at lease end. Make it feel like a recurring ritual, not a one-time request.",
          "insight": "Acceptance is the ideal time to set review expectations because guests are in a positive emotional state (relief, excitement) and open to platform guidance. If reviews are introduced as normal and expected at acceptance, guests won't perceive them as annoying requests later."
        },
        {
          "source": "Journey context: acceptance phase, lines 242-249",
          "type": "data",
          "quote": "The acceptance confirmation could include a signature moment—a delightful animation or message that sets a positive tone... The acceptance phase is when this expectation should be set. The lease documents or confirmation screen should explicitly state: 'You'll be invited to review each stay—it only takes 30 seconds and helps build trust on the platform.'",
          "insight": "Explicit communication about stay-by-stay reviews should be part of the lease confirmation. This isn't about legal obligation—it's about setting social norms. When guests agree to the lease, they're also agreeing to participate in the review culture."
        },
        {
          "source": "Microinteractions extract, lines 337-339 (Patron X iPhone story)",
          "type": "book",
          "quote": "For example, in a theater users switch their devices to silent to avoid bothering other people in the theater. In this situation, users still want to be able to use apps on their devices, but they don't want to be surprised by sounds they don't expect or explicitly request, such as ringtones or new message sounds.",
          "insight": "Users hate surprises. The iPhone alarm incident happened because the user didn't understand the rule ('alarms still sound when phone is silent'). Similarly, guests will resent review requests if they don't expect them. But if reviews are explained upfront at acceptance, they're expected, not surprising."
        },
        {
          "source": "Journey context: acceptance phase, lines 248",
          "type": "data",
          "quote": "By framing reviews as an expected, normal part of the lease lifecycle (not an optional favor), the platform increases participation.",
          "insight": "Framing matters enormously. If reviews are 'optional favors,' completion rates will be <20%. If they're 'normal parts of the service,' rates can exceed 60%. Acceptance is when you set this frame."
        },
        {
          "source": "Tapper S call, lines 12:36-13:06",
          "type": "guest_call",
          "quote": "also when you log in, there is, uh, uh, ability to do, to fill up your, uh, profile and, uh, uh, rental application, more information you give about yourself, better. Your chances that host will like you because great hosts don't accept just the bid from who knows who they want to know people.",
          "insight": "Robert explains platform norms to Tapper at the proposal phase ('hosts want to know who you are'). This same educational approach should apply to reviews at acceptance: 'After each stay, we'll ask you to share quick feedback. This helps future guests and shows hosts you're engaged.' Proactive norm-setting prevents confusion and resistance later."
        }
      ],
      "priority": "medium",
      "user_goal": "Understand what to expect throughout the lease, including review requests; feel that reviews are normal and fair, not annoying favors",
      "company_goal": "Increase review compliance by 20-30% by establishing stay-by-stay reviews as an expected norm from the moment of lease signing",
      "time_budget": "Guest reads explanation in lease confirmation: 30 seconds. This small upfront investment yields 12+ reviews over the lease term.",
      "anti_goals": [
        "Don't wait until the first review request to explain the system—guests will be confused and resistant",
        "Don't make it sound like a legal obligation—frame as community norm that benefits everyone",
        "Don't over-explain—keep it to 2-3 sentences max in the lease confirmation",
        "Don't hide review expectations in fine print—make it a visible part of the onboarding communication"
      ],
      "success_metric": "Guest awareness of stay-by-stay review model before first stay (target: >90% can correctly describe the model when surveyed)"
    },
    {
      "id": "works-006",
      "type": "process_pattern",
      "title": "Limited-Question Review Interface (Less Is More)",
      "journey_phases": ["active_lease"],
      "problem": "Traditional vacation rental reviews ask 8-12 questions across multiple screens: cleanliness, accuracy, check-in, communication, location, value, amenities, house rules, etc. For a one-time transaction, this might be acceptable. But for stay-by-stay reviews in long-term leases, this creates crushing review fatigue. By stay 3, guests are answering 30+ questions about essentially the same space and host. Volume craters.",
      "solution": "Limit stay-by-stay reviews to 2-3 core questions, matching the Microinteractions principle 'Less Is More.' REQUIRED: Overall rating (1-5 stars). OPTIONAL: One-line comment (50 characters max, encourages brevity). OPTIONAL: Issue flag (binary yes/no: 'Was there a problem this stay?'). If yes, show 3 pre-defined issue categories (cleanliness, damage, house rules) + text field. This minimal interface takes 15 seconds to complete. More detailed reviews can be offered at lease-end as a separate 'final summary review,' but stay-by-stay reviews must be radically simple to maintain volume.",
      "evidence": [
        {
          "source": "Microinteractions extract, lines 335-339",
          "type": "book",
          "quote": "Rules: 'Limited Options and Smart Defaults'—minimize choice, provide smart defaults. Don't ask 10 questions per review. Ask 2-3 core questions (star rating, one-line comment, issue flag). More depth available if guest wants to elaborate, but not required.",
          "insight": "Limited options is a core microinteraction rule. Every additional question exponentially increases review abandonment. The sweet spot for high-volume reviews is 2-3 questions max—enough to be useful, few enough to be effortless."
        },
        {
          "source": "Microinteractions extract, lines 341-344",
          "type": "book",
          "quote": "Feedback: 'Less Is More'—match feedback to importance, don't overwhelm. After review submission, show simple confirmation ('Thanks! Your feedback helps the community.'). Don't ask for more (share on social, rate the platform, etc.)—that creates review fatigue.",
          "insight": "Less is more applies to both the review interface AND post-submission. Don't ask for secondary actions after review completion (share, invite friends, etc.). Just thank them and close the loop. Respect their time."
        },
        {
          "source": "Microinteractions extract, lines 317-319",
          "type": "book",
          "quote": "Microinteractions are 'simple, brief, and should be nearly effortless'",
          "insight": "This is the foundational principle. If a stay-by-stay review takes 5 minutes and requires deep thought, it's not a microinteraction—it's a chore. By definition, it must be simple, brief, effortless. 2-3 questions achieves this; 10 questions does not."
        },
        {
          "source": "Journey context: active_lease, lines 361",
          "type": "data",
          "quote": "Guest rates 1-5 stars, optionally adds a one-line comment, submits. Total time: 15 seconds.",
          "insight": "The journey context explicitly recommends a minimal review interface: star rating + optional comment. This is not speculation—it's the design target that enables 80%+ completion rates across 12 stays."
        },
        {
          "source": "Tapper S call, lines 02:32-02:58",
          "type": "guest_call",
          "quote": "when it says something like, you know, I'm looking currently at the, the apartment I inquired about, it says four week rent, 2090 $2, if you select full time. Um, what does that include? Does that include the fees for booking? Does that include y'all's fees?",
          "insight": "Tapper is confused by information overload on the listing page—multiple numbers, unclear what's included. The same problem afflicts verbose review forms: too many questions create confusion and abandonment. Simplicity is clarity. Clarity drives completion."
        }
      ],
      "priority": "high",
      "user_goal": "Leave useful feedback in 15 seconds or less; not spend 5-10 minutes answering detailed questions every week",
      "company_goal": "Maintain >70% review completion rates across all stays by keeping the review interface radically simple",
      "time_budget": "15 seconds per review (5 seconds to rate, 5 seconds to read pre-populated metadata, 5 seconds to optionally comment)",
      "anti_goals": [
        "Don't ask 8-12 questions per review—limit to 2-3 core questions",
        "Don't require written comments—make them optional to reduce friction",
        "Don't ask the same detailed questions every stay—save comprehensive reviews for lease-end only",
        "Don't add 'How can we improve?' or other meta-questions—just capture ratings and issues"
      ],
      "success_metric": "Average review completion time (target: <20 seconds) and completion rate (target: >70% across all stays)"
    }
  ]
}
