<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Design Stack v2 Report</title>
  <link href="https://fonts.googleapis.com/css2?family=Instrument+Serif&family=Outfit:wght@300;400;500;600;700&family=IBM+Plex+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg: #f6f4f0;
      --bg-deep: #eae7e1;
      --surface: #ffffff;
      --surface-warm: #fdfcfa;
      --ink: #1a1714;
      --ink-soft: #4a4640;
      --ink-muted: #8a857e;
      --ink-ghost: #bdb8b0;
      --accent: #2d5a3d;
      --accent-light: #e8f0eb;
      --accent-bright: #3a7a52;
      --signal-warn: #c17a28;
      --signal-warn-bg: #fef3e2;
      --signal-danger: #b83a3a;
      --signal-danger-bg: #fde8e8;
      --signal-info: #2d5a8a;
      --signal-info-bg: #e8f0fa;
      --signal-success: #2d5a3d;
      --signal-success-bg: #e8f0eb;
      --border: #e2dfd9;
      --border-strong: #ccc8c0;
      --radius-sm: 6px;
      --radius-md: 10px;
      --radius-lg: 16px;
      --shadow-sm: 0 1px 3px rgba(26,23,20,0.06);
      --shadow-md: 0 2px 8px rgba(26,23,20,0.08);
      --ease-out: cubic-bezier(0.16, 1, 0.3, 1);
    }

    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: 'Outfit', sans-serif; color: var(--ink); background: var(--bg); line-height: 1.6; }

    /* Header */
    .report-header { background: var(--surface); border-bottom: 1px solid var(--border); padding: 32px 40px; }
    .report-header h1 { font-family: 'Instrument Serif', serif; font-size: 36px; font-weight: 400; margin-bottom: 4px; }
    .report-header .lens-label { font-size: 16px; color: var(--ink-soft); margin-bottom: 12px; }
    .report-meta { display: flex; gap: 24px; flex-wrap: wrap; color: var(--ink-muted); font-size: 13px; font-family: 'IBM Plex Mono', monospace; }
    .badge { display: inline-flex; align-items: center; gap: 6px; padding: 2px 10px; border-radius: 9999px; font-size: 12px; font-weight: 500; }
    .badge-complete { background: var(--accent-light); color: var(--accent); }
    .badge-partial { background: var(--signal-warn-bg); color: var(--signal-warn); }

    /* Coherence Alert Bar */
    .coherence-bar { background: var(--signal-warn-bg); border-bottom: 1px solid rgba(193,122,40,0.2); padding: 10px 40px; font-size: 13px; color: var(--signal-warn); display: none; align-items: center; gap: 12px; }
    .coherence-bar.has-flags { display: flex; }
    .coherence-bar .count { font-family: 'IBM Plex Mono', monospace; font-weight: 600; }

    /* Tab Nav */
    .tab-nav { position: sticky; top: 0; z-index: 100; background: var(--surface); border-bottom: 1px solid var(--border); padding: 0 40px; display: flex; gap: 0; overflow-x: auto; box-shadow: var(--shadow-sm); }
    .tab-nav button { background: none; border: none; padding: 14px 20px; font-family: 'Outfit', sans-serif; font-size: 13px; font-weight: 500; color: var(--ink-muted); cursor: pointer; border-bottom: 2px solid transparent; transition: all 200ms var(--ease-out); white-space: nowrap; display: flex; align-items: center; gap: 8px; }
    .tab-nav button:hover { color: var(--ink-soft); }
    .tab-nav button.active { color: var(--accent); border-bottom-color: var(--accent); }
    .tab-nav button .layer-num { display: inline-flex; align-items: center; justify-content: center; width: 20px; height: 20px; border-radius: 50%; background: var(--bg-deep); font-size: 11px; font-family: 'IBM Plex Mono', monospace; font-weight: 600; color: var(--ink-muted); }
    .tab-nav button.active .layer-num { background: var(--accent); color: white; }

    /* Main */
    .main-content { max-width: 1200px; margin: 0 auto; padding: 32px 40px; }
    .tab-panel { display: none; animation: fadeIn 300ms var(--ease-out); }
    .tab-panel.active { display: block; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(4px); } to { opacity: 1; transform: translateY(0); } }

    /* Element Card */
    .element-card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-lg); padding: 28px 32px; margin-bottom: 20px; box-shadow: var(--shadow-sm); }
    .element-card-header { display: flex; align-items: flex-start; gap: 12px; margin-bottom: 16px; padding-bottom: 14px; border-bottom: 1px solid var(--border); flex-wrap: wrap; }
    .element-card-header h3 { font-family: 'Instrument Serif', serif; font-size: 22px; font-weight: 400; flex: 1; min-width: 200px; }
    .type-badge { padding: 3px 10px; border-radius: 9999px; font-size: 11px; font-family: 'IBM Plex Mono', monospace; font-weight: 600; text-transform: uppercase; letter-spacing: 0.03em; }
    .type-process_pattern { background: #e8f0fa; color: #2d5a8a; }
    .type-info_architecture { background: #f0e8fa; color: #6a2d8a; }
    .type-visual_pattern { background: #fae8f0; color: #8a2d5a; }
    .type-interaction_pattern { background: #faf0e8; color: #8a5a2d; }
    .type-emotional_element { background: #e8faf0; color: #2d8a5a; }
    .type-validation_strategy { background: var(--bg-deep); color: var(--ink-soft); }
    .priority-badge { padding: 3px 10px; border-radius: 9999px; font-size: 11px; font-family: 'IBM Plex Mono', monospace; font-weight: 600; }
    .priority-high { background: var(--signal-danger-bg); color: var(--signal-danger); }
    .priority-medium { background: var(--signal-warn-bg); color: var(--signal-warn); }
    .priority-low { background: var(--bg-deep); color: var(--ink-muted); }

    /* Phase Tags */
    .phase-tags { display: flex; gap: 6px; flex-wrap: wrap; margin-bottom: 16px; }
    .phase-tag { padding: 2px 8px; border-radius: var(--radius-sm); font-size: 11px; font-family: 'IBM Plex Mono', monospace; background: var(--accent-light); color: var(--accent); }

    /* Problem/Solution */
    .ps-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin-bottom: 16px; }
    .ps-box { padding: 14px 16px; border-radius: var(--radius-md); font-size: 14px; }
    .ps-box.problem { background: var(--signal-danger-bg); border-left: 3px solid var(--signal-danger); }
    .ps-box.solution { background: var(--signal-success-bg); border-left: 3px solid var(--signal-success); }
    .ps-box label { display: block; font-size: 11px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; color: var(--ink-muted); margin-bottom: 4px; font-family: 'IBM Plex Mono', monospace; }
    @media (max-width: 700px) { .ps-grid { grid-template-columns: 1fr; } }

    /* Evidence */
    .evidence-toggle { background: none; border: 1px solid var(--border); border-radius: var(--radius-sm); padding: 6px 14px; font-size: 12px; font-family: 'IBM Plex Mono', monospace; cursor: pointer; color: var(--ink-muted); transition: all 150ms; }
    .evidence-toggle:hover { border-color: var(--accent); color: var(--accent); }
    .evidence-list { display: none; margin-top: 12px; }
    .evidence-list.open { display: block; }
    .evidence-item { padding: 10px 14px; margin: 6px 0; background: var(--surface-warm); border: 1px solid var(--border); border-radius: var(--radius-sm); font-size: 13px; }
    .evidence-item .source { font-family: 'IBM Plex Mono', monospace; font-size: 11px; color: var(--accent); font-weight: 600; margin-bottom: 4px; }
    .evidence-item .quote { color: var(--ink-soft); font-style: italic; }
    .evidence-item .insight { color: var(--ink); margin-top: 4px; }

    /* Layer-specific fields */
    .extra-fields { margin-top: 16px; display: grid; gap: 8px; }
    .extra-field { font-size: 13px; }
    .extra-field label { font-weight: 600; color: var(--ink-soft); font-size: 12px; }
    .extra-field .value { color: var(--ink); }

    /* Coherence sections */
    .coherence-section { margin-bottom: 28px; }
    .coherence-section h3 { font-family: 'Instrument Serif', serif; font-size: 20px; font-weight: 400; margin-bottom: 12px; }
    .reinforcement-card { padding: 14px 16px; margin: 8px 0; border-radius: var(--radius-md); background: var(--signal-success-bg); border-left: 4px solid var(--signal-success); font-size: 14px; }
    .contradiction-card { padding: 14px 16px; margin: 8px 0; border-radius: var(--radius-md); background: var(--signal-danger-bg); border-left: 4px solid var(--signal-danger); font-size: 14px; }
    .extension-card { padding: 14px 16px; margin: 8px 0; border-radius: var(--radius-md); background: var(--signal-info-bg); border-left: 4px solid var(--signal-info); font-size: 14px; }
    .card-label { font-family: 'IBM Plex Mono', monospace; font-size: 11px; font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; margin-bottom: 4px; }

    /* Coverage Map */
    .coverage-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(130px, 1fr)); gap: 10px; margin: 16px 0; }
    .coverage-cell { padding: 12px; border-radius: var(--radius-md); text-align: center; border: 1px solid var(--border); }
    .coverage-cell .phase-name { font-family: 'IBM Plex Mono', monospace; font-size: 11px; font-weight: 600; color: var(--ink-muted); margin-bottom: 4px; }
    .coverage-cell .count { font-size: 24px; font-weight: 700; }
    .coverage-cell .level { font-size: 11px; color: var(--ink-muted); }
    .coverage-none { background: var(--signal-danger-bg); }
    .coverage-thin { background: var(--signal-warn-bg); }
    .coverage-moderate { background: var(--signal-info-bg); }
    .coverage-strong { background: var(--signal-success-bg); }

    /* Journey Context phase cards */
    .phase-card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius-md); padding: 20px; margin-bottom: 12px; }
    .phase-card h4 { font-family: 'IBM Plex Mono', monospace; font-size: 13px; font-weight: 600; color: var(--accent); margin-bottom: 8px; text-transform: uppercase; }
    .phase-card p { font-size: 14px; color: var(--ink-soft); margin-bottom: 6px; }
    .phase-card .risk { font-size: 12px; font-family: 'IBM Plex Mono', monospace; padding: 2px 8px; border-radius: 9999px; display: inline-block; margin-top: 6px; }
    .risk-critical { background: var(--signal-danger-bg); color: var(--signal-danger); }
    .risk-high { background: var(--signal-warn-bg); color: var(--signal-warn); }
    .risk-medium { background: var(--signal-info-bg); color: var(--signal-info); }
    .risk-low { background: var(--bg-deep); color: var(--ink-muted); }

    /* Responsive + Print */
    @media (max-width: 768px) { .report-header, .main-content, .tab-nav, .coherence-bar { padding-left: 20px; padding-right: 20px; } }
    @media print { .tab-nav, .coherence-bar { display: none; } .tab-panel { display: block !important; page-break-inside: avoid; } body { background: white; } }
  </style>
</head>
<body>

  <!-- Data injection points -->
  <!-- INJECT:run-config -->
  <script id="run-config" type="application/json">{"run_id":"2026-02-19_1103","process_type":"design-stack","journey_type":"guest","lens":{"call_file":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt","book_chapters":"Choice Architecture — Stimulus-Response Compatibility, Make It Easy, Defaults, Expect Error, Give Feedback, Understanding Mappings, Structure Complex Choices, Incentives"},"status":"pending","started_at":"2026-02-19T20:00:00Z","element_id_prefix":"ds-ui-1103"}</script>
  <!-- INJECT:layer-0 -->
  <script id="data-layer-0" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt","lens_summary":"This lens reveals how a guest with a mismatched need (short-term, immediate housing for a visiting family member) encounters a platform whose choice architecture fails to qualify, redirect, or retain her before the human-agent call — exposing critical gaps in discovery-phase filtering, stimulus-response compatibility in service messaging, and the absence of smart defaults for ineligible prospects."},"phases":{"discovery":{"what_this_lens_reveals":"Sophie found Split Lease through some channel (not specified in the transcript) and called in with a specific, time-sensitive need: a one-month apartment in New York for a visiting family member, needed 'almost next week.' The call reveals that nothing in the discovery experience communicated Split Lease's minimum commitment (6 weeks) or minimum lead time (3 weeks) before Sophie invested the effort of making a phone call. The Nudge chapter on Stimulus-Response Compatibility directly applies: the signals Sophie received during discovery (whatever led her to call) were incompatible with the actual service constraints. She received a stimulus that said 'flexible housing' but the required response was '6-week minimum commitment with 3 weeks lead time.' This is the equivalent of Thaler's door handles that say 'pull' when you need to push. The Make It Easy principle is also violated in reverse: the platform made it easy for an ineligible prospect to reach a human agent, wasting both parties' time, instead of making it easy for her to self-qualify or self-disqualify before calling.","user_state":{"emotional_state":"Urgent and purposeful — Sophie has a concrete, time-bound need (family member visiting in May). She is not browsing; she is trying to solve a problem quickly.","knowledge_level":"Very low — Sophie does not understand Split Lease's co-tenancy model, minimum commitment, or lead time requirements. She appears to think it is a standard short-term rental service.","commitment_level":"Ready to act for the wrong service — she has a real need and is willing to commit to a one-month rental, but this does not match what Split Lease offers.","data_available":"Only that she found Split Lease through some external channel and called in. No website interaction is described. She is looking on behalf of a family member, not for herself."},"dropout_risk":{"level":"critical","reasons":["Service constraints (6-week minimum, 3-week lead time) are invisible during discovery, causing 100% dropout for short-term seekers who reach the call stage","No self-qualification mechanism exists before the call — the guest cannot determine eligibility without human interaction","The guest is acting as a proxy for the actual user (a visiting family member), adding a layer of indirection that makes the mismatch harder to catch"],"evidence":"Sophie Charvet call, 0:26-1:00: 'I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?' — The agent must manually explain constraints that should have been surfaced before the call."},"key_quotes":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks.","relevance":"Reveals that the core service constraints — minimum lead time and minimum commitment duration — are only communicated during the human call, not during discovery. This is a stimulus-response incompatibility: the discovery signal says 'we can help with housing' but the actual requirement is '6 weeks minimum, 3 weeks from now.'"},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","relevance":"Directly explains why Sophie called: the discovery-phase signals she received were inconsistent with the actual service requirements. The stimulus (flexible housing platform) was incompatible with the required response (commit to 6+ weeks with 3 weeks lead time)."},{"source":"nudge-choice-architecture.txt, Make It Easy section","quote":"Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.","relevance":"The platform should remove the obstacle of ambiguity about eligibility. A simple upfront qualifier (minimum stay, lead time) would channel eligible guests forward and ineligible guests to alternatives — facilitating good behavior for both segments."}]},"search":{"what_this_lens_reveals":"This lens reveals a complete absence of the search phase for this guest. Sophie never reached the search phase because she called directly (or was routed to a call) without browsing listings. However, the Nudge chapter on Structure Complex Choices and Understanding Mappings reveals what the search phase should do for guests like Sophie: help them quickly map their needs (duration, timing, flexibility) onto the platform's actual offerings. Tversky's 'elimination by aspects' strategy — where people set cutoff criteria and eliminate non-matching options — is exactly what a well-designed search would enable. Sophie's minimum cutoff (one month, starting almost immediately) would have eliminated all Split Lease options instantly if surfaced in a search interface, saving her the call entirely. The absence of this filtering mechanism means the platform relies entirely on human agents to perform the qualification that choice architecture should handle automatically.","user_state":{"emotional_state":"Not reached — Sophie bypassed search entirely and went straight to a phone call.","knowledge_level":"Zero familiarity with available listings or the co-tenancy model.","commitment_level":"Would have been high if matching options existed — she had a concrete need and was ready to act.","data_available":"No search behavior data exists for this guest. She never interacted with the listing inventory."},"dropout_risk":{"level":"critical","reasons":["The search phase was entirely skipped, meaning no automated qualification occurred","If Sophie had searched, the lack of short-term (under 6-week) options with immediate availability would have produced zero results with no explanation of why","Without guidance on what the platform does offer, an empty search result is indistinguishable from a broken or empty platform"],"evidence":"Sophie Charvet call, 1:09: 'this was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may' — Her search criteria (1 month, May only) would have returned zero results on the platform. The Nudge chapter on Structure Complex Choices (paint store example) shows that presenting options without structure causes worse outcomes — but presenting zero options with no explanation is even worse."},"key_quotes":[{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","quote":"Someone using this strategy first decides what aspect is most important (say, commuting distance), establishes a cutoff level (say, no more than a thirty-minute commute), then eliminates all the alternatives that do not come up to this standard.","relevance":"Sophie's decision process follows Tversky's elimination by aspects: her cutoffs are duration (one month) and timing (May). A well-designed search would let her apply these cutoffs and immediately see that no options match — with an explanation of what would match and when."},{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","quote":"As alternatives become more numerous and more complex, choice architects have more work to do, and are much more likely to influence choices (for better or for worse).","relevance":"When the choice set is zero (no matches), the choice architect's work is to redirect, not abandon. The platform should structure the 'no results' experience to educate about what would match, not leave the guest with a dead end."}]},"listing_evaluation":{"what_this_lens_reveals":"This lens does not directly address the listing evaluation phase. Sophie never reached a specific listing because her need was disqualified at the discovery/call stage. However, the Nudge chapter on Understanding Mappings is highly relevant to what listing evaluation should accomplish: helping guests map listing attributes (photos, price, rules, schedule, co-tenancy arrangement) onto their actual living experience. The book's ice cream vs. medical treatment comparison applies: choosing an ice cream flavor is easy because the mapping between choice and outcome is direct, but choosing a shared living arrangement is complex because the guest must predict what it will be like to share a space on a split schedule — an experience most have never had. The platform needs to make this unfamiliar mapping comprehensible, much like the free taste at the ice cream shop.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached — Sophie never evaluated a specific listing.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"high","reasons":["Even if Sophie had reached this phase, the co-tenancy model is inherently unfamiliar and the mapping from listing description to lived experience is opaque","The concept of sharing a space with a complementary-schedule stranger requires explanation that a standard listing page may not provide"],"evidence":"Sophie Charvet call, 2:10-2:33: 'the way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.' — The agent's verbal explanation of the co-tenancy model is itself convoluted and hard to follow. A listing page must make this mapping far clearer than a phone explanation does."},"key_quotes":[{"source":"nudge-choice-architecture.txt, Understanding Mappings section","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off. One way to do this is to make the information about various options more comprehensible, by transforming numerical information into units that translate more readily into actual use.","relevance":"The co-tenancy model requires guests to mentally translate 'Monday through Friday' and 'shared space, different timeframes' into a concrete living arrangement. Listing evaluation should transform this abstract model into visual, concrete representations — calendars showing which days are theirs, photos showing the space in 'their' configuration."},{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","relevance":"Even the human agent struggles to explain the co-tenancy mapping clearly. If a trained agent fumbles the explanation, a listing page must be designed with extreme clarity to make this unfamiliar model comprehensible."}]},"proposal_creation":{"what_this_lens_reveals":"This lens does not directly address the proposal creation phase. Sophie was disqualified before reaching this stage. However, the Nudge chapter on Defaults is deeply relevant. When a guest creates a proposal, they must configure dates, duration, and days per week — a complex set of choices. The book argues that 'many people will take whatever option requires the least effort, or the path of least resistance,' and that 'if, for a given choice, there is a default option — an option that will prevail if the chooser does nothing — then we can usually expect a large number of people to end up with that option.' This means the proposal creation form should offer smart defaults (e.g., pre-populated based on the guest's search criteria, common configurations for the listing type) rather than presenting a blank form. The book also discusses 'required choice' vs. 'prompted choice' — the proposal form should use prompted choice with sensible defaults rather than forcing guests to configure every parameter from scratch.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"high","reasons":["Configuring a proposal for an unfamiliar co-tenancy arrangement without defaults increases cognitive load and dropout risk","Guests who have never experienced split-schedule living cannot easily determine the right configuration without guidance"],"evidence":"nudge-choice-architecture.txt, Defaults section: 'Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.' — Proposal creation for co-tenancy is exactly this kind of complicated choice."},"key_quotes":[{"source":"nudge-choice-architecture.txt, Defaults section","quote":"Many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the 'yeah, whatever' heuristic. All these forces imply that if, for a given choice, there is a default option — an option that will prevail if the chooser does nothing — then we can usually expect a large number of people to end up with that option.","relevance":"Proposal creation must leverage defaults to guide guests toward viable configurations. Without defaults, guests face a blank-slate problem that triggers inertia and abandonment."},{"source":"nudge-choice-architecture.txt, Defaults section","quote":"The choice architect can force the choosers to make their own choice! This approach has various names, including 'required choice,' 'mandated choice,' and 'active choosing.'... required choosing is often more appropriate for simple yes-or-no decisions than it is for more complex choices.","relevance":"Proposal creation is a complex, multi-parameter choice. Required choice (blank form, fill everything) is inappropriate. Prompted choice with sensible defaults is better."}]},"negotiation":{"what_this_lens_reveals":"This lens does not directly address the negotiation phase. Sophie never created a proposal, so no negotiation occurred. However, the Nudge chapter on Give Feedback is relevant. During negotiation, the host may counter a proposal, and the guest must evaluate modified terms. The book states that 'an excellent way to help Humans improve their performance is to provide feedback' and warns that 'warning systems have to avoid the problem of offering so many warnings that they are ignored.' The negotiation phase should provide clear, actionable feedback about what changed in a counter-proposal, why it changed, and what the implications are for the guest — without overwhelming the guest with information. The chapter on Expect Error also applies: guests may accidentally reject or misunderstand counter-proposals, and the system should be forgiving of such errors.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"medium","reasons":["Counter-proposals introduce new terms that may confuse guests unfamiliar with the co-tenancy model","Without clear feedback about what changed and why, guests may interpret a counter as rejection rather than negotiation"],"evidence":"nudge-choice-architecture.txt, Give Feedback section: 'An excellent way to help Humans improve their performance is to provide feedback. Well-designed systems tell people when they are doing well and when they are making mistakes.' — Negotiation requires feedback that distinguishes 'the host wants to adjust terms' from 'the host rejected you.'"},"key_quotes":[{"source":"nudge-choice-architecture.txt, Give Feedback section","quote":"Warning systems have to avoid the problem of offering so many warnings that they are ignored. If our computer constantly nags us about whether we are sure we want to open that attachment, we begin to click 'yes' without thinking about it.","relevance":"Negotiation feedback must be meaningful and specific — not generic warnings. Each counter-proposal should highlight exactly what changed and what the guest needs to decide, without burying the signal in noise."},{"source":"nudge-choice-architecture.txt, Expect Error section","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","relevance":"In negotiation, a guest might accidentally decline a counter-proposal or misunderstand the terms. The system should allow easy reversal of errors and clearly confirm consequential actions before they become final."}]},"acceptance":{"what_this_lens_reveals":"This lens does not directly address the acceptance phase. Sophie's call ended before any engagement with the platform. However, the Nudge chapter on Expect Error is particularly relevant to acceptance — the moment when payment is authorized and lease documents are sent. The book's discussion of 'postcompletion errors' (forgetting the gas cap after refueling, leaving the ATM card after getting cash) applies directly: after the high-effort decision to accept terms, the guest may neglect critical follow-up steps (reading lease documents, confirming payment details, noting move-in instructions). The system should use forcing functions to ensure these steps are completed, not rely on the guest remembering to do them after the emotional relief of reaching agreement.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"medium","reasons":["Postcompletion errors: after the relief of reaching agreement, guests may neglect critical steps like reviewing lease terms or confirming payment","The acceptance moment is emotionally charged and cognitively depleting, increasing error rates"],"evidence":"nudge-choice-architecture.txt, Expect Error section: 'Leaving the gas cap behind is a special kind of mistake psychologists call a postcompletion error. The idea is that when you have finished your main task, you tend to forget things relating to previous steps.' — Acceptance is a postcompletion moment: the main task (finding and agreeing to housing) feels complete, but critical details (lease review, payment confirmation, move-in prep) still need attention."},"key_quotes":[{"source":"nudge-choice-architecture.txt, Expect Error section","quote":"Another strategy, suggested by Don Norman, is to use what he calls a 'forcing function,' meaning that in order to get what you want, you have to do something else first. So if you have to remove the card in order to get your cash, you will not forget to do so.","relevance":"Acceptance should include forcing functions: the guest cannot proceed to move-in without confirming they have read the lease, acknowledged house rules, and verified payment details. This prevents postcompletion errors at a high-stakes transition."}]},"move_in":{"what_this_lens_reveals":"This lens does not directly address the move-in phase from Sophie's experience. However, the Nudge chapter on Stimulus-Response Compatibility and Give Feedback are highly relevant. Move-in is where the guest's mental model of the co-tenancy arrangement meets physical reality. The stimulus-response principle applies: every physical signal in the space (key handoff procedure, storage areas, shared vs. private zones) must be compatible with the guest's expectations set during listing evaluation. If the listing showed a private bedroom but the guest arrives to find ambiguous shared spaces, that is the equivalent of a door handle that says 'pull' when you need to push. The Give Feedback principle applies to the House Manual and check-in procedures: the guest needs clear, real-time confirmation that they are doing the right things (arrived at the right time, using the right entrance, following the right procedures) rather than discovering errors after the fact.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"high","reasons":["First physical encounter with the co-tenancy arrangement may produce stimulus-response conflicts if the space does not match the listing's implied promise","Without real-time feedback during check-in, guests may make errors (wrong entrance, wrong storage area) that create negative first impressions","The 'Look Right!' principle from the London crosswalks chapter applies: guests entering an unfamiliar arrangement need prominent, context-specific guidance at the exact moment of potential error"],"evidence":"nudge-choice-architecture.txt, Stimulus-Response Compatibility: 'Those doors are bad architecture because they violate a simple psychological principle... stimulus response compatibility. The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action.' — At move-in, every physical and digital signal must be consistent with the guest's expected action. The House Manual must function like London's 'Look Right!' signs — placed exactly where errors are likely to occur."},"key_quotes":[{"source":"nudge-choice-architecture.txt, Expect Error, London crosswalks example","quote":"The city of London tries to help with good design. On many corners, especially in neighbourhoods frequented by tourists, the pavement has signs that say, 'Look right!'","relevance":"Move-in guidance should follow the 'Look Right!' pattern: place guidance at the exact point of potential error. Key handoff instructions at the door, storage labels on shelves, schedule reminders in the shared space calendar — all positioned where the guest will encounter them at the moment of decision."},{"source":"nudge-choice-architecture.txt, Give Feedback section","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","relevance":"The move-in experience should confirm correct actions (check-in photo submitted, arrival notification sent) with positive feedback, not just flag errors. This builds confidence in a novel living arrangement."}]},"active_lease":{"what_this_lens_reveals":"This lens does not directly address the active lease phase from Sophie's experience. However, the Nudge chapter on Incentives and its concept of salience is directly relevant to the ongoing lease experience. The book asks 'Who chooses? Who uses? Who pays? Who profits?' — in the co-tenancy model, the guest chooses the arrangement, the guest and a co-tenant both use the space, the guest pays Split Lease which pays the host, and all three parties (guest, host, platform) profit. This multi-party incentive structure means misalignment is likely: the guest's incentive is comfort and flexibility, the host's is reliable income and property care, and the platform's is retention and fee collection. The salience principle is also critical: during active lease, the salient costs are per-stay (cleaning, arrival hassle, schedule constraints) while the benefits (lower cost than solo rental, flexibility) are diffuse and less salient. The Date Change Tool, cleaning photos, and stay reviews mentioned in the journey definition are all opportunities to make the benefits of the arrangement more salient relative to the per-interaction costs.","user_state":{"emotional_state":"Not reached.","knowledge_level":"Not reached.","commitment_level":"Not applicable.","data_available":"None for this guest at this phase."},"dropout_risk":{"level":"medium","reasons":["Per-stay friction (cleaning photos, arrival notifications, schedule coordination) is highly salient, while the ongoing benefit (affordable flexible housing) is diffuse and easy to take for granted","Incentive misalignment between guest comfort and platform processes (documentation requirements) could erode satisfaction over time","The 'taxi meter' effect from the Incentives chapter: every per-stay action makes the cost of the arrangement salient, while the savings vs. alternatives are invisible"],"evidence":"nudge-choice-architecture.txt, Incentives section: 'every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks. So a behavioral analysis of the incentives of car ownership will predict that people will underweight the opportunity costs of car ownership and possibly other less salient aspects... and may overweight the very salient costs of using a taxi.' — Per-stay tasks (cleaning photos, check-in notifications) are the 'taxi meter' of co-tenancy. The ongoing savings are the invisible 'car ownership cost.'"},"key_quotes":[{"source":"nudge-choice-architecture.txt, Incentives section","quote":"The most important modification that must be made to a standard analysis of incentives is salience. Do choosers actually notice the incentives they face?","relevance":"During active lease, the platform must make the benefits of co-tenancy salient — not just the obligations. Monthly savings summaries, schedule flexibility confirmations, and positive host reviews all serve to counterbalance the salient per-stay friction costs."},{"source":"nudge-choice-architecture.txt, Incentives section","quote":"Who chooses? Who uses? Who pays? Who profits?","relevance":"The co-tenancy model separates these four roles across guest, co-tenant, host, and platform. Each active lease interaction should align these incentives visibly: when the guest sends cleaning photos, the feedback should show how this protects their deposit and builds their reputation — not just that it is a platform requirement."}]}},"cross_phase_patterns":[{"pattern":"Stimulus-Response Incompatibility Between Platform Messaging and Actual Service Constraints","phases_affected":["discovery","search","listing_evaluation","move_in"],"evidence":"Sophie Charvet call, 0:26-1:09: Sophie's expectation (short-term rental, immediate availability) was completely incompatible with the actual service (6-week minimum, 3-week lead time). This incompatibility was only revealed during a human phone call — not through any automated choice architecture. Nudge, Stimulus-Response Compatibility: 'you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.' This pattern recurs: at discovery (messaging doesn't signal constraints), at search (filters don't surface eligibility), at listing evaluation (co-tenancy model is unfamiliar and unexplained), and at move-in (physical space signals may conflict with listing promises)."},{"pattern":"Absence of Smart Defaults Forces Every Guest to Start from Zero","phases_affected":["search","proposal_creation","negotiation","active_lease"],"evidence":"Nudge, Defaults section: 'many people will take whatever option requires the least effort, or the path of least resistance.' Sophie's call shows no pre-qualification defaults existed — she had to call a human to discover basic eligibility. This absence of defaults applies across the journey: search has no pre-set filters based on stated need, proposal creation has no default configurations based on listing norms, negotiation has no default acceptance terms, and active lease has no default schedule templates. Each phase forces the guest to construct their choices from scratch rather than adjusting sensible defaults."},{"pattern":"No Error Recovery Path for Ineligible or Mismatched Prospects","phases_affected":["discovery","search","listing_evaluation"],"evidence":"Sophie Charvet call, 1:25-1:38: 'That's unfortunate that we cannot help you... if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.' The agent offers a polite verbal redirect, but there is no systematic mechanism to capture Sophie's future need, redirect her to appropriate alternatives, or re-engage her when she might qualify. Nudge, Expect Error: 'A well-designed system expects its users to err and is as forgiving as possible.' The 'error' here is not Sophie's — it is the system's failure to expect that ineligible prospects will arrive and to design a forgiving path (redirect, future notification, referral to appropriate services) rather than a dead end."},{"pattern":"The Proxy Guest Problem — Choosing on Behalf of Another","phases_affected":["discovery","search","listing_evaluation","proposal_creation"],"evidence":"Sophie Charvet call, 3:07: 'I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.' Sophie is not the end user — she is searching on behalf of a visiting family member. The Nudge chapter on Incentives asks 'Who chooses? Who uses?' — when the chooser and the user are different people, mappings become harder (the chooser cannot taste the ice cream) and defaults become more important (the chooser cannot evaluate subjective fit). This proxy-guest pattern likely recurs: corporate travel arrangers, family members, relocation agents all may search on behalf of the actual guest, creating a systematic mismatch between chooser knowledge and user needs."},{"pattern":"Channel Factor Friction — Small Obstacles That Block the Entire Journey","phases_affected":["discovery","search","proposal_creation","acceptance"],"evidence":"Nudge, Make It Easy / Channel Factors: 'Lewin argued that similarly tiny factors can create surprisingly strong inhibitors to behavior that people want to take. Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.' The tetanus shot study showed 28% uptake vs. 3% when students were given a map and asked to plan their route — even though they knew where the health center was. In Sophie's journey, the small obstacles are: (1) no upfront eligibility check at discovery, (2) no search filter for minimum commitment, (3) no default proposal templates, (4) no redirect mechanism for ineligible prospects. Each is a tiny channel factor that, if removed, would either qualify the right guests faster or gracefully exit the wrong ones."},{"pattern":"Salience Asymmetry — Costs Are Visible, Benefits Are Invisible","phases_affected":["proposal_creation","active_lease"],"evidence":"Nudge, Incentives / Salience section: 'every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks.' In the co-tenancy model, per-interaction costs (cleaning photos, arrival notifications, schedule coordination, proposal configuration effort) are highly salient because they require active effort at specific moments. The benefits (lower cost than solo rental, schedule flexibility, guaranteed housing) are diffuse and chronic — easy to take for granted. This salience asymmetry means the arrangement can feel burdensome even when it is objectively advantageous, increasing dropout risk during active lease and discouraging proposal creation for new prospects."}],"sources_consulted":["Sophie Charvet - 18 April 2022.txt — Full guest call transcript. Extracted: service constraint mismatch (6-week minimum, 3-week lead time vs. 1-month need), proxy guest pattern (searching for family member), agent's verbal explanation of co-tenancy model, absence of pre-qualification, polite dead-end for ineligible prospect.","nudge-choice-architecture.txt — Full book extract, Chapter 5: Choice Architecture. Extracted: Stimulus-Response Compatibility principle (signals must match desired actions), Make It Easy / Channel Factors (small obstacles block behavior), Defaults (path of least resistance dominates, smart defaults vs. required choice), Expect Error (postcompletion errors, forcing functions, forgiving design), Give Feedback (timely, specific feedback improves performance), Understanding Mappings (help people map choices to outcomes), Structure Complex Choices (elimination by aspects, collaborative filtering, winnowing), Incentives (salience of costs vs. benefits, Who chooses/uses/pays/profits).","journey-types.json — Guest journey phase definitions. Used to map transcript evidence and book principles to the correct phase vocabulary: discovery, search, listing_evaluation, proposal_creation, negotiation, acceptance, move_in, active_lease.","library/elements.json — Existing element library (18,500+ lines, 250+ elements). Consulted to understand existing coverage. Noted: strong coverage of host journey phases (discovery through retention), emerging guest journey coverage. This lens adds unique perspective on ineligible-prospect handling, proxy-guest patterns, and stimulus-response compatibility in service messaging — areas not well covered by existing elements."]}</script>
  <!-- INJECT:layer-1 -->
  <script id="data-layer-1" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"works-001","type":"process_pattern","title":"Upfront Eligibility Disqualification Before Human Contact","journey_phases":["discovery","search"],"problem":"The platform has no automated mechanism to communicate its core service constraints (minimum 6-week commitment, minimum 3-week lead time) before a prospect invests time in a phone call. Sophie called with a 1-month need starting almost immediately and had to be told verbally that she was ineligible. This wastes both the prospect's time and the agent's time. The discovery experience sends a stimulus ('flexible housing') that is incompatible with the required response ('commit to 6+ weeks with 3+ weeks lead time'). Every ineligible prospect who reaches a human agent represents a failure of choice architecture, not a failure of sales.","solution":"Surface hard eligibility constraints (minimum commitment duration, minimum lead time) at the earliest possible touchpoint in the guest discovery flow, before the guest can reach a human agent. This should take the form of a brief qualification gate — not a barrier, but a transparent disclosure. The gate should: (1) State the minimum commitment and lead time in plain language before any call-to-action to speak with an agent. (2) If the guest's stated need falls outside these parameters, immediately redirect to an explanation of what the service does offer and an option to be contacted when their need might match. (3) If the guest's need does match, reinforce the match explicitly ('Your 8-week need starting in June fits our service — here is what to expect next'). The pattern is: disqualify early, redirect gracefully, never waste a human interaction on information that should be automated.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?","insight":"The agent must manually communicate service constraints that should have been surfaced before the call. The entire call exists because no automated qualification occurred during discovery."},{"source":"Sophie Charvet - 18 April 2022.txt, 1:09","type":"guest_call","quote":"This was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may, unfortunately.","insight":"Sophie's need (1 month, May only) was never viable for the platform. She invested effort calling, only to learn in seconds that no match was possible. A pre-call qualifier would have saved both parties this interaction entirely."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","insight":"The discovery-phase stimulus ('flexible housing platform') was incompatible with the required response ('6-week minimum commitment with 3-week lead time'). This is a textbook stimulus-response incompatibility — the equivalent of Thaler's door handles that say 'pull' when you need to push."},{"source":"nudge-choice-architecture.txt, Make It Easy / Channel Factors section","type":"book","quote":"Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.","insight":"The obstacle here is ambiguity about eligibility. Removing it (by stating constraints upfront) facilitates good behavior for both eligible prospects (who proceed with confidence) and ineligible prospects (who self-redirect without wasting time)."}],"priority":"high","user_goal":"Understand within 10 seconds of encountering the platform whether my specific housing need (duration, timing) can be served, so I do not waste time pursuing an incompatible service.","company_goal":"Eliminate unqualified phone calls that consume agent time without conversion potential, redirecting agent effort toward prospects whose needs match the service.","time_budget":"10 seconds to scan eligibility criteria; 30 seconds to complete a self-qualification check if interactive.","anti_goals":["DO NOT hide service constraints behind a call-to-action in hopes of getting the prospect on the phone. An ineligible prospect on a call is a cost, not an opportunity.","DO NOT make the qualification gate feel like rejection. Frame it as helpfully informing: 'Our service works best for stays of 6+ weeks. Here is what we offer.'","DO NOT require the prospect to create an account or provide personal information before learning basic eligibility criteria.","DO NOT use vague language like 'flexible stays' or 'short-to-medium-term housing' that allows ineligible prospects to assume they qualify."],"success_metric":"Reduction in phone calls from prospects with sub-6-week needs by at least 60%, measured by pre-call qualification completions vs. total inbound calls. Secondary: increase in call-to-proposal conversion rate as agent time shifts to qualified prospects."},{"id":"works-002","type":"process_pattern","title":"Graceful Redirect for Ineligible Prospects","journey_phases":["discovery","search"],"problem":"When a prospect's need does not match the service, the current journey ends in a dead end. Sophie was told 'that's unfortunate that we cannot help you' and offered a vague future invitation. There is no mechanism to capture her need for future re-engagement, redirect her to appropriate alternatives, or convert her awareness into a referral channel. The system treats ineligible prospects as lost causes rather than as people whose needs might evolve or who might know others who qualify. The Nudge principle of 'expect error' applies: the 'error' is not the prospect's — it is the system's failure to design a path for the predictable scenario of mismatched prospects arriving.","solution":"Design an explicit redirect path for prospects whose needs fall outside service parameters. This path should: (1) Acknowledge the mismatch clearly and without blame — 'Our minimum is 6 weeks; your need is 1 month. Here is what might work instead.' (2) Offer to capture the prospect's contact information for future outreach when their need might match — 'If you ever need housing for 6+ weeks, we can notify you of options.' (3) Where possible, suggest alternative services or resources relevant to their actual need. (4) Make it easy for the prospect to refer others who might qualify — 'Know someone who commutes weekly? Here is what we do for them.' The pattern is: every prospect interaction, even a mismatch, should produce value — either a future lead, a referral, or goodwill.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The agent's verbal redirect is polite but structureless. There is no mechanism to capture Sophie's email for future contact, no referral to alternative services, no way to convert this interaction into future value. The prospect walks away with nothing actionable."},{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie declines the agent's offer to send more information because her current need does not match. But Sophie lives in New York and might have future needs, or know others who commute. The interaction ends with zero future value captured."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"The 'error' here is not the prospect's mistake but a predictable system event: ineligible prospects will arrive. A well-designed system expects this and has a forgiving, productive path for them rather than a dead end."},{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","type":"book","quote":"As alternatives become more numerous and more complex, choice architects have more work to do, and are much more likely to influence choices (for better or for worse).","insight":"When the choice set is zero (no matching options), the choice architect's work is not finished — it is redirectional. The system should structure the 'no results' experience to educate, redirect, and capture value, not simply present emptiness."}],"priority":"high","user_goal":"When my need does not match this service, understand immediately what would match and whether I should keep this service in mind for future needs or refer others.","company_goal":"Convert every ineligible prospect interaction into at least one of: a future lead (email capture for re-engagement), a referral source (easy sharing mechanism), or brand goodwill (positive impression despite mismatch).","time_budget":"15 seconds to communicate the mismatch and present the redirect options. The prospect should not spend more than 30 seconds on a dead-end interaction.","anti_goals":["DO NOT treat ineligible prospects as failures to be discarded. Every interaction is an investment that should produce some return.","DO NOT force ineligible prospects through a sales pitch for a service they cannot use. Sophie's agent correctly kept it brief; the system should formalize this restraint.","DO NOT collect contact information without a clear, honest value proposition for why the prospect should share it.","DO NOT redirect to generic homepage content. The redirect must acknowledge the specific mismatch and offer specifically relevant alternatives."],"success_metric":"Email capture rate from ineligible prospects (target: 20% of disqualified prospects leave an email for future contact). Secondary: referral rate from ineligible prospects who share the service with others."},{"id":"works-003","type":"process_pattern","title":"Elimination-by-Aspects Search Filters for Core Constraints","journey_phases":["search","listing_evaluation"],"problem":"The platform lacks search filters that allow prospects to quickly apply their hard cutoff criteria (minimum stay duration, move-in date, lead time) and determine whether any options exist. Sophie never reached search at all, but even if she had, the absence of filters matching her cutoff criteria (1-month duration, immediate availability) would have produced zero results with no explanation. Tversky's 'elimination by aspects' strategy — the natural way people narrow large choice sets — requires that the most important cutoff criteria are surfaceable. Without these filters, the platform either returns irrelevant results (failing the guest) or returns nothing (appearing broken or empty).","solution":"Implement search filters aligned with the cutoffs guests naturally apply first: (1) Minimum stay duration — let guests specify their desired length of stay and filter to only listings that accommodate it. (2) Earliest available start date — let guests specify when they need to move in and filter to listings available by that date. (3) When filters produce zero results, do not show an empty page. Instead, explain why no results match ('Our minimum commitment is 6 weeks — your search for 4 weeks returned no matches') and show what would match if the guest adjusted their criteria ('If you could extend to 6 weeks, here are 12 options'). This follows the paint store principle: structure the choice set by the dimensions that matter most to the chooser, and when the set is empty, guide the chooser toward viable alternatives.","evidence":[{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","type":"book","quote":"Someone using this strategy first decides what aspect is most important (say, commuting distance), establishes a cutoff level (say, no more than a thirty-minute commute), then eliminates all the alternatives that do not come up to this standard.","insight":"Sophie's decision process follows Tversky's elimination by aspects: her cutoffs are duration (one month) and timing (May). A well-designed search would let her apply these cutoffs instantly and see that no options match — with guidance on what would match."},{"source":"Sophie Charvet - 18 April 2022.txt, 1:09","type":"guest_call","quote":"This was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may, unfortunately.","insight":"Sophie has clear, non-negotiable cutoff criteria: 1 month, May only. These are exactly the 'aspects' in Tversky's elimination strategy. The platform provides no way for her to apply these criteria in a self-service search."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off.","insight":"Search filters are the mechanism by which guests map their housing needs (duration, timing, location) onto available listings. Without these filters, the mapping is impossible — the guest cannot determine which choices lead to which outcomes."}],"priority":"high","user_goal":"Apply my most important criteria (how long I need housing, when I need it) as filters and instantly see whether this platform has options for me.","company_goal":"Automate prospect qualification at the search level, reducing agent workload on ineligible prospects and increasing the relevance of results shown to eligible prospects.","time_budget":"5 seconds to set primary filters (duration, start date); 3 seconds to scan whether results exist; 10 seconds to understand a 'no results' explanation if filters produce no matches.","anti_goals":["DO NOT show all listings without filters and expect guests to manually check each one for compatibility with their schedule.","DO NOT present a zero-results page without explanation. An empty page with no context is indistinguishable from a broken platform.","DO NOT over-filter by including too many criteria upfront. Start with the two or three cutoffs that matter most (duration, timing, location) and allow progressive refinement.","DO NOT hide the co-tenancy model behind search results. If the guest does not understand that listings involve shared space on complementary schedules, search results will be confusing regardless of filtering."],"success_metric":"Percentage of search sessions where the guest applies at least one filter before viewing listings (target: 80%). Secondary: reduction in zero-result dead-end sessions (target: zero-result pages always show an alternative suggestion)."},{"id":"works-004","type":"process_pattern","title":"Co-Tenancy Model Mapping Through Concrete Representation","journey_phases":["listing_evaluation","proposal_creation"],"problem":"The co-tenancy model — two people sharing the same space on complementary schedules — is inherently unfamiliar. Most guests have never experienced this arrangement and cannot mentally map a listing description onto a lived experience. Even the trained agent struggles to explain it clearly ('the way we do it with the two people was complimentary schedule... somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes'). If a human agent fumbles the verbal explanation, a listing page without explicit visual mapping will fare worse. The Nudge chapter on Understanding Mappings identifies this as the core challenge: complex choices require help translating abstract descriptions into concrete, predictable outcomes — like the free taste at the ice cream shop.","solution":"Transform the abstract co-tenancy model into concrete, visual representations at every touchpoint where the guest must understand what they are choosing. This means: (1) Show a weekly calendar visualization on every listing that displays which days are available to the guest and which are occupied by the co-tenant, making the split schedule tangible rather than conceptual. (2) Use 'before and after' or 'your days vs. their days' visual comparisons to make the shared-space concept concrete. (3) Provide a 'what to expect' narrative that translates the arrangement into daily-life terms: 'You arrive Monday evening. The space is yours until Friday morning. Your co-tenant uses it on weekends.' (4) Offer an equivalent of the ice cream store's free taste: a virtual walkthrough or detailed photo set showing the space as the guest would experience it during their allocated days. The pattern is: never ask the guest to imagine an unfamiliar living arrangement; show it to them in terms they already understand.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The agent's verbal explanation of the co-tenancy model is convoluted and hard to follow. If a trained human struggles to convey this arrangement clearly in conversation, a static listing page must be designed with extreme clarity to make this unfamiliar model comprehensible."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off. One way to do this is to make the information about various options more comprehensible, by transforming numerical information into units that translate more readily into actual use.","insight":"The co-tenancy model requires guests to mentally translate 'Monday through Friday' and 'shared space, different timeframes' into a concrete living arrangement. The platform must transform this abstract schedule into visual, experiential units — calendars, photos of 'their' configuration, daily-life narratives."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"The co-tenancy model is an 'exotic flavor' — most guests have never tried it. The platform needs an equivalent of the free taste: a concrete, sensory preview of what the arrangement actually feels like in daily life, not just an abstract description of how it works."}],"priority":"high","user_goal":"Understand exactly what my day-to-day living experience will be in a co-tenancy arrangement before I commit, without having to imagine something I have never experienced.","company_goal":"Increase listing-to-proposal conversion by reducing the comprehension barrier that causes guests to abandon when they cannot visualize the co-tenancy model.","time_budget":"15 seconds to understand the basic co-tenancy concept from a visual calendar; 60 seconds to review a 'what to expect' narrative or virtual walkthrough.","anti_goals":["DO NOT rely on text-only explanations of the co-tenancy model. If the agent struggled verbally, text-only will be worse.","DO NOT assume guests understand what 'complementary schedule' means. Use plain, concrete language: 'You use the space Monday to Friday. Another guest uses it on weekends.'","DO NOT bury the co-tenancy explanation deep in a listing page. It should be among the first things a guest sees, since it determines whether the entire concept is viable for them.","DO NOT present the co-tenancy model as unusual or experimental. Frame it as a practical, proven arrangement that thousands of commuters use."],"success_metric":"Time-on-listing-page before bounce (target: guests who view the calendar visualization spend at least 30 seconds more than those who do not). Secondary: reduction in agent calls asking 'how does the sharing work?' (target: 40% reduction)."},{"id":"works-005","type":"process_pattern","title":"Smart Defaults for Proposal Configuration","journey_phases":["proposal_creation","negotiation"],"problem":"Creating a proposal for a co-tenancy arrangement requires configuring multiple parameters (dates, duration, days per week, schedule pattern) — a complex, multi-dimensional choice that most guests have no prior experience with. Without defaults, the guest faces a blank-slate problem: they must determine from scratch what a reasonable configuration looks like for an arrangement they have never experienced. Thaler and Sunstein show that when choice is complicated and difficult, people either accept whatever default is present or abandon the process entirely. Required choice (a blank form where every field must be filled) is inappropriate for complex multi-parameter decisions. The current system likely forces exactly this kind of required choice, triggering inertia and abandonment.","solution":"Pre-populate proposal forms with smart defaults based on the listing's common configuration patterns and the guest's expressed search criteria. This means: (1) If the guest searched for 'Monday to Friday, starting June 1,' the proposal should pre-fill with those dates and that schedule. (2) For each listing, calculate the most common successful proposal configuration and offer it as the default: 'Most guests at this listing book Monday-Friday, 8 weeks.' (3) Allow prompted choice rather than required choice: present the default configuration and let the guest adjust specific parameters rather than building from scratch. (4) For parameters the guest has not specified, use the listing's median successful configuration. The pattern is: always start the guest at a viable configuration and let them adjust, never start them at zero.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the 'yeah, whatever' heuristic. All these forces imply that if, for a given choice, there is a default option — an option that will prevail if the chooser does nothing — then we can usually expect a large number of people to end up with that option.","insight":"Proposal creation without defaults means the path of least resistance is abandonment — the only zero-effort option when facing a blank form. Smart defaults change the path of least resistance to a viable proposal, making completion the easy option."},{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.","insight":"Configuring a co-tenancy proposal is exactly this kind of 'arcane setting' problem. Most guests cannot determine the right configuration without guidance. A sensible default (based on common patterns for the listing) eliminates this burden."},{"source":"Sophie Charvet - 18 April 2022.txt, 0:45-1:00","type":"guest_call","quote":"I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that? Is that something which is going to work for you?","insight":"The agent verbally offers what amounts to a 'default configuration' — minimum 6 weeks, 3 weeks lead time. This is the human-conversation equivalent of a smart default: stating the standard parameters and asking the guest to accept or adjust. The digital experience should replicate this pattern without requiring a human."}],"priority":"medium","user_goal":"Start my proposal from a reasonable, pre-filled configuration rather than a blank form, so I only need to adjust what matters to me rather than figure out every parameter from scratch.","company_goal":"Increase proposal completion rate by reducing the cognitive load of configuration, converting more listing views into submitted proposals.","time_budget":"30 seconds to review a pre-filled proposal and confirm or adjust. Compare to the current experience where guests must research, decide, and fill every field (estimated 3-5 minutes if they complete it at all).","anti_goals":["DO NOT present a blank proposal form with no guidance on what typical configurations look like.","DO NOT use defaults that serve the platform's interests over the guest's. Defaults should reflect genuinely common, successful configurations, not the most profitable ones.","DO NOT lock the guest into defaults. Every pre-filled field must be easily adjustable — the default is a starting point, not a constraint.","DO NOT show defaults without context. Label them: 'Most guests at this listing book Monday-Friday for 8 weeks' — so the guest understands why these values were chosen."],"success_metric":"Proposal form completion rate (target: 50% of guests who open a proposal form submit it, up from current baseline). Secondary: median time to complete a proposal (target: under 60 seconds)."},{"id":"works-006","type":"process_pattern","title":"Proxy-Guest Accommodation for Third-Party Searchers","journey_phases":["discovery","search","listing_evaluation","proposal_creation"],"problem":"Sophie was not searching for herself — she was searching on behalf of a visiting family member. The Nudge framework asks 'Who chooses? Who uses?' — when the chooser and the user are different people, the mapping between choice and outcome becomes harder because the chooser cannot directly experience the outcome (they cannot 'taste the ice cream'). The platform has no mechanism to recognize or accommodate proxy guests — people searching on behalf of someone else (family members booking for visitors, corporate travel managers, relocation agents). Proxy guests have incomplete information about the end user's preferences, different urgency patterns, and may not be the ones who ultimately commit to or live in the space.","solution":"Recognize the proxy-guest pattern as a distinct user mode and accommodate it explicitly. This means: (1) Allow the searcher to indicate they are searching on behalf of someone else, which adjusts the flow to ask for the end user's constraints rather than the searcher's. (2) Provide a shareable summary or listing link that the searcher can forward to the actual guest, containing all relevant information in a self-contained format. (3) In the co-tenancy mapping (works-004), emphasize objective, transferable information (calendar, rules, photos, transit time) over subjective descriptions ('cozy,' 'charming') that the proxy cannot evaluate on the end user's behalf. (4) Allow the proposal to be initiated by the proxy but confirmed by the actual guest before commitment. The pattern is: when the chooser is not the user, make the information transferable and the commitment deferrable.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie explicitly identifies herself as a proxy: she is searching for a family member, not herself. She declines the agent's offer to send more information because she is not the end user. This proxy pattern means the platform lost not just Sophie but also her family member — the actual potential guest — because the flow assumed the caller was the user."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Who chooses? Who uses? Who pays? Who profits?","insight":"When the chooser (Sophie) is not the user (her family member), incentive alignment breaks down. The chooser cannot evaluate subjective fit, may have different urgency, and may not follow through on commitments that require the user's participation. The platform must design for this separation."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"A proxy guest cannot 'taste the ice cream' — they cannot directly experience what the arrangement would feel like for the end user. This makes the mapping problem harder and requires the platform to provide objective, transferable information (calendar, transit time, photos) rather than relying on subjective impression."}],"priority":"medium","user_goal":"As someone searching on behalf of another person, easily find and share relevant housing options with the actual guest, without needing to commit on their behalf or evaluate subjective fit I cannot assess.","company_goal":"Capture leads from proxy searchers who would otherwise be lost when the proxy determines they are not the end user, converting proxy interactions into actual guest engagements.","time_budget":"10 seconds to indicate 'I am searching for someone else'; 30 seconds to generate a shareable summary link to send to the actual guest.","anti_goals":["DO NOT assume every visitor to the platform is the end user. Proxy guests are a predictable, recurring pattern (family booking for visitors, corporate travel arrangers, relocation agents).","DO NOT require the proxy to create an account or provide the end user's details to browse listings. Browsing should be frictionless for anyone.","DO NOT allow a proxy to complete a binding commitment without the actual guest's confirmation. The chooser and the committer should be the same person for consequential actions.","DO NOT design listing information that only works when the viewer is the potential resident. Include objective, shareable data (calendar, location, transit, price) that a proxy can meaningfully evaluate and forward."],"success_metric":"Shareable listing link generation rate (target: 10% of listing views generate a share link). Secondary: conversion rate from shared links to actual guest engagement (target: 15% of shared links result in a new prospect interaction)."}]}</script>
  <!-- INJECT:layer-2 -->
  <script id="data-layer-2" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"communicates-001","type":"info_architecture","title":"Constraint-First Disclosure at Discovery Entry Points","journey_phases":["discovery","search"],"problem":"The platform's discovery-phase information architecture buries its hardest eligibility constraints (6-week minimum commitment, 3-week minimum lead time) behind a human phone call. Sophie Charvet invested effort reaching an agent only to learn in seconds that her 1-month, next-week need was entirely outside the service's parameters. The information hierarchy is inverted: the most disqualifying facts are revealed last, after the prospect has already committed attention and effort. Thaler and Sunstein's stimulus-response compatibility principle is violated: the discovery stimulus ('flexible housing') is inconsistent with the actual requirement ('6+ weeks, 3+ weeks out'), causing the prospect to 'blunder' into a dead-end interaction. The information the prospect needs most urgently to make a go/no-go decision is the information presented last.","solution":"Restructure the discovery information hierarchy so that hard service constraints appear before any call-to-action, form, or phone number. The primary information layer at every entry point (landing page, ad, referral link) should state the minimum commitment and lead time in plain, specific language. This is not a barrier; it is stimulus-response alignment. The prospect's automatic system should receive a signal consistent with the actual service: 'Housing for stays of 6 weeks or more, starting 3+ weeks from now.' Prospects whose needs match proceed with confidence. Prospects whose needs do not match self-redirect immediately, without wasting their time or agent time. The pattern is: disqualifying constraints are primary information, not fine print.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?","insight":"The agent reveals the two hardest constraints (3-week lead time, 6-week minimum) verbally during the call. This information should have been the first thing Sophie encountered, not the last. The entire call exists because the information hierarchy at discovery placed constraints below the fold."},{"source":"Sophie Charvet - 18 April 2022.txt, 1:09","type":"guest_call","quote":"This was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may, unfortunately.","insight":"Sophie's need (1 month, May only) was never viable. She could have self-disqualified in 10 seconds if the constraints were visible at discovery. Instead, she invested the effort of a phone call to learn what a heading could have told her."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","insight":"Discovery messaging that says 'flexible housing' when the service requires 6+ week commitment is a stimulus-response mismatch. The signal ('flexible') triggers an action (calling for short-term housing) that is incompatible with the actual service. Placing constraints first aligns stimulus with response."},{"source":"nudge-choice-architecture.txt, Make It Easy / Channel Factors section","type":"book","quote":"Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.","insight":"The obstacle is ambiguity about eligibility. Removing it at the discovery level is a channel factor that facilitates good behavior for both segments: eligible prospects proceed with confidence, ineligible prospects redirect without wasted effort."}],"priority":"high","hierarchy_principle":"Primary: hard eligibility constraints (minimum duration, minimum lead time) in specific numbers. Secondary: service model summary (co-tenancy, complementary schedules). Tertiary: call-to-action or contact option. The prospect must pass through the constraint layer before reaching the engagement layer, because constraints determine whether engagement is even viable.","disclosure_pattern":"Immediate, upfront, unconditional. Constraints are not progressive disclosure material -- they are gate information. Unlike pricing or listing details that benefit from context-building, eligibility constraints have no benefit from delayed revelation. Every second of delay between prospect arrival and constraint visibility is a second of wasted effort for ineligible prospects. Disclose at the earliest pixel of every entry point.","cognitive_load_constraint":"Maximum 2 constraint facts at the primary level: minimum stay duration (e.g., '6 weeks minimum') and minimum lead time (e.g., 'starting 3+ weeks from now'). No more than 15 words total for the constraint statement. The constraint must be scannable in under 5 seconds without requiring the prospect to read a paragraph or click through to a details page.","scan_order":["Minimum stay duration (6+ weeks)","Minimum lead time (3+ weeks from now)","Brief service description (shared housing on complementary schedules)","Call-to-action for qualified prospects"],"exclude":["Pricing details at discovery level -- premature before eligibility is established","Detailed co-tenancy mechanics -- too complex for the constraint gate","Host testimonials or social proof -- irrelevant until the prospect knows they qualify","Specific listing details -- belong in search and listing evaluation, not discovery"]},{"id":"communicates-002","type":"info_architecture","title":"Structured Dead-End Redirect for Zero-Result States","journey_phases":["discovery","search"],"problem":"When a prospect's need does not match the service -- whether determined by a self-qualification check or by a zero-result search -- the information architecture offers nothing. Sophie's call ended with 'That's unfortunate that we cannot help you... if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.' This is a verbal dead end: polite, but structureless. No information is provided about what would match, when the prospect might qualify, or how to stay connected. The Nudge chapter on Structure Complex Choices warns that when the choice set is large, structure matters -- but when the choice set is zero, the absence of structure is even worse. An empty result with no explanation is indistinguishable from a broken platform.","solution":"Design a structured information layer for every dead-end state that transforms 'no results' into an educational redirect. The dead-end screen or interaction must contain three information tiers: (1) Acknowledgment: state the specific mismatch in concrete terms ('Your need is 1 month; our minimum is 6 weeks'). (2) Reframing: show what would match if the prospect adjusted their criteria ('If you could extend to 6 weeks, here are 12 options starting in June'). (3) Future capture: offer a low-friction way to stay connected for when needs might change ('Leave your email and we will notify you when options match your timing'). The pattern is: dead ends are information architecture opportunities, not dismissal points.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The agent's verbal redirect contains no structured information: no specific threshold the prospect would need to meet, no timeline for when they might qualify, no mechanism to capture the contact for future engagement. The redirect is emotionally appropriate but informationally empty."},{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie declines the agent's offer to send information because her current need does not match. But she lives in New York and might have future needs. The dead end captured zero future value because the information offered was generic ('see our website') rather than targeted to her situation."},{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","type":"book","quote":"As alternatives become more numerous and more complex, choice architects have more work to do, and are much more likely to influence choices (for better or for worse).","insight":"When the alternative set is zero, the choice architect's responsibility does not vanish -- it shifts from structuring choices to structuring the redirect. The zero-result state is a choice architecture moment: the prospect must choose between abandoning entirely, adjusting their criteria, or staying connected for the future. That choice deserves structure."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"An ineligible prospect arriving is not a user error -- it is a predictable system event. A forgiving system has a designed path for this event, not a blank wall. The 'error' the system must expect is that some percentage of arrivals will not qualify, and it must be as forgiving (structured, helpful, value-capturing) as possible for them."}],"priority":"high","hierarchy_principle":"Primary: the specific mismatch stated in concrete, comparative terms (your need vs. our minimum). Secondary: what would match if the prospect adjusted (the nearest viable alternative). Tertiary: future connection option (email capture with clear value proposition). The hierarchy moves from diagnosis to remedy to relationship -- never from apology to silence.","disclosure_pattern":"All three tiers should be visible simultaneously on a single screen or in a single interaction beat. This is not progressive disclosure; it is immediate, comprehensive response to a dead-end state. The prospect should not need to click, scroll, or ask a follow-up question to see all three tiers. The dead end must feel like a complete interaction, not an abrupt dismissal.","cognitive_load_constraint":"Maximum 3 information blocks on the dead-end screen: (1) mismatch diagnosis in 1 sentence, (2) nearest alternative in 1 sentence with a number ('12 options starting in June'), (3) email capture field with 1 sentence value proposition. Total cognitive load: under 30 words of text plus 1 input field. No paragraphs, no scrolling, no links to 'learn more.'","scan_order":["Specific mismatch statement (your need vs. our threshold)","Nearest viable alternative with count","Email capture with future-value proposition"],"exclude":["Generic apology language without specific mismatch data","Full service explanation -- the prospect has already determined they do not qualify now","Multiple call-to-action buttons -- the dead-end state should have exactly one action (leave email) plus one exit (close)","Testimonials or social proof -- irrelevant to someone who just learned they cannot use the service right now"]},{"id":"communicates-003","type":"info_architecture","title":"Co-Tenancy Model Mapping Through Visual Schedule Translation","journey_phases":["listing_evaluation","proposal_creation"],"problem":"The co-tenancy model -- two people sharing the same space on complementary schedules -- is an 'exotic flavor' that most guests have never experienced. Even the trained agent struggled to explain it clearly: 'the way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.' This verbal explanation is convoluted. The mapping between the abstract concept ('complementary schedule co-tenancy') and the lived experience ('you arrive Monday evening, the space is yours until Friday, someone else uses it on weekends') is opaque. Thaler and Sunstein's Understanding Mappings principle identifies this as the core challenge: when the mapping between choice and welfare is complex, the choice architect must translate abstract descriptions into concrete, experiential terms -- like the ice cream shop offering a free taste.","solution":"Replace text-based explanations of the co-tenancy model with a visual schedule mapping on every listing page. The primary information element should be a weekly calendar that shows the guest's days in one color and the co-tenant's days in another, making the split immediately tangible. Below the calendar, provide a 'what to expect' narrative in daily-life language: 'You arrive Monday evening. The space is set up for you. You use it through Friday morning. Over the weekend, another guest uses the space.' This is the digital equivalent of the ice cream store's free taste: the guest experiences the arrangement concretely before committing. The pattern is: never explain the model abstractly when you can show it concretely.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The agent's verbal explanation of the co-tenancy model is hard to follow even in real-time conversation. If a trained human fumbles this mapping verbally, a text-only explanation on a listing page will be worse. The information architecture must bypass text explanation entirely and use visual representation."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off. One way to do this is to make the information about various options more comprehensible, by transforming numerical information into units that translate more readily into actual use.","insight":"The co-tenancy schedule is numerical information (days of the week, time blocks) that must be translated into 'units of actual use' -- a visual calendar showing which days are the guest's. This is the same principle as the tire safety rating: raw numbers are meaningless without translation into what matters to the user."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"Co-tenancy is an exotic flavor. The visual schedule calendar is the free taste: it lets the guest 'experience' the arrangement before committing, without having to imagine something they have never done."}],"priority":"high","hierarchy_principle":"Primary: visual weekly calendar showing the guest's days vs. the co-tenant's days (the 'free taste'). Secondary: 'what to expect' narrative in daily-life language (arrival, departure, transitions). Tertiary: detailed house rules and logistics. The guest must understand the schedule split before they can meaningfully evaluate anything else about the listing, because the schedule determines whether the arrangement is even conceptually viable for them.","disclosure_pattern":"The calendar visualization should appear within the first scroll of the listing page -- above price, above photos, above amenities. This is counterintuitive (most rental platforms lead with photos), but for co-tenancy, the schedule split is the most fundamental piece of information. A beautiful apartment is irrelevant if the schedule does not work. After the guest has processed the calendar (estimated 10-15 seconds), progressively reveal: (1) daily-life narrative, (2) photos, (3) pricing, (4) amenities, (5) detailed rules.","cognitive_load_constraint":"The calendar visualization should use no more than 7 horizontal blocks (one per day of the week), with 2 colors (guest days, co-tenant days) and minimal text labels. Maximum 3 sentences in the 'what to expect' narrative. No jargon ('complementary schedule,' 'co-tenancy arrangement') -- only plain daily-life language ('your days,' 'the other guest's days'). The entire co-tenancy concept should be communicable in under 15 seconds of visual scanning.","scan_order":["Weekly calendar with colored day blocks (guest vs. co-tenant)","Brief 'what to expect' narrative in daily-life terms","Listing photos","Price per period","Amenities and house rules"],"exclude":["Abstract explanations of the co-tenancy business model -- the guest does not need to understand the business logic, only the schedule","Legal language about lease structure at the listing evaluation stage","Information about the specific co-tenant (identity, profession) -- this belongs later in the journey if at all","Platform fee structure -- premature until the guest has accepted the co-tenancy concept"]},{"id":"communicates-004","type":"info_architecture","title":"Default-Anchored Proposal Form with Prompted Choice","journey_phases":["proposal_creation","negotiation"],"problem":"Creating a co-tenancy proposal requires configuring multiple parameters (start date, duration, days of the week, schedule pattern) that most guests have no experience with. A blank proposal form is a 'required choice' scenario -- the guest must determine every parameter from scratch for an arrangement they have never experienced. Thaler and Sunstein argue that 'required choosing is often more appropriate for simple yes-or-no decisions than it is for more complex choices' and that 'most users do not want to have to read an incomprehensible manual to determine which arcane setting to select.' A blank co-tenancy proposal form is exactly the kind of arcane, multi-parameter choice where the path of least resistance -- when no default is provided -- is abandonment.","solution":"Pre-populate the proposal form with smart defaults derived from two sources: (1) the guest's search criteria (if they searched for Monday-Friday starting June 1, those values should be pre-filled), and (2) the listing's most common successful configuration (e.g., 'Most guests at this listing book Monday-Friday for 8 weeks'). Present this as prompted choice: the guest sees a complete, viable proposal and adjusts specific fields rather than building from zero. Each pre-filled field should have a brief contextual label explaining the default: 'Suggested based on your search' or 'Most common at this listing.' The pattern is: start the guest at a viable configuration and let them adjust, never start them at a blank form.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the 'yeah, whatever' heuristic. All these forces imply that if, for a given choice, there is a default option -- an option that will prevail if the chooser does nothing -- then we can usually expect a large number of people to end up with that option.","insight":"Without defaults, the path of least resistance on a proposal form is abandonment (close the tab). With smart defaults, the path of least resistance is submission of a viable proposal. Defaults transform the proposal form from a cognitive barrier into a confirmation step."},{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.","insight":"Configuring a co-tenancy proposal (which days, how many weeks, what start date, which schedule pattern) is exactly the kind of 'arcane setting' problem where sensible defaults dramatically reduce cognitive load and abandonment."},{"source":"Sophie Charvet - 18 April 2022.txt, 0:45-1:00","type":"guest_call","quote":"I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that? Is that something which is going to work for you?","insight":"The agent verbally offers the equivalent of a smart default: 'minimum 6 weeks, 3 weeks from now -- does that work?' This is prompted choice in conversation form. The digital proposal form should replicate this pattern: present the standard configuration and ask the guest to confirm or adjust."}],"priority":"medium","hierarchy_principle":"Primary: pre-filled proposal summary showing all parameters at once (dates, duration, schedule, estimated price) as a single reviewable block. Secondary: individual editable fields with contextual labels explaining each default. Tertiary: 'why this configuration' tooltip or footnote with data source ('based on 34 successful proposals at this listing'). The guest should be able to scan and approve the entire proposal without editing a single field, then drill into specifics only if something does not fit.","disclosure_pattern":"Present the full pre-filled proposal as a single visible block (not a multi-step wizard). The guest's first view should be the complete proposed configuration, not a sequence of individual parameter selections. This follows the prompted choice model: show the whole and let the guest react, rather than forcing them to construct piece by piece. If the guest modifies any parameter, immediately show the impact on other fields (e.g., changing duration updates estimated total price). Progressive disclosure applies only to explanatory detail (why these defaults), not to the core proposal parameters.","cognitive_load_constraint":"Maximum 5 editable parameters visible at once: start date, end date (or duration), days of week, schedule pattern, and estimated price. Each parameter should have its default value plus a 1-line contextual label (under 10 words). Total form should be reviewable in under 30 seconds. No multi-page wizards; no 'next step' buttons between parameters; no required fields that lack a pre-filled default.","scan_order":["Complete proposal summary block (all parameters at a glance)","Estimated total price for the proposed configuration","Individual parameter fields with defaults and edit option","Submit/confirm button"],"exclude":["Blank form fields -- every parameter must have a pre-filled default","Multi-step wizard flows that force sequential parameter entry","Legal terms or lease language at the proposal stage -- these belong at acceptance","Co-tenant identity or details -- irrelevant to the proposal configuration"]},{"id":"communicates-005","type":"info_architecture","title":"Forcing-Function Checkpoint Sequence at Acceptance","journey_phases":["acceptance","move_in"],"problem":"Acceptance is a postcompletion moment: the guest's main task (finding and agreeing to housing) feels finished, but critical steps remain (reviewing lease terms, confirming payment details, noting move-in instructions, understanding house rules). Thaler and Sunstein identify postcompletion errors as a specific failure mode: 'when you have finished your main task, you tend to forget things relating to previous steps.' The emotional relief of reaching agreement depletes attention for follow-up details. Without forcing functions, guests will skip lease review, ignore house rules, and arrive at move-in unprepared -- generating support burden and negative first impressions.","solution":"Structure the acceptance-to-move-in transition as a sequence of forcing-function checkpoints where the guest must acknowledge each critical information block before proceeding to the next. The pattern follows Don Norman's ATM card principle: 'if you have to remove the card in order to get your cash, you will not forget to do so.' (1) Lease summary checkpoint: guest must confirm they have reviewed the key terms (not the full legal document -- a 5-point summary of the most important clauses). (2) Payment confirmation checkpoint: guest must verify the amount, schedule, and method before proceeding. (3) Move-in preparation checkpoint: guest must acknowledge arrival instructions, key/access details, and house rules before the move-in date. Each checkpoint should be brief, specific, and framed as preparation for a positive experience -- not as legal burden.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Leaving the gas cap behind is a special kind of mistake psychologists call a 'postcompletion' error. The idea is that when you have finished your main task, you tend to forget things relating to previous steps.","insight":"Acceptance is the 'getting your cash' moment -- the main goal achieved. Everything after (lease review, payment setup, move-in prep) is the 'gas cap' that gets forgotten. The information architecture must prevent this postcompletion error by making critical steps unavoidable."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Another strategy, suggested by Don Norman, is to use what he calls a 'forcing function,' meaning that in order to get what you want, you have to do something else first. So if you have to remove the card in order to get your cash, you will not forget to do so.","insight":"The forcing function principle applies directly: the guest cannot access their move-in details (the 'cash') until they have confirmed their lease understanding (the 'card'). Each critical information block is gated behind the previous one."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","insight":"Each forcing-function checkpoint should provide positive feedback on completion ('Lease reviewed -- you are all set on terms') rather than just blocking progress. The information architecture should make each checkpoint feel like progress toward move-in, not like bureaucratic overhead."}],"priority":"medium","hierarchy_principle":"Primary: the specific action required at this checkpoint (review these 5 lease points, confirm this payment amount). Secondary: positive feedback on completion (checkmark, progress indicator). Tertiary: full detail available on demand (complete lease document, full payment schedule). The checkpoint surfaces only the essential information and gates the detail behind an 'expand' option, not the other way around.","disclosure_pattern":"Sequential, gated disclosure. Each checkpoint reveals only its own information block and requires acknowledgment before the next checkpoint becomes visible. This is the opposite of the proposal form (which should show everything at once) because the acceptance context is different: the guest is cognitively depleted from the decision and will skip anything that is not gated. The sequence is: lease summary > payment confirmation > move-in preparation. Each checkpoint should take under 60 seconds to review and acknowledge.","cognitive_load_constraint":"Maximum 5 bullet points per checkpoint. Each bullet should be under 15 words. No full legal documents at the checkpoint level -- only the 5 most important points, with a 'view full document' link for those who want it. Total time across all 3 checkpoints: under 3 minutes. The checkpoints should feel like a 3-minute preparation ritual, not a 30-minute legal review.","scan_order":["Checkpoint title stating what this step covers","5 key points to review/confirm","Acknowledge button with positive framing ('Got it, next step')","Progress indicator showing position in the sequence"],"exclude":["Full legal lease document at the checkpoint level -- available on demand but not required reading","Detailed house rules beyond the 3-5 most critical ones -- full rules available at move-in","Financial projections or savings comparisons -- the decision is already made; do not re-sell","Information about the co-tenant -- this may generate anxiety at a high-stakes moment"]},{"id":"communicates-006","type":"info_architecture","title":"Proxy-Guest Information Transfer Layer","journey_phases":["discovery","search","listing_evaluation"],"problem":"Sophie was searching on behalf of a visiting family member, not herself. The Nudge framework asks 'Who chooses? Who uses?' -- when the chooser and the user are different people, information architecture faces a compounding challenge: the information must be (1) comprehensible to the proxy who lacks the end user's preferences, (2) transferable so the proxy can share it with the end user, and (3) objective rather than subjective, since the proxy cannot evaluate experiential qualities on the end user's behalf. The current information architecture assumes the viewer is the future resident, relying on subjective descriptions and immersive framing that fails when the viewer is a proxy. Sophie declined the agent's offer to send information ('I won't read that myself') because the information was not structured for forwarding to the actual decision-maker.","solution":"Design a transferable information format -- a 'shareable listing summary' -- that strips subjective framing and presents objective, decision-relevant facts that a proxy can evaluate and forward. This summary should contain: (1) Schedule: which days are available, in calendar format. (2) Location: address and transit times to key destinations (the proxy likely knows where the end user needs to go). (3) Price: total cost for the proposed duration, with no hidden components. (4) Constraints: minimum commitment, lead time, house rules summary. (5) Photos: the space as the guest would experience it during their allocated days. The summary should be shareable via a single link or attachment, self-contained (no login required to view), and formatted for both mobile and desktop scanning. The pattern is: when the chooser is not the user, make the information portable and objective.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie explicitly signals the proxy pattern: she is not the end user and will not consume information designed for the end user. The platform's information architecture assumed the caller would be the reader. When the chooser and the user are different people, the information must be structured for transfer, not personal consumption."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Who chooses? Who uses? Who pays? Who profits?","insight":"When these four roles are split across different people -- Sophie chooses, her family member uses, the family member pays, the platform profits -- information architecture must serve the chooser's transfer needs, not just the user's consumption needs. The proxy needs portable, objective data they can forward to the actual user."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"A proxy cannot 'taste the ice cream' for the end user. This means subjective experiential information ('cozy space,' 'vibrant neighborhood') is useless to the proxy. The information architecture must emphasize objective, transferable data (calendar, location, price, photos) that allows the proxy to filter and the end user to evaluate."}],"priority":"medium","hierarchy_principle":"Primary: objective, filterable facts (schedule calendar, location with transit times, total price). Secondary: visual evidence (photos of the space during the guest's allocated days). Tertiary: experiential detail (neighborhood description, host reviews) available via the shared link for the end user to evaluate directly. The proxy needs facts for filtering and forwarding; the end user needs experience for deciding. The information hierarchy must serve both, in sequence.","disclosure_pattern":"Two-layer disclosure designed for the handoff moment. Layer 1 (proxy-facing): a compact, shareable summary with objective facts that the proxy can scan in 15 seconds and forward with confidence. Layer 2 (end-user-facing): the full listing page accessible via the shared link, with all experiential detail, photos, and reviews. The proxy never needs to see Layer 2 for the transfer to work. The shareable summary should be generatable from any listing page with a single click -- 'Share this listing.'","cognitive_load_constraint":"The shareable summary should contain no more than 5 information blocks: schedule, location, price, constraints, and 2-3 photos. Total word count under 50 words (excluding photo captions). The summary must render correctly on mobile (the proxy is likely sending it via messaging app). No login walls on the shared link. No interactive elements required to view the summary -- it should be a static, self-contained card.","scan_order":["Schedule calendar (available days highlighted)","Location with transit time to 1-2 key destinations","Total price for the period","Key constraints (minimum stay, lead time)","2-3 photos of the space"],"exclude":["Subjective descriptions that the proxy cannot evaluate ('cozy,' 'charming,' 'perfect for...')","Login-gated content on the shared link -- the end user may not have an account","Platform marketing language -- the shared summary is a decision tool, not a sales pitch","Co-tenant details -- irrelevant to the proxy's filtering task and potentially anxiety-inducing for the end user at this stage"]}]}</script>
  <!-- INJECT:layer-3 -->
  <script id="data-layer-3" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"looks-001","type":"visual_pattern","title":"Constraint-Gate Typography Hierarchy","journey_phases":["discovery","search"],"problem":"The platform's hardest eligibility constraints (6-week minimum commitment, 3-week lead time) are invisible during discovery. Sophie Charvet called and invested time only to learn verbally that her 1-month need was ineligible. Visually, this means the most critical qualifying information has no typographic prominence -- it is either absent or buried below engagement CTAs. The visual hierarchy inverts what matters: decorative imagery and brand messaging occupy the eye's first fixation zone, while the constraint data that determines whether the guest should proceed at all has no visual home.","solution":"Establish a distinct typographic treatment for hard service constraints that commands the eye before any call-to-action. Use the mono typeface (IBM Plex Mono) at a prominent size for constraint data -- '6 weeks minimum' and 'Starting 3+ weeks from now' -- placed within the first visual scan zone of every discovery entry point. The mono face signals precision and non-negotiability: these are facts, not marketing copy. Pair with high-contrast ink on a warm surface background to ensure constraints register on the first fixation, before the serif headline or the CTA button. The visual principle is: data that determines eligibility must be typographically louder than data that sells the service.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?","insight":"The constraint data ('three weeks', 'minimum six weeks') exists only in the agent's verbal delivery. There is no visual artifact for these facts. Typography must give them a permanent, prominent visual home."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","insight":"The visual stimulus at discovery must be compatible with the required response. If the visual hierarchy leads with aspirational imagery and buries constraints, the stimulus says 'engage' when the required response for ineligible guests is 'redirect.' Typography hierarchy must align the visual stimulus with the correct action."}],"priority":"high","tokens":{"colors":["ink","surface-warm","accent"],"typography":["IBM Plex Mono, 500 weight, --text-lg (18px) for constraint values","Outfit, 400 weight, --text-base (14px) for constraint labels"],"spacing":["lg (24px) vertical separation between constraint block and surrounding content","md (16px) padding within constraint block"],"new_tokens_needed":["constraint-bg: a slightly tinted surface color (between surface-warm and accent-light) to create a subtle container for constraint data without appearing like an alert"]},"contrast_requirements":"WCAG AA minimum. IBM Plex Mono constraint text in ink (#1a1714) on surface-warm (#fdfcfa) achieves approximately 15:1 contrast ratio, exceeding AAA. The constraint block background must maintain at least 4.5:1 contrast between text and its background. Do not use accent (#2d5a3d) for constraint text -- it should remain a framing or border element, not the text color, to preserve readability.","visual_hierarchy_rule":"Constraint data occupies Position 1 in the scan order: the eye should encounter '6 weeks minimum / Starting 3+ weeks out' before encountering the brand headline, listing imagery, or the CTA button. Achieve this through vertical placement (above the fold, above the headline), typographic weight (mono at --text-lg vs. serif headline at --text-2xl but positioned below), and a subtle background container (constraint-bg) that creates a visual 'speed bump' before the marketing content.","brand_alignment":"Aligns with taste-model.md principle 'Confident, not flashy' -- stating constraints upfront is a confidence signal, not a barrier. Aligns with 'Trustworthy, not corporate' -- mono type for constraint data signals precision and honesty. Aligns with 'Relentless Personalization' -- the constraint block could adapt based on the prospect's referral source or stated need, showing relevant constraints rather than all constraints."},{"id":"looks-002","type":"visual_pattern","title":"Dead-End Redirect Card Visual Treatment","journey_phases":["discovery","search"],"problem":"When a prospect's need does not match the service, the current experience is a verbal dead end: 'That's unfortunate that we cannot help you.' There is no visual treatment for the zero-result or disqualification state. Visually, dead ends in most platforms use apologetic, diminished styling -- small gray text, empty states with sad illustrations -- that communicates 'you have failed' or 'there is nothing here.' This violates the Nudge principle that systems should expect error and be forgiving. The visual treatment of dead ends should communicate redirection and future value, not dismissal.","solution":"Design a structured redirect card with three visual tiers presented simultaneously on a warm surface. Tier 1 (diagnosis): state the specific mismatch in a high-contrast, left-aligned text block using sans body type -- 'Your need: 1 month. Our minimum: 6 weeks.' Use a subtle two-column comparison layout with the prospect's need on the left and the service threshold on the right, visually distinguishing them with ink-soft vs. accent color. Tier 2 (reframe): show the nearest viable alternative with a count in accent color -- '12 options starting in June for 6+ weeks' -- using the serif headline face to signal that this is a positive offering, not a consolation. Tier 3 (capture): a single email input field with a warm CTA in accent background, framed as a future value proposition. The entire card should feel like a helpful redirect, not a rejection notice.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The verbal redirect is emotionally appropriate but visually structureless. A visual card format would give this redirect permanence, shareability, and the three-tier structure (diagnosis, reframe, capture) that the verbal exchange lacks."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"The visual treatment of dead ends is the visual expression of 'forgiving design.' A forgiving visual system does not use diminished, apologetic styling for predictable mismatch states. It uses warm, structured, helpful styling that treats the prospect as someone worth redirecting, not someone to dismiss."}],"priority":"high","tokens":{"colors":["surface-warm","ink","ink-soft","accent","accent-light","border"],"typography":["Outfit, 400 weight, --text-base for mismatch diagnosis text","Instrument Serif, 400 weight, --text-xl for the reframe headline (nearest alternative)","IBM Plex Mono, 500 weight, --text-sm for the specific numbers ('6 weeks', '12 options')"],"spacing":["xl (40px) vertical padding around the card","lg (24px) between the three tiers","md (16px) horizontal padding within the card"],"new_tokens_needed":["redirect-card-bg: a warm, distinct surface color that differentiates the redirect card from the page background without using signal-warn or signal-danger tones -- something between surface-warm and accent-light"]},"contrast_requirements":"WCAG AA minimum for all text within the card. The mismatch diagnosis text (ink on redirect-card-bg) must achieve at least 4.5:1. The reframe headline in accent (#2d5a3d) on the card background must also achieve 4.5:1 -- test carefully since green on warm off-white can fail. The email input field must meet standard form accessibility: visible border (border-strong), label text at 4.5:1 contrast, and focus state using accent.","visual_hierarchy_rule":"The eye should process the card in three beats: (1) the mismatch numbers catch the eye first because they use mono type in a larger weight than surrounding text, (2) the reframe headline in serif draws the eye next as the largest text element in the card, (3) the email capture CTA in accent background is the terminal action. The card should feel like a complete interaction, not a fragment -- no 'learn more' links, no secondary navigation, just three tiers and one action.","brand_alignment":"Aligns with 'Warm, not cold' -- the redirect card uses warm surface colors and avoids the cold, diminished styling typical of error states. Aligns with 'Trustworthy, not corporate' -- stating the specific mismatch in concrete numbers builds trust even in rejection. Aligns with 'Premium-accessible' -- a well-designed redirect card signals that the brand values every visitor's time, not just converting visitors."},{"id":"looks-003","type":"visual_pattern","title":"Co-Tenancy Calendar Visualization Color System","journey_phases":["listing_evaluation","proposal_creation"],"problem":"The co-tenancy model -- two people sharing one space on complementary schedules -- is an unfamiliar arrangement that even the trained agent struggled to explain verbally: 'somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.' This model cannot be communicated through text. It requires a visual calendar where the guest's days and the co-tenant's days are chromatically distinct. The visual challenge is creating a two-tone day system that is immediately legible, colorblind-accessible, and brand-aligned without creating a 'busy' or anxiety-inducing calendar feel.","solution":"Use a 7-column weekly calendar grid where the guest's available days use the accent color (forest green) as a fill with white text, and the co-tenant's days use a neutral muted fill (bg-deep or border) with ink-muted text. The chromatic contrast between forest green (the guest's days, the actionable days) and warm neutral (the co-tenant's days, the non-actionable days) creates an immediate visual split without requiring the guest to read labels or legends. The guest's days should feel 'active' and 'yours' through color saturation and slight elevation (a subtle shadow-sm), while the co-tenant's days should feel 'present but receded' through desaturation and flatness. The day cells should use the existing day-badge component pattern (32px circles) but scaled to a larger format (48px or --input-height-lg) for the listing calendar context. Each day should display only the day abbreviation (M, T, W, Th, F, Sa, Su) in the sans typeface.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The verbal explanation is incoherent. A visual calendar would replace this entire explanation with a single glance: green days are yours, gray days are not. The color system carries the communication burden that language cannot."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off. One way to do this is to make the information about various options more comprehensible, by transforming numerical information into units that translate more readily into actual use.","insight":"The co-tenancy schedule is numerical/temporal information (days of the week) that must be transformed into visual units of 'actual use.' A color-coded calendar translates days-of-the-week data into an immediately comprehensible visual map of the guest's living arrangement."}],"priority":"high","tokens":{"colors":["accent (guest days fill)","accent-light (guest days hover/focus)","bg-deep (co-tenant days fill)","ink-muted (co-tenant days text)","surface (calendar background)"],"typography":["Outfit, 600 weight, --text-sm-md for day abbreviations inside circles","Outfit, 400 weight, --text-sm for 'Your days' / 'Other guest' legend labels"],"spacing":["sm (8px) gap between day circles","md (16px) padding around the calendar grid","lg (24px) vertical margin below the calendar before the next content block"],"new_tokens_needed":["calendar-guest-active: a slightly brighter variant of accent (#3a7a52 / accent-bright) for the active/selected state of guest days to distinguish from the default accent fill","calendar-cotenant-fill: a specific neutral that is warmer than standard gray but clearly receded -- could be bg-deep (#eae7e1) or a new token between bg-deep and border"]},"contrast_requirements":"WCAG AA for both day states. Guest days: white text (#ffffff) on accent (#2d5a3d) achieves approximately 7.5:1 -- passes AAA. Co-tenant days: ink-muted (#8a857e) on bg-deep (#eae7e1) achieves approximately 3.2:1 -- this fails AA for normal text. Solution: use ink-soft (#4a4640) for co-tenant day text, which achieves approximately 5.5:1 on bg-deep. Alternatively, increase co-tenant cell size and use --text-lg to qualify for the large-text 3:1 threshold. Colorblind accessibility: the green vs. warm-gray distinction is primarily a saturation/value difference, not a hue difference, so it remains legible for protanopia and deuteranopia. Add a subtle visual differentiator beyond color: guest day circles get shadow-sm, co-tenant day circles remain flat.","visual_hierarchy_rule":"The guest's days dominate the calendar visually through chromatic saturation (accent green vs. neutral gray), slight elevation (shadow), and label association ('Your days' legend in accent color). The co-tenant's days are visible but receded. The calendar as a whole should be the first major visual element on the listing page -- above photos, above price -- because it determines whether the arrangement is conceptually viable for the guest before any other attribute matters.","brand_alignment":"Aligns with 'Warm, not cold' -- the warm neutral for co-tenant days avoids the cold clinical feel of standard gray calendars. Aligns with 'Trustworthy, not corporate' -- the calendar is transparent about the sharing arrangement, showing the co-tenant's days rather than hiding them. Aligns with 'Premium-accessible' -- the day badge circle pattern is elegant and familiar (from the existing design system) while being functionally informative. Aligns with 'Relentless Personalization' -- the calendar is inherently personalized, showing the specific days available to this guest in this listing."},{"id":"looks-004","type":"visual_pattern","title":"Smart Default Pre-Fill Visual Distinction","journey_phases":["proposal_creation","negotiation"],"problem":"Creating a co-tenancy proposal requires configuring multiple unfamiliar parameters (start date, duration, days of week, schedule pattern). A blank form is visually a wall of empty inputs -- each one a micro-decision the guest must make without context. Thaler and Sunstein show that blank forms trigger abandonment because the path of least resistance is to close the tab. The visual challenge is: how do you make a pre-filled default value look different from a user-entered value, so the guest understands that the form is helping them (providing a starting point) rather than constraining them (locking in values they did not choose)?","solution":"Pre-fill all proposal form fields with smart defaults and visually distinguish them from user-edited values using a subtle typographic and color shift. Default values should render in ink-muted (#8a857e) with an italic style and a small contextual label below each field in ink-ghost, explaining the source of the default ('Based on your search' or 'Most common at this listing'). When the guest edits a field, the value shifts to ink (#1a1714) in regular weight and the contextual label fades or updates to 'Custom.' This creates a visual gradient from 'suggested' (muted, italic) to 'confirmed' (full ink, regular weight) that communicates helpfulness without rigidity. The entire proposal should be visible as a single block -- not a multi-step wizard -- so the guest can scan all defaults at once and decide which to accept and which to change.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the 'yeah, whatever' heuristic.","insight":"Without visual defaults, the path of least resistance is abandonment (empty form). With visually present defaults, the path of least resistance is acceptance of a viable configuration. The visual treatment of defaults literally changes the path of least resistance."},{"source":"Sophie Charvet - 18 April 2022.txt, 0:45-1:00","type":"guest_call","quote":"I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that? Is that something which is going to work for you?","insight":"The agent verbally offers a default configuration: minimum 6 weeks, 3 weeks from now. This is prompted choice in conversation. The proposal form should replicate this visually -- present the standard configuration and let the guest confirm or adjust."}],"priority":"medium","tokens":{"colors":["ink-muted (default values before editing)","ink (user-edited values)","ink-ghost (contextual labels below default fields)","accent-light (subtle background tint for default fields)","surface (form background)"],"typography":["Outfit, 400 italic, --text-md for default pre-filled values","Outfit, 500 weight, --text-md for user-edited values","Outfit, 400 weight, --text-xs for contextual default source labels","IBM Plex Mono, 400 weight, --text-md for numerical values (dates, durations, prices)"],"spacing":["sm (8px) between the field value and the contextual label below","md (16px) between individual form fields","lg (24px) padding around the form card","xl (40px) between the form card and the submit button"],"new_tokens_needed":["default-field-bg: a barely-there tint (possibly accent-light at 30% opacity or a new token between surface and accent-light) that distinguishes pre-filled fields from empty/edited fields without creating visual noise"]},"contrast_requirements":"WCAG AA for all text states. Default values in ink-muted (#8a857e) on surface (#ffffff) achieve approximately 3.7:1 -- this fails AA for normal text. Two solutions: (1) use a slightly darker muted tone (ink-soft #4a4640 achieves 7.3:1) but in italic to maintain the 'suggested' feel, or (2) use ink-muted but at --text-md (16px) size, which visually compensates even if technically requiring AA large-text ratio of 3:1 for 18px+. Recommendation: use ink-soft (#4a4640) in italic for defaults to maintain both the 'suggested' visual distinction and WCAG AA compliance. Contextual labels in ink-ghost (#bdb8b0) on surface achieve approximately 2.3:1 -- acceptable only if treated as non-essential supplementary text and accompanied by an accessible alternative (aria-description).","visual_hierarchy_rule":"The proposal form as a whole should read as a single, reviewable block -- the eye takes in all five parameters (start date, end date, days, pattern, price estimate) simultaneously, not sequentially. Within the block, the estimated total price should be the most visually prominent element (mono typeface, --text-xl, accent color) because it is the single number that summarizes the entire proposal. Default values should be visually present but slightly receded (muted color, italic) compared to user-edited values (full ink, regular weight), creating a visual 'confirmation gradient' from left-to-right or top-to-bottom.","brand_alignment":"Aligns with 'Confident, not flashy' -- the pre-filled form signals confidence in the platform's knowledge of what works, without being prescriptive. Aligns with 'Premium-accessible' -- a pre-filled form removes barriers for all guests, not just experienced ones. Aligns with 'Relentless Personalization' -- defaults derived from the guest's search criteria and the listing's patterns are inherently personalized, not generic."},{"id":"looks-005","type":"visual_pattern","title":"Postcompletion Checkpoint Progress Visual","journey_phases":["acceptance","move_in"],"problem":"After accepting a proposal, the guest enters a postcompletion state where the main cognitive task (finding housing) feels finished but critical follow-up steps remain: reviewing lease terms, confirming payment, preparing for move-in. Thaler and Sunstein identify postcompletion errors (leaving the gas cap, forgetting the ATM card) as a predictable failure mode when the main task is done. Visually, the challenge is: the acceptance moment triggers emotional relief that depletes attention, and anything presented after the 'congratulations' screen will be scanned with minimal engagement. The visual treatment must use forcing functions and progress indicators that make skipping impossible without making the experience feel punitive.","solution":"Design a sequential checkpoint flow with a horizontal progress bar at the top that shows three clearly labeled steps: Lease Review, Payment Confirmation, Move-In Prep. Each checkpoint is a compact card (maximum 5 bullet points, each under 15 words) with a single acknowledge button. The progress bar uses the accent color for completed steps, a subtle border treatment for the current step, and ink-ghost for upcoming steps. Each checkpoint card appears one at a time -- the next is gated behind acknowledgment of the current one. The acknowledge button uses positive framing ('Got it, next step') in accent background with white text, not punitive framing ('I confirm I have read...'). On completion of all three checkpoints, a final confirmation card in accent-light background with an Instrument Serif headline signals that the guest is genuinely ready for move-in.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Leaving the gas cap behind is a special kind of mistake psychologists call a 'postcompletion' error. The idea is that when you have finished your main task, you tend to forget things relating to previous steps.","insight":"Acceptance is the 'getting your cash' moment. The visual treatment must prevent the postcompletion error of skipping lease review, payment confirmation, and move-in preparation. A gated progress flow is the visual forcing function."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","insight":"Each checkpoint should provide positive visual feedback on completion -- a checkmark animation, the progress bar filling in accent color, a brief 'Done' confirmation. The visual feedback makes each step feel like an accomplishment, not a burden."}],"priority":"medium","tokens":{"colors":["accent (completed steps, acknowledge button)","accent-light (final confirmation card background)","border (current step outline)","ink-ghost (upcoming steps)","surface (checkpoint card background)","ink (checkpoint text)"],"typography":["Outfit, 600 weight, --text-md for checkpoint step labels in the progress bar","Outfit, 400 weight, --text-base for bullet point text within each checkpoint","Instrument Serif, 400 weight, --text-xl for the final 'Ready for move-in' headline","Outfit, 600 weight, --text-base for the acknowledge button text"],"spacing":["xl (40px) vertical padding above and below the entire checkpoint flow","lg (24px) between individual checkpoint cards","md (16px) padding within each checkpoint card","sm (8px) between bullet points within a checkpoint"],"new_tokens_needed":["progress-complete: could reuse accent (#2d5a3d) but may need a slightly lighter variant for the progress bar fill to avoid overwhelming the horizontal space -- test accent-bright (#3a7a52) as an alternative","checkpoint-active-border: a 2px border in accent or accent-bright to highlight the current step's card without using a full background fill"]},"contrast_requirements":"WCAG AA for all text within checkpoint cards. Bullet text in ink (#1a1714) on surface (#ffffff) exceeds AAA. Acknowledge button text in white (#ffffff) on accent (#2d5a3d) achieves approximately 7.5:1 -- passes AAA. Progress bar labels for completed steps should use accent (#2d5a3d) text, which on bg (#f6f4f0) achieves approximately 6.5:1 -- passes AA. Upcoming step labels in ink-ghost (#bdb8b0) on bg achieve approximately 2.3:1 -- acceptable because these are decorative/supplementary and the progress bar's visual state (filled vs. empty) carries the primary information.","visual_hierarchy_rule":"The progress bar is the first thing the eye sees at the top of the acceptance flow -- it establishes context (three steps, you are here) before any content. Within each checkpoint card, the step title is the most prominent text element, followed by the bullet points, followed by the acknowledge button at the bottom. The button should be the terminal visual element in each card, not competing with the content. After all checkpoints are complete, the final confirmation card should feel visually distinct from the checkpoints (serif headline, accent-light background) to signal a state change from 'processing' to 'ready.'","brand_alignment":"Aligns with 'Warm, not cold' -- the acknowledge button uses positive, warm framing ('Got it, next step') rather than cold legal language. Aligns with 'Trustworthy, not corporate' -- the checkpoint format is transparent about what the guest is confirming, not hiding terms behind a single 'I agree' checkbox. Aligns with 'Confident, not flashy' -- the progress bar is a simple, confident visual element that does not overanimate or draw excessive attention to itself. The spring easing (for the checkmark animation on completion) adds a moment of delight without spectacle."},{"id":"looks-006","type":"visual_pattern","title":"Shareable Listing Summary Card for Proxy Guests","journey_phases":["discovery","search","listing_evaluation"],"problem":"Sophie was searching on behalf of a visiting family member and declined the agent's offer to send information ('I won't read that myself'). The proxy-guest pattern -- where the person browsing is not the person who will live in the space -- requires information that is transferable, objective, and self-contained. Standard listing pages use immersive, subjective framing (hero photos, neighborhood mood, 'cozy' descriptions) designed for the person who will live there. A proxy needs a compact, factual card they can forward via messaging app in seconds. The visual challenge is creating a summary format that is information-dense but scannable, mobile-optimized but not diminished, and brand-consistent but stripped of subjective marketing language.","solution":"Design a shareable listing summary card that renders as a compact, self-contained visual block -- optimized for messaging app previews and mobile screens. The card should contain five information blocks in a fixed vertical stack: (1) a small co-tenancy calendar (7 mini day circles using the looks-003 color system), (2) location with transit time to one or two key destinations in mono type, (3) total price for the period in mono type at a prominent size, (4) key constraints (minimum stay, lead time) in a subtle row, (5) one or two listing photos at a fixed aspect ratio. The card should be generatable from any listing page with a single 'Share this listing' button, require no login to view via the shared link, and render correctly as a link preview in WhatsApp, iMessage, and SMS. Total word count under 50 words. No subjective descriptions, no login gates, no interactive elements -- a static, portable decision artifact.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie explicitly signals the proxy pattern: she will not consume the information herself because she is not the end user. The standard listing page -- designed for immersive browsing by the future resident -- is the wrong visual format for a proxy. A compact, forwardable card is the right format."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Who chooses? Who uses? Who pays? Who profits?","insight":"When the chooser (Sophie) and the user (her family member) are different people, the visual format must serve both. The proxy needs factual, compact data for filtering and forwarding. The end user -- who receives the shared card -- needs enough visual information to decide whether to click through to the full listing. The card must satisfy both in under 15 seconds of viewing."}],"priority":"medium","tokens":{"colors":["surface (card background)","ink (primary text)","ink-soft (secondary text like transit times)","accent (calendar guest-day circles and price highlight)","bg-deep (calendar co-tenant-day circles)","border (card border and section dividers)"],"typography":["IBM Plex Mono, 500 weight, --text-lg for the total price","IBM Plex Mono, 400 weight, --text-sm for transit times and constraint data","Outfit, 600 weight, --text-base for the listing title/area","Outfit, 400 weight, --text-xs for constraint labels"],"spacing":["md (16px) padding within the card","sm (8px) between information blocks","xs (4px) gap between mini calendar day circles"],"new_tokens_needed":["card-share-width: a fixed max-width for the shareable card (approximately 360px or --max-width-sidebar) that optimizes for mobile messaging app preview rendering","card-share-photo-height: a fixed height for the listing photo thumbnail within the card (approximately 120px) to maintain the card's compact form factor"]},"contrast_requirements":"WCAG AA for all text on the card. Price text in ink (#1a1714) on surface (#ffffff) exceeds AAA. Transit time text in ink-soft (#4a4640) on surface achieves approximately 7.3:1 -- passes AA. Mini calendar day circles at small size (24px or smaller) should use the same color system as looks-003 but may need thicker borders or higher contrast fills to remain legible at reduced size. The card border should be border (#e2dfd9) at 1px, providing subtle containment without visual weight.","visual_hierarchy_rule":"The eye should process the card top-to-bottom in five quick fixations: (1) mini calendar strip (immediate visual of the schedule split), (2) location and transit data (is this geographically viable?), (3) price (is this financially viable?), (4) constraints (is this temporally viable?), (5) photo (does this look acceptable?). The price should be the most visually prominent text element on the card (mono, large, possibly accent-colored) because it is the single piece of information most likely to determine whether the proxy forwards the card to the end user.","brand_alignment":"Aligns with 'Confident, not flashy' -- the card is pure information without marketing embellishment. Aligns with 'Trustworthy, not corporate' -- presenting objective facts (calendar, price, transit) rather than subjective descriptions ('charming', 'cozy') builds trust with both the proxy and the end user. Aligns with 'Premium-accessible' -- the card's compact, elegant format signals quality without requiring the viewer to invest time in an immersive listing page."},{"id":"looks-007","type":"visual_pattern","title":"Salience-Balancing Benefit Reinforcement Strip","journey_phases":["active_lease"],"problem":"During the active lease phase, per-stay friction tasks (cleaning photos, arrival notifications, schedule coordination) are highly salient because they require active effort at specific moments. The ongoing benefit of the co-tenancy arrangement (lower cost than solo rental, schedule flexibility) is diffuse and easy to take for granted. Thaler and Sunstein's taxi-meter analogy applies: 'every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks.' Per-stay tasks are the taxi meter of co-tenancy. The arrangement can feel burdensome even when objectively advantageous because the costs are visible and the benefits are invisible. There is no visual treatment that makes the ongoing benefit of the arrangement salient at the moments when per-stay friction is felt.","solution":"At every per-stay friction touchpoint (cleaning photo upload, arrival notification, schedule confirmation), include a compact 'benefit reinforcement strip' -- a single horizontal bar that surfaces one salient benefit data point in mono type on an accent-light background. Examples: 'You have saved $2,340 vs. a solo rental this quarter' or 'Schedule flexibility: you changed dates 3 times this month at no cost.' The strip should be visually lightweight -- a single line of text in a subtle container -- positioned immediately above or below the friction task, so the benefit is salient at exactly the moment the cost is being felt. The data should be real, personalized, and updated dynamically. Use the mono typeface for the number (savings amount, flexibility count) to signal precision and credibility, and the sans typeface for the contextual label.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"The most important modification that must be made to a standard analysis of incentives is salience. Do choosers actually notice the incentives they face?","insight":"The co-tenancy benefit is an incentive the guest does not notice because it is diffuse and chronic. The benefit reinforcement strip makes this incentive visually salient at the moments when per-stay costs are most felt, rebalancing the salience asymmetry."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks.","insight":"Per-stay tasks (cleaning photos, check-in notifications) are the 'taxi meter' of co-tenancy. The benefit reinforcement strip is the visual equivalent of showing 'you saved $X by not owning a car this month' every time the taxi meter runs -- making the invisible benefit salient alongside the visible cost."}],"priority":"medium","tokens":{"colors":["accent-light (strip background)","accent (strip left border or icon)","ink (label text)","accent (benefit number)"],"typography":["IBM Plex Mono, 600 weight, --text-md for the benefit number ('$2,340')","Outfit, 400 weight, --text-sm for the contextual label ('saved vs. solo rental this quarter')"],"spacing":["sm (8px) vertical padding within the strip","md (16px) horizontal padding within the strip","md (16px) vertical margin between the strip and the adjacent friction task"],"new_tokens_needed":[]},"contrast_requirements":"WCAG AA minimum. Benefit number in accent (#2d5a3d) on accent-light (#e8f0eb) achieves approximately 5.2:1 -- passes AA. Label text in ink (#1a1714) on accent-light achieves approximately 13:1 -- exceeds AAA. The strip's accent-light background must be visually distinct from the page background (bg or surface) to register as a deliberate element rather than an accidental background shift -- test for sufficient differentiation on both bg (#f6f4f0) and surface (#ffffff).","visual_hierarchy_rule":"The benefit strip is secondary to the friction task it accompanies -- it should not obstruct or delay the completion of the cleaning photo upload or schedule confirmation. The strip should be scannable in under 3 seconds: the mono number catches the eye first (because it is the most visually distinct element), then the contextual label provides meaning. The strip should feel like a helpful aside, not a modal or interruption. Positioning below the task (not above) ensures the guest completes the task first and absorbs the benefit reinforcement second.","brand_alignment":"Aligns with 'Relentless Personalization' -- the benefit strip uses real, personalized data (actual savings, actual flexibility uses) rather than generic claims. Aligns with 'Warm, not cold' -- the accent-light background and positive framing ('you saved') create a warm, affirming moment during an otherwise transactional task. Aligns with 'Trustworthy, not corporate' -- using mono type for the benefit number signals that this is verified data, not marketing spin. The precision of the number builds trust."}]}</script>
  <!-- INJECT:layer-4 -->
  <script id="data-layer-4" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"behaves-001","type":"interaction_pattern","title":"Inline Eligibility Disqualification Gate","journey_phases":["discovery","search"],"problem":"Prospects with incompatible needs (duration too short, lead time too tight) reach human agents before learning basic service constraints. Sophie Charvet called with a 1-month, next-week need and had to be told verbally she was ineligible. The interaction wastes both parties' time because the platform provides no automated stimulus-response-compatible feedback loop during discovery. The system's first interaction response to a mismatched prospect is a phone call -- the most expensive, least scalable response possible.","solution":"Implement a lightweight, inline eligibility check that responds to the prospect's first expression of need (duration, timing) with immediate, non-blocking feedback about compatibility. When the prospect enters or selects parameters that fall outside service constraints, the UI should respond within 200ms with a clear, warm diagnosis -- not a modal blocker, but an inline state change that transforms the CTA from 'Contact us' to 'See what we offer instead.' The interaction principle is: the system should respond to incompatible inputs the way a good concierge responds -- immediately, helpfully, without requiring the prospect to ask. The response is proportional to the mismatch: a near-miss (5-week need vs. 6-week minimum) gets a softer nudge than a total mismatch (1-week need).","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?","insight":"The agent performs what should be an automated interaction: comparing the prospect's stated need against service constraints and delivering immediate feedback. This comparison takes the agent 34 seconds of verbal processing. An automated gate could deliver the same information in under 200ms."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","insight":"The eligibility gate is a stimulus-response alignment mechanism: when the prospect's input (stimulus) is incompatible with the service, the system's response must immediately signal that incompatibility rather than allowing the prospect to proceed toward a dead-end interaction."},{"source":"nudge-choice-architecture.txt, Make It Easy / Channel Factors section","type":"book","quote":"Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.","insight":"The obstacle is ambiguity about eligibility. The gate removes this obstacle at the earliest interaction point -- no clicking through to a call, no navigating to a FAQ page, no reading fine print. The system responds to the prospect's input with eligibility feedback inline, at the point of input."}],"priority":"high","states":{"default":"The eligibility input fields (desired duration, desired start date) appear as standard form elements with no pre-judgment. The CTA reads 'Explore options' or equivalent. No constraint information is displayed until the prospect provides input.","loading":"After the prospect enters duration or start date, a brief shimmer (150ms) on the constraint feedback area indicates the system is evaluating. This should feel instant -- the shimmer is cosmetic, not blocking. No spinner, no disabled state.","empty":"If the prospect has not yet entered any parameters, the constraint feedback area is absent (not visible as an empty container). The form feels clean and inviting. Constraints appear only in response to input -- they are reactive, not preemptive clutter.","error":"When the prospect's input falls outside service parameters, the feedback area transitions in with a warm, non-alarming state change: the input field border shifts from border (#e2dfd9) to signal-warn (#c17a28), and a diagnosis message appears below in ink-soft on signal-warn-bg. The message is specific and comparative: 'Your need: 1 month. Our minimum: 6 weeks.' No generic error language ('Invalid input'). The CTA transforms from 'Explore options' to 'See alternatives' -- it does not disappear or become disabled.","success":"When the prospect's input matches service parameters, the input field border shifts to accent (#2d5a3d) and a brief confirmation appears: 'We have options for that.' The CTA remains 'Explore options' with increased visual confidence (accent background fills in). The transition from neutral to confirmed should feel like a quiet nod, not a celebration."},"transition_principle":"All state transitions should use the 'out' easing (cubic-bezier(0.16, 1, 0.3, 1)) to feel responsive but not jarring. The transition from default to error or success should feel like the system is thinking alongside the prospect -- a gentle reveal, not a judgment. The incompatibility message should slide in from below (translateY with opacity) rather than appearing abruptly, giving the prospect a moment to register the change before reading. The CTA transformation should crossfade the text label rather than swapping it instantly.","timing":{"response_target":"200ms from input change to feedback display. The evaluation itself is client-side (comparing input against known constraints), so no network latency. The 200ms includes the transition animation start.","easing":"cubic-bezier(0.16, 1, 0.3, 1)","rationale":"200ms is within the 'instant' perception threshold for UI feedback. The out easing provides a quick start (the feedback appears almost immediately) with a gentle settle (the feedback eases into its final position), matching the tone of a helpful observation rather than an abrupt correction."},"journey_state_awareness":"During discovery, the gate evaluates broad parameters (duration, lead time) since the prospect may not have specific listing preferences yet. During search, the gate can be more granular -- evaluating against actual listing availability rather than platform-wide constraints. If the prospect has already been through discovery and is now in search, the constraint feedback should reference their previously stated parameters: 'You mentioned 4 weeks -- our shortest options start at 6 weeks.'","edge_cases":["Prospect enters a duration at the exact boundary (exactly 6 weeks) -- the system should confirm eligibility, not flag a near-miss warning","Prospect changes their input multiple times rapidly -- debounce the evaluation to avoid flashing between states; use a 300ms debounce on input change","Prospect is a proxy searcher (like Sophie, searching for a family member) and may not know the end user's exact parameters -- the gate should accept ranges ('4-8 weeks') and respond to the worst-case end of the range","Prospect arrives via a marketing channel that already communicated constraints -- the gate should still respond to input but may suppress the constraint message if the prospect's input is already compatible","Mobile viewport where the feedback area may push the CTA below the fold -- the feedback message must be compact enough (under 2 lines) to keep the CTA visible without scrolling"]},{"id":"behaves-002","type":"interaction_pattern","title":"Graceful Dead-End Redirect with Future Capture","journey_phases":["discovery","search"],"problem":"When a prospect is confirmed ineligible, the interaction ends in a dead end with no mechanism to capture future value. Sophie's agent said 'That's unfortunate that we cannot help you... if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.' This verbal redirect is structureless: it captures no email, offers no specific alternative, and provides no reason for Sophie to re-engage later. The interaction pattern treats ineligible prospects as lost rather than as deferred leads. The system 'expects' this error (ineligible arrivals are predictable) but has no forgiving response path.","solution":"When eligibility disqualification is confirmed (behaves-001 error state), the UI should transition the entire interaction context from 'qualification' to 'redirect' mode. This is not a separate page -- it is a state transformation of the current view. The redirect state presents three simultaneous actions: (1) a specific mismatch diagnosis with the nearest viable alternative ('If you could extend to 6 weeks, we have 12 options'), (2) a single email capture field framed as future value ('We will notify you when options match your timing'), and (3) a share mechanism for the prospect to forward the platform to someone who might qualify. The interaction should feel like a pivot, not a dismissal -- the same container transforms from a qualification form into a redirect card, maintaining spatial continuity.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The verbal redirect contains no structured capture mechanism. The agent offers a vague future invitation but has no way to convert it into a re-engagement trigger. The system ends the interaction at the point of maximum awareness -- the prospect now understands what the service is -- without capturing that awareness for future use."},{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie declines the agent's offer to send information because her current need does not match. But the interaction pattern should have pivoted to capture her as a potential future lead or referral source. She lives in New York -- she may know commuters who qualify. The dead end captured zero value from a fully-engaged, now-informed prospect."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"Ineligible arrivals are not errors by the prospect -- they are predictable system events. A 'forgiving' system has a designed, value-capturing path for this event. The dead-end redirect is the system's forgiveness mechanism: it treats the mismatch as a redirection opportunity, not a failure state."}],"priority":"high","states":{"default":"Not applicable -- this pattern activates only after behaves-001 has confirmed ineligibility. The entry state is the error state of behaves-001.","loading":"When the redirect card is assembling its nearest-alternative count (which may require a database query), show a skeleton state for the alternative count only: 'If you could extend to 6 weeks, we have [---] options.' The mismatch diagnosis and email field appear immediately since they require no async data.","empty":"If there are zero alternatives even with adjusted criteria (e.g., the platform has no listings at all in the prospect's city), the redirect card omits the alternative tier entirely and leads with the email capture: 'We are expanding to your area. Leave your email to be first to know.' The card never shows 'zero options' -- it always presents a forward-looking action.","error":"If the email capture submission fails (network error), show a subtle inline retry message below the field: 'Could not save -- try again.' Do not use a modal, toast, or page-level error. The retry message uses signal-warn color. The email field retains the entered value so the prospect does not have to retype.","success":"After email submission, the email field transforms into a confirmation: 'Saved -- we will reach out when options match.' The confirmation uses accent color and a subtle checkmark icon. The card remains visible (does not dismiss itself) so the prospect can still use the share mechanism or review the mismatch diagnosis."},"transition_principle":"The transition from behaves-001 error state to the redirect card should feel like a spatial transformation, not a page navigation. The eligibility form container should morph into the redirect card using the same container dimensions with content crossfading inside. This maintains the prospect's spatial orientation -- they are in the same place, the context has shifted. Use the 'out' easing for the container morph and stagger the three tiers (diagnosis, alternative, email) with 100ms delays so they appear to build in sequence rather than flash all at once.","timing":{"response_target":"400ms for the full redirect card to assemble and appear after disqualification is confirmed. The first tier (mismatch diagnosis) should appear within 200ms; the second tier (nearest alternative) within 300ms; the third tier (email capture) within 400ms. The stagger creates a reading-order reveal.","easing":"cubic-bezier(0.16, 1, 0.3, 1)","rationale":"The staggered 400ms total avoids the jarring effect of a full-card pop-in after disqualification. The prospect has just received bad news (ineligible); the redirect should arrive gently, tier by tier, giving them time to process each piece of information. The out easing ensures each tier settles quickly after its entrance."},"journey_state_awareness":"During discovery (first visit, no account), the redirect card emphasizes email capture and the share mechanism -- converting an anonymous visitor into a reachable lead. During search (the prospect has been browsing), the redirect card can be more specific: 'Your search for [city] apartments, 4 weeks, returned no matches. With 6 weeks, you would see [N] options in [city].' If the prospect is a return visitor (cookie or account detected), acknowledge the relationship: 'Welcome back -- we still require a 6-week minimum, but here is what is available now.'","edge_cases":["The prospect's email domain suggests they are a corporate user (e.g., @bigcompany.com) -- the share mechanism could be promoted above the personal email capture, since corporate users may be searching on behalf of employees","The prospect rapidly closes the tab after disqualification -- the redirect card should render server-side as well so that email remarketing can reference the specific mismatch, even if the client-side card was never seen","The prospect has already submitted their email from a previous visit -- the email field should pre-fill and the CTA should change to 'Update preferences' rather than asking for an email they already provided","The nearest alternative count is stale (e.g., listings were filled since the last cache) -- use a 'live' indicator if the count is real-time, or omit precision ('several options') if the count is approximate"]},{"id":"behaves-003","type":"interaction_pattern","title":"Co-Tenancy Calendar Interactive Comprehension","journey_phases":["listing_evaluation","proposal_creation"],"problem":"The co-tenancy model is an unfamiliar arrangement that even the trained agent struggled to explain: 'the way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.' This verbal explanation is nearly incomprehensible. The interaction challenge is: how does the system respond to the prospect's arrival at a listing page such that the co-tenancy model becomes comprehensible within seconds, without requiring the prospect to read a paragraph of text? The calendar visualization (from looks-003) must behave interactively -- responding to hover, tap, and focus to reveal day-level detail -- so the prospect can explore the schedule split at their own pace.","solution":"The co-tenancy calendar should be the first interactive element on the listing page. On load, it renders a static 7-day strip with the guest's available days in accent and the co-tenant's days in neutral. On hover or tap of any day, the calendar responds with a detail tooltip or expandable row showing the arrival/departure time for that day: 'Monday -- you arrive by 6pm' or 'Friday -- your last day, check out by 10am.' This interaction transforms an abstract schedule into a concrete daily narrative, one day at a time. The calendar also responds to the prospect's own schedule input: if the prospect has entered preferred days during search, the calendar highlights matches and mismatches. The principle is: the calendar is not a static display but an explorable map of the living arrangement. Each interaction reveals one more layer of concrete detail, following the 'free taste' principle from Nudge.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The agent's verbal attempt to map the abstract model onto concrete days fails because language is sequential and the schedule is spatial. An interactive calendar replaces the entire verbal explanation with a single visual that responds to exploration."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"Each hover or tap on a calendar day is a 'free taste' -- the prospect experiences one day of the arrangement concretely before committing to evaluate the whole listing. The interaction is low-commitment and reversible: hover off to dismiss the detail, hover on another day to taste a different slice."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off. One way to do this is to make the information about various options more comprehensible, by transforming numerical information into units that translate more readily into actual use.","insight":"The calendar transforms 'Monday through Friday, complementary schedule' (numerical/temporal abstraction) into 'you arrive Monday at 6pm, you leave Friday at 10am' (units of actual use). Each interaction step makes the mapping more concrete."}],"priority":"high","states":{"default":"The 7-day calendar strip renders immediately on page load with guest days in accent and co-tenant days in neutral. No day is selected or expanded. A subtle legend below reads 'Your days' (accent) and 'Other guest' (neutral). The calendar is visually complete and informative even without interaction.","loading":"If day-level detail (arrival/departure times) requires an async fetch, the tooltip shows a 1-line skeleton shimmer for 150ms. The calendar day circles themselves are always rendered from static data and never show a loading state -- only the detail layer loads asynchronously.","empty":"If a listing has no co-tenant yet (all days are available to the guest), the calendar shows all 7 days in accent with a label: 'All days available -- you would be the first guest.' This is a positive empty state: full availability is a feature, not a gap. No gray days, no 'no co-tenant assigned' messaging.","error":"If day-level detail cannot be fetched, the calendar remains fully functional at the overview level (guest days vs. co-tenant days are always visible). The tooltip for the affected day shows: 'Details unavailable -- contact us for arrival times.' This degrades gracefully: the primary mapping (which days are yours) is never lost, even if the secondary mapping (arrival/departure times) fails.","success":"When the prospect transitions from calendar exploration to proposal creation, the days they explored most (longest hover time, most taps) are highlighted with a subtle pulse, suggesting they start their proposal from those days. This bridges the calendar interaction into the proposal form as a natural continuation."},"transition_principle":"Hover/tap reveals should use the 'spring' easing (cubic-bezier(0.34, 1.56, 0.64, 1)) for the tooltip entrance to create a lively, inviting feel -- the calendar should feel explorable, not clinical. The tooltip should emerge from the day circle as if growing out of it (scale from 0.9 to 1.0 with opacity from 0 to 1). On hover-off, the tooltip should fade faster (150ms) than it appeared (250ms) to keep the exploration pace brisk. When switching between days, the tooltip should crossfade in place rather than exit-then-enter, maintaining spatial continuity.","timing":{"response_target":"100ms from hover/tap to tooltip appearance. The calendar should feel as responsive as flipping through physical calendar pages. No perceptible delay between the prospect's input and the system's response.","easing":"cubic-bezier(0.34, 1.56, 0.64, 1)","rationale":"The spring easing with its slight overshoot gives the tooltip a physical, tactile quality that invites continued exploration. The 100ms response target ensures the calendar feels like a direct extension of the prospect's gesture, not a system reaction to it."},"journey_state_awareness":"During listing_evaluation (first visit to this listing), the calendar starts with all days at equal visual weight. During proposal_creation (the prospect has started configuring a proposal), the calendar reflects the proposed days with a selected state (accent with a check or ring) so the prospect can see their proposal overlaid on the schedule. If the prospect returns to the listing after a previous visit, the calendar remembers which days they explored and subtly highlights them as 'previously viewed.'","edge_cases":["Touchscreen devices where hover is not available -- the first tap on a day should reveal the tooltip, and a second tap on the same day should dismiss it. Tapping a different day should dismiss the current tooltip and reveal the new one.","Screen readers must receive the calendar data as a structured table with row headers (day names) and cell values ('Your day -- arrive by 6pm' or 'Other guest's day'). The interactive tooltips should be announced via aria-live regions.","Listings with irregular schedules (e.g., alternating weeks rather than fixed days) -- the calendar should switch to a monthly view with week rows instead of day columns. The interaction principle remains the same: hover/tap reveals detail.","Listings where the co-tenant's schedule is not yet confirmed -- show the guest's available days in accent and the unconfirmed days in a dashed-border neutral, with a tooltip: 'This day is pending -- may become available.'","Very narrow mobile screens where 7 day circles may be cramped -- allow horizontal scroll on the day strip or stack into two rows (Mon-Thu / Fri-Sun) with the same interaction behavior"]},{"id":"behaves-004","type":"interaction_pattern","title":"Smart-Default Proposal Pre-Fill with Edit Affordance","journey_phases":["proposal_creation","negotiation"],"problem":"Creating a co-tenancy proposal requires configuring multiple parameters (start date, end date, days of week, schedule pattern) for an arrangement the guest has likely never experienced. A blank proposal form is a 'required choice' scenario where the path of least resistance is abandonment. Thaler and Sunstein show that when choice is complicated and difficult, sensible defaults dramatically increase completion. The interaction challenge is twofold: (1) pre-fill the form with smart defaults derived from the guest's search behavior and the listing's successful patterns, and (2) make the pre-filled state visually and interactively distinct from user-edited values, so the guest understands they are being helped, not constrained.","solution":"On proposal form load, all fields arrive pre-populated with smart defaults. The interaction responds to two sources: the guest's search criteria (if they searched for Monday-Friday starting June 1, those values pre-fill) and the listing's most common successful configuration (if 80% of accepted proposals at this listing are Monday-Friday for 8 weeks, that is the fallback default). Each pre-filled field renders in a visually muted state (italic, softer color per looks-004) with a contextual label ('Based on your search' or 'Most common at this listing'). When the guest taps or clicks any field to edit, the value transitions from muted/italic to full ink/regular weight, the contextual label updates to 'Custom', and the field enters an active editing state. The interaction principle is: the guest starts at a complete, viable proposal and adjusts only what they need to, rather than building from scratch.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance. Recall the discussion of inertia, status quo bias, and the 'yeah, whatever' heuristic. All these forces imply that if, for a given choice, there is a default option -- an option that will prevail if the chooser does nothing -- then we can usually expect a large number of people to end up with that option.","insight":"Without defaults, the path of least resistance on a proposal form is closing the tab. With pre-filled defaults, the path of least resistance is submitting a viable proposal. The interaction pattern literally changes what 'doing nothing' produces -- from an empty form to a complete proposal."},{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.","insight":"A co-tenancy proposal is an 'arcane setting' problem. The guest must decide which days, how many weeks, what start date -- for an arrangement they have never configured before. Smart defaults replace the need to 'read the manual' by starting the guest at a known-good configuration."},{"source":"Sophie Charvet - 18 April 2022.txt, 0:45-1:00","type":"guest_call","quote":"I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that? Is that something which is going to work for you?","insight":"The agent verbally performs a 'prompted choice' -- presenting the standard configuration (6 weeks, 3 weeks lead time) and asking the guest to accept or adjust. The proposal form should replicate this interaction digitally: present a default configuration and let the guest respond to it."}],"priority":"high","states":{"default":"All proposal fields are pre-populated. Each field shows its value in ink-soft italic with a contextual label in ink-ghost below. The total estimated price (calculated from defaults) is prominently displayed in accent-colored mono type. The submit button reads 'Send proposal' and is active (not disabled) -- the default proposal is valid and submittable as-is.","loading":"If default values require an async calculation (e.g., querying the listing's most common configuration), show skeleton shimmers inside each field for a maximum of 500ms. The submit button is disabled during loading with reduced opacity. If loading exceeds 500ms, show partial defaults (the guest's search criteria) and backfill listing-derived defaults when they arrive.","empty":"If no defaults can be derived (the guest has no search history and the listing has no prior proposals), the form presents platform-wide defaults: 6-week minimum duration, starting 3 weeks from today, Monday-Friday schedule. The contextual label reads 'Platform minimum' to signal these are baseline values, not recommendations. This is the only scenario where the form may feel like a required choice -- and the defaults at least prevent the blank-form paralysis.","error":"If the guest edits a field to an invalid value (e.g., end date before start date, fewer than 6 weeks), the field border transitions to signal-warn and an inline message appears below: 'Minimum 6 weeks required -- your selection is 4 weeks.' The message is specific and corrective, not generic. The submit button becomes disabled only if the overall proposal is invalid. If only one field is invalid, the others remain editable and the price estimate updates to reflect valid fields only.","success":"On proposal submission, the entire form container transitions to a confirmation state: fields become read-only with full ink color (no longer muted), the submit button transforms to a checkmark with 'Proposal sent', and a brief summary appears: 'Your proposal for [dates] at [price] has been sent to the host.' The confirmation uses the spring easing for the checkmark animation to create a satisfying moment of closure."},"transition_principle":"Field state changes (default-to-edited, valid-to-invalid) should use the 'out' easing with a 200ms duration. The color shift from ink-soft italic to ink regular should feel like the text is 'waking up' -- gaining confidence as the guest takes ownership. The price recalculation on any field edit should crossfade the old number to the new number (not animate the digits) to avoid a distracting counter effect. On submission, the form-to-confirmation transition should use a 300ms container morph with staggered content reveals (form fields fade, confirmation fades in).","timing":{"response_target":"200ms for field state change after edit. 400ms for price recalculation display after any field change. 300ms for submission confirmation after server response.","easing":"cubic-bezier(0.16, 1, 0.3, 1)","rationale":"200ms for field edits keeps the form feeling responsive and direct. 400ms for price recalculation allows the number crossfade to be perceptible (the guest should see the price change, not miss it). 300ms for submission confirmation balances between 'instant' (which might feel untrustworthy for a commitment) and 'slow' (which might feel uncertain)."},"journey_state_awareness":"During proposal_creation (first proposal for this listing), defaults lean on the listing's successful patterns. During negotiation (the host has countered), the form re-opens with the host's counter-proposal pre-filled as the new defaults, clearly labeled 'Host's counter-proposal.' The guest can see what changed by comparing the muted original values (shown as struck-through labels) against the host's new values. If the guest has submitted proposals for other listings, the form may offer their most recent proposal configuration as a 'Your usual' default alongside the listing-specific default.","edge_cases":["The guest rapidly submits without changing any defaults -- this is a valid and expected outcome. The system should not prompt 'Are you sure?' or add friction. The defaults were designed to be submittable.","The listing has only one prior proposal (insufficient data for a reliable 'most common' pattern) -- use the platform-wide defaults rather than a single-sample listing default, and label accordingly","The guest is a proxy searcher (like Sophie) who may not know the end user's exact schedule preferences -- the default labels should indicate they can be adjusted by the actual guest later: 'The person staying can adjust these after you share the proposal'","The guest changes one field that invalidates another (e.g., changing start date such that the duration is now too short) -- cascade the validation immediately and highlight all affected fields, not just the one edited","Slow network on submission -- show an optimistic UI: transition to the confirmation state immediately and roll back only if the server rejects. Display a subtle 'Sending...' indicator during the server round-trip but do not block the visual transition"]},{"id":"behaves-005","type":"interaction_pattern","title":"Counter-Proposal Change-Diff Feedback","journey_phases":["negotiation"],"problem":"When a host counters a guest's proposal, the guest must evaluate modified terms without clear feedback about what changed, why it changed, and what the implications are. Thaler and Sunstein warn that 'warning systems have to avoid the problem of offering so many warnings that they are ignored' and that feedback must be specific and actionable. The interaction challenge is: a counter-proposal modifies parameters the guest originally chose (or accepted as defaults), and without explicit change highlighting, the guest may miss critical differences, misinterpret the counter as a rejection, or feel overwhelmed by the full proposal being re-presented.","solution":"When a counter-proposal arrives, the notification should open a diff view that shows only what changed. Each modified parameter is displayed in a before/after format: the guest's original value on the left (struck through, muted) and the host's new value on the right (accent color, full ink). Unchanged parameters are collapsed into a single line: '3 parameters unchanged.' The total price difference is calculated and displayed prominently: 'Price change: +$200/month' or 'No price change.' The interaction responds to the guest's options: 'Accept changes', 'Modify and re-send', or 'Keep my original terms.' Each option is a clear, labeled button -- not a text link, not buried in a paragraph. The principle is: feedback about changes must be precise, comparative, and immediately actionable.","evidence":[{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","insight":"A counter-proposal is neither 'doing well' nor 'making a mistake' -- it is a negotiation signal. The feedback must characterize the counter accurately: the host wants to adjust specific terms, not reject the guest. The diff view makes this distinction visually clear by showing the negotiation as a set of specific parameter changes, not a wholesale rejection."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Warning systems have to avoid the problem of offering so many warnings that they are ignored. If our computer constantly nags us about whether we are sure we want to open that attachment, we begin to click 'yes' without thinking about it.","insight":"The counter-proposal notification must avoid the 'warning fatigue' pattern. Instead of a generic 'You have a counter-proposal' notification that the guest must click through to understand, the notification itself should contain the most important change: 'The host adjusted your dates by 1 week -- review changes.' The signal is specific enough to be meaningful on first scan."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"The guest may accidentally accept or decline a counter-proposal. The system should be forgiving: 'Accept changes' should have a brief undo window (5 seconds) after click, and 'Keep my original terms' should confirm before sending, since it effectively rejects the host's counter."}],"priority":"medium","states":{"default":"The diff view renders with changed parameters expanded and unchanged parameters collapsed. The before/after format is immediately visible. The three action buttons are equally weighted visually, with 'Accept changes' in accent as the primary action.","loading":"If the diff calculation requires comparing against the original proposal stored server-side, show a skeleton of the diff layout with placeholder bars where values will appear. The action buttons are disabled during loading. Target: under 300ms for the diff to assemble.","empty":"If the host's counter-proposal is identical to the guest's original (unusual but possible if the host made and undid changes), display: 'The host confirmed your original terms -- no changes.' The action simplifies to a single 'Accept' button.","error":"If the acceptance or rejection fails to send (network error), show an inline retry below the action buttons. The diff view remains visible and the guest's last-clicked action is highlighted so they can re-confirm without re-evaluating. Do not clear the diff view on error.","success":"On acceptance, the diff view transitions to a confirmed state: changed values show the accepted new values in full ink, the before values fade to ink-ghost, and a confirmation line reads 'Terms updated.' On rejection ('Keep my original terms'), the diff view reverses: original values restore to full ink, the host's values fade. Both transitions should feel like a resolution, not a dismissal."},"transition_principle":"The diff view should enter with staggered reveals (changed parameters first, then unchanged summary, then action buttons) at 100ms intervals using the out easing. On acceptance, the before/after values should converge visually -- the host's value slides left to replace the guest's original value, creating a sense of merging rather than replacement. The undo window after acceptance should show a subtle progress bar beneath the action button that depletes over 5 seconds, giving the guest visual feedback on the remaining undo time.","timing":{"response_target":"300ms for diff view to fully render from notification click. 5000ms undo window after acceptance. 200ms for confirmation transition after undo window expires.","easing":"cubic-bezier(0.16, 1, 0.3, 1)","rationale":"300ms for diff rendering balances speed with comprehension -- the staggered reveal gives the guest time to orient before all information is present. The 5-second undo window provides error recovery without encouraging indecision. 200ms for the final confirmation ensures the resolution feels prompt once committed."},"journey_state_awareness":"If this is the first counter-proposal the guest has ever received (first-time user), add a brief contextual note above the diff: 'This is a normal part of the process -- the host would like to adjust some terms.' For returning users who have negotiated before, omit the contextual note. If the guest has received multiple counters on the same proposal, show a negotiation history timeline so they can see the progression of changes across rounds.","edge_cases":["The host changed every parameter (nothing unchanged to collapse) -- display all changes without a collapsed section, but add a summary at the top: 'The host suggested a significantly different arrangement'","The counter-proposal arrives while the guest is browsing other listings -- the notification should be persistent (not auto-dismiss) and include the most important change in the notification preview","The guest starts editing the counter ('Modify and re-send') but then navigates away -- auto-save their partial edits and restore them when they return","Multiple counter-proposals arrive in rapid succession (race condition if the host retracts and re-sends) -- always show the most recent counter and note 'Updated 2 minutes ago' with a link to the previous version if needed"]},{"id":"behaves-006","type":"interaction_pattern","title":"Postcompletion Checkpoint Forcing Flow","journey_phases":["acceptance","move_in"],"problem":"After a proposal is accepted, the guest enters a postcompletion state where the main cognitive task (finding housing) feels finished but critical follow-up steps remain: reviewing lease terms, confirming payment, preparing for move-in. Thaler and Sunstein identify postcompletion errors as a predictable failure mode -- 'when you have finished your main task, you tend to forget things relating to previous steps.' The emotional relief of acceptance depletes attention for administrative follow-up. Without forcing functions, guests will skip lease review, miss payment details, and arrive at move-in unprepared -- generating support burden and early-tenure friction.","solution":"Structure the acceptance-to-move-in transition as a sequential checkpoint flow with forcing-function gates. The guest cannot access move-in details until they have acknowledged the lease summary; they cannot access the house manual until they have confirmed payment. Each checkpoint is a compact card (maximum 5 key points, each under 15 words) with a single acknowledge button using positive framing ('Got it, next step'). A horizontal progress bar at the top shows three clearly labeled steps: Lease Review, Payment Confirmation, Move-In Prep. Each checkpoint card appears one at a time -- the next is gated. The interaction principle is: the forcing function makes critical steps unavoidable without making them punitive. Each checkpoint should take under 60 seconds and feel like preparation, not bureaucracy.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Leaving the gas cap behind is a special kind of mistake psychologists call a 'postcompletion' error. The idea is that when you have finished your main task, you tend to forget things relating to previous steps.","insight":"Acceptance is the 'getting your cash' moment. Lease review, payment confirmation, and move-in prep are the 'gas cap' that gets forgotten. The forcing function prevents this postcompletion error by making each step a prerequisite for the next."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Another strategy, suggested by Don Norman, is to use what he calls a 'forcing function,' meaning that in order to get what you want, you have to do something else first. So if you have to remove the card in order to get your cash, you will not forget to do so.","insight":"The ATM card-before-cash pattern maps directly: the guest must confirm lease terms (card) before receiving move-in details (cash). Each checkpoint is a forcing function that prevents the next step from being skipped."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","insight":"Each checkpoint completion should deliver positive feedback -- a progress bar fill, a checkmark, a 'Done' confirmation. The guest should feel that each step is an accomplishment in their journey toward move-in, not a bureaucratic hurdle imposed by the platform."}],"priority":"medium","states":{"default":"The progress bar shows the current step highlighted and subsequent steps grayed out. The current checkpoint card is fully visible with its 5 key points and acknowledge button. Completed steps show a checkmark in accent. Upcoming steps show a lock icon in ink-ghost.","loading":"If checkpoint content requires an async fetch (e.g., generating a lease summary from the accepted terms), the card shows a skeleton state with 5 placeholder lines and a disabled acknowledge button. The progress bar still shows the current position. Target: under 500ms for content to load.","empty":"If a checkpoint has no content to present (e.g., the lease summary is not yet generated by the back office), display a holding state: 'We are preparing your lease summary -- you will be notified when it is ready.' The progress bar shows the step as 'pending' (animated border) rather than locked. The guest cannot skip this step but is not blocked from other platform activity.","error":"If the acknowledge action fails (e.g., network error when saving the confirmation), show an inline retry message below the button. The progress bar does not advance. The checkpoint card retains all content so the guest does not have to re-read on retry.","success":"On acknowledging a checkpoint, the card smoothly compresses and slides up, the progress bar step fills with accent color and shows a checkmark, and the next checkpoint card slides in from below with a brief delay. On completing all three checkpoints, the progress bar fills completely and a final confirmation card appears with a serif headline: 'Ready for move-in' on an accent-light background."},"transition_principle":"Checkpoint completion should feel like progress through a short, satisfying ritual. The current card compresses upward (200ms, out easing), the progress bar step fills (300ms, out easing with the checkmark using spring easing for a lively pop), and the next card enters from below (250ms, out easing). The spring easing on the checkmark creates a small moment of delight at each completion. The final 'Ready for move-in' card should enter with a longer duration (400ms) and a slightly different feel (scale from 0.95 to 1.0 with opacity) to signal that this is a culmination, not just another step.","timing":{"response_target":"200ms for card compression after acknowledge. 300ms for progress bar fill. 250ms for next card entrance. Total step transition: 500ms from click to next card visible.","easing":"cubic-bezier(0.34, 1.56, 0.64, 1) for checkmark; cubic-bezier(0.16, 1, 0.3, 1) for all other transitions","rationale":"500ms total step transition is long enough to register as a meaningful progression (the guest sees their progress advance) but short enough to avoid feeling slow when the guest wants to move quickly through checkpoints. The spring easing on the checkmark adds a subtle reward at each step."},"journey_state_awareness":"The checkpoint flow adapts to the guest's behavior. If the guest completes all three checkpoints in one session, the flow is uninterrupted and the final confirmation is immediate. If the guest leaves after one checkpoint and returns later, the progress bar shows their saved position and the next checkpoint card is immediately visible -- no re-reading of completed steps. If move-in is more than 2 weeks away, the third checkpoint (Move-In Prep) may be gated by time rather than sequence: 'Available 5 days before your move-in date' -- because move-in instructions may not be finalized yet.","edge_cases":["The guest tries to access move-in details directly (via a deep link or bookmark) without completing earlier checkpoints -- redirect them to the earliest incomplete checkpoint with a message: 'Complete this step first to unlock your move-in details'","The guest shares the acceptance flow with a proxy (e.g., Sophie forwarding to her family member) -- the checkpoints should be completable by the actual guest, not the proxy. If the wrong person attempts to acknowledge, prompt for account verification.","The lease terms change between acceptance and the guest's checkpoint review (e.g., the host corrects an error) -- the checkpoint should flag the change: 'Updated since your acceptance -- please review the highlighted changes'","The guest completes checkpoints on mobile with an unstable connection -- each acknowledge should be queued and retried automatically, with offline-tolerant optimistic UI showing the step as complete even before server confirmation"]},{"id":"behaves-007","type":"interaction_pattern","title":"Per-Stay Benefit Salience Reinforcement","journey_phases":["active_lease"],"problem":"During the active lease phase, per-stay friction tasks (uploading cleaning photos, sending arrival notifications, coordinating schedule changes) are the 'taxi meter' of co-tenancy -- highly salient costs that the guest experiences at specific, effortful moments. Meanwhile, the ongoing benefits of the arrangement (cost savings vs. solo rental, schedule flexibility, guaranteed housing) are diffuse and invisible. Thaler and Sunstein note that 'the most important modification that must be made to a standard analysis of incentives is salience. Do choosers actually notice the incentives they face?' The guest does not notice the benefits because they are chronic and backgrounded. This salience asymmetry makes the arrangement feel burdensome even when objectively advantageous, increasing dissatisfaction and dropout risk.","solution":"At every per-stay friction touchpoint, inject a compact 'benefit reinforcement strip' -- a single-line data point that makes the invisible benefit salient at the exact moment the visible cost is felt. When the guest uploads a cleaning photo, the strip shows: 'You have saved $2,340 vs. solo rental this quarter.' When the guest confirms a schedule change, the strip shows: 'You changed dates 3 times this month -- no extra cost.' The data is real, personalized, and dynamically calculated. The strip is positioned below the friction task (so the guest completes the task first and absorbs the reinforcement second). The interaction is passive -- no click required, no dismissal needed. The strip simply appears alongside the task, using the benefit reinforcement visual from looks-007.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"The most important modification that must be made to a standard analysis of incentives is salience. Do choosers actually notice the incentives they face?","insight":"The co-tenancy benefit is an incentive the guest does not notice because it lacks salience. The benefit strip forces salience by placing a concrete, personalized benefit number at the moment of maximum friction -- when the guest is most likely to question the value of the arrangement."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks. So a behavioral analysis of the incentives of car ownership will predict that people will underweight the opportunity costs of car ownership and possibly other less salient aspects... and may overweight the very salient costs of using a taxi.","insight":"Per-stay tasks are the taxi meter of co-tenancy. Without the benefit strip, guests overweight the visible friction (cleaning photo upload) and underweight the invisible benefit (savings vs. solo rental). The strip is the visual equivalent of showing 'but your monthly car payment is $0' every time the taxi meter runs."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Who chooses? Who uses? Who pays? Who profits?","insight":"During active lease, the guest uses, pays, and increasingly questions whether they profit. The benefit strip answers the 'who profits?' question at the friction point: 'You profit -- here is the exact amount.' This aligns the guest's perception of incentives with the actual incentive structure."}],"priority":"medium","states":{"default":"The benefit strip appears below each per-stay task interface (cleaning photo upload, schedule confirmation, arrival notification) as a subtle horizontal bar in accent-light background with a personalized benefit number in mono accent type and a contextual label in sans ink type.","loading":"If the benefit calculation requires real-time data (e.g., computing savings vs. current solo rental market rates), show a skeleton bar with a shimmer where the number will appear. The contextual label ('saved vs. solo rental') renders immediately to prime the guest for the benefit before the number arrives. Target: under 300ms for the number to calculate.","empty":"If the guest has just started their lease and there is not yet enough data for a meaningful benefit calculation (e.g., first stay, no savings to report), show an aspirational strip: 'After 3 months, guests like you save an average of $2,100.' Use the platform average rather than showing nothing. Label clearly: 'Based on similar guests.'","error":"If the benefit calculation fails, the strip does not appear. Absence is preferable to an error message in a reinforcement element -- the strip is optional encouragement, not required information. No error state should interrupt the friction task itself.","success":"After the guest completes the friction task (e.g., submits cleaning photos), the benefit strip brightens slightly (opacity shifts from 0.85 to 1.0) and the benefit number receives a brief scale pulse (1.0 to 1.02 and back) to acknowledge that the task completion has been registered alongside its benefit context."},"transition_principle":"The benefit strip should enter with a subtle fade-in (opacity 0 to 1, 300ms, out easing) that is noticeable but does not compete with the friction task for attention. The strip should never enter before the friction task interface is fully loaded -- the task comes first, the reinforcement comes second. After task completion, the brief scale pulse on the benefit number (150ms, spring easing) creates a micro-reward that links the effort of the task to the value of the arrangement.","timing":{"response_target":"300ms for benefit strip to appear after friction task interface loads. 150ms for the scale pulse after task completion.","easing":"cubic-bezier(0.16, 1, 0.3, 1) for strip entrance; cubic-bezier(0.34, 1.56, 0.64, 1) for post-completion pulse","rationale":"300ms entrance delay ensures the strip does not compete with the task interface for initial attention. The spring easing on the post-completion pulse adds a moment of physical 'bounce' that makes the benefit feel tangible and earned, not just informational."},"journey_state_awareness":"The benefit data adapts based on lease tenure. In months 1-2 (early lease), the strip emphasizes projected savings: 'On track to save $X this quarter.' In months 3-6 (established lease), the strip shows actual cumulative savings: 'You have saved $X since [start date].' After 6 months, the strip can compare to market alternatives: 'Your rate is $X less than the average solo rental in [area].' The strip should also rotate between different benefit types across stays -- savings one time, flexibility count the next, positive host review snippet another time -- to avoid habituation to a single number.","edge_cases":["The guest's actual savings are negative (e.g., they are paying more than a solo rental due to their specific configuration) -- do not show the savings benefit. Show an alternative benefit type: schedule flexibility, location access, or host review quote. Never present a negative benefit number.","The guest is on their final stay before lease end -- shift the strip from ongoing benefit to retention: 'You saved $X total. Renewing your lease locks in this rate.'","The benefit number is very small (e.g., '$45 saved') -- this may feel patronizing. Set a minimum threshold: only show savings if they exceed $100/quarter. Below that threshold, show a different benefit type.","Multiple friction tasks on the same screen (e.g., cleaning photos and schedule confirmation) -- show only one benefit strip per screen to avoid over-reinforcement. Choose the benefit most relevant to the task at hand.","The guest has opted out of non-essential UI elements (a hypothetical preference setting) -- respect the opt-out and do not show the strip. The benefit should be available on demand (e.g., in the dashboard) but not forced."]}]}</script>
  <!-- INJECT:layer-5 -->
  <script id="data-layer-5" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"feels-001","type":"emotional_element","title":"Immediate Clarity Before Commitment","journey_phases":["discovery","search"],"problem":"Sophie invested the effort of a phone call only to learn within seconds that her need (1 month, starting almost immediately) was completely outside the service's parameters. The emotional experience was wasted effort followed by abrupt disappointment -- she felt purposeful and ready to act, then was told the service could not help her at all. The platform let her build momentum toward a goal that was structurally impossible, then halted her cold. This is the emotional equivalent of Thaler's door handle that says 'pull' when you need to push: the guest's emotional trajectory (urgency, readiness, hope) was incompatible with the outcome the system would deliver (rejection). Every second of false momentum before disqualification converts into frustration when the mismatch is revealed.","solution":"The guest should feel informed certainty within the first 10 seconds of encountering the platform. Before any emotional investment in the service (browsing, calling, hoping), the guest must receive a clear, honest signal about whether their specific need can be served. The emotional principle is: respect precedes engagement. The platform earns the right to the guest's emotional investment by first demonstrating that it respects their time enough to tell them the truth immediately. For eligible guests, this creates confidence ('they understand what I need'). For ineligible guests, this creates respect ('they did not waste my time'). Both outcomes are emotionally superior to the current pattern of hope followed by disappointment.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick. I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that?","insight":"The agent delivers the disqualifying information apologetically but too late. Sophie has already invested emotional energy in calling -- her urgency, her family's need, her hope that this could solve the problem. The constraint information arrives after the emotional commitment, not before it."},{"source":"Sophie Charvet - 18 April 2022.txt, 1:09","type":"guest_call","quote":"This was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may, unfortunately.","insight":"Sophie's tone shifts from purposeful to deflated. The word 'unfortunately' carries the emotional weight of someone who came with a real need and just learned they cannot be helped. This deflation was entirely preventable -- the same information delivered 60 seconds earlier (before the call) would have prevented the emotional investment entirely."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action. When there are inconsistencies, performance suffers and people blunder.","insight":"Emotional stimulus-response compatibility means: the emotional signal the platform sends during discovery (warmth, invitation, 'we can help') must be consistent with the emotional outcome the guest will experience. Sending a warm invitation signal to someone who will be rejected creates an emotional blunder -- the guest feels deceived, not disappointed."}],"priority":"high","target_emotion":"safety","emotion_rationale":"At discovery, before the guest has invested emotional energy, the dominant need is to feel safe enough to proceed -- safe that their time will not be wasted, safe that the platform is honest about what it can and cannot do.","copy_guidelines":{"voice":"direct, honest, respectful of time","do":["State constraints in specific numbers: '6 weeks minimum, starting 3+ weeks from now'","Lead with what the service requires before describing what it offers","Use the guest's own terms: 'Your stay' not 'the lease commitment'"],"dont":["Use vague language that lets ineligible guests assume they qualify: 'flexible stays', 'short-to-medium term'","Bury constraints after aspirational descriptions of the service","Frame constraints apologetically -- they are facts, not flaws"],"example_good":"Split Lease matches guests for stays of 6 weeks or more, starting at least 3 weeks from now. Does that fit your timeline?","example_bad":"Welcome to Split Lease! We offer flexible, affordable housing in New York. Tell us what you are looking for and we will find the perfect match."},"animation_feel":{"easing":"cubic-bezier(0.16, 1, 0.3, 1) -- smooth settle","feel_description":"Constraint information appears with a calm, settled presence -- not urgent, not animated, just there. Like a well-placed sign you notice without effort. No bouncing, no fading in, no attention-grabbing motion. The information's importance comes from its position and clarity, not from animation.","duration_range":"200-350ms"},"tension_relief":{"tension_point":"The guest arrives with a specific need and does not know whether this platform can serve it","relief_point":"Within 10 seconds, the guest sees a clear, specific statement of what the platform requires and can immediately determine their own eligibility","timing":"Under 10 seconds from first exposure to resolution"},"personalization_signals":["If the guest enters criteria that match, confirm the match explicitly: 'Your 8-week need starting in June fits our service'","If the guest enters criteria that do not match, state the specific gap: 'Your need is 4 weeks; our minimum is 6 weeks'","Remember the guest's criteria if they return, showing the platform retained their context"],"anti_patterns":[{"pattern":"Delaying constraint disclosure behind a call-to-action or sign-up form","reason":"Every second of engagement before constraint disclosure builds emotional investment that converts to frustration when the mismatch is revealed. The longer the delay, the worse the disappointment feels.","example_bad":"Sign up to see available listings in your area! (Guest signs up, browses, finds nothing matching a 1-month need, feels deceived.)"}]},{"id":"feels-002","type":"emotional_element","title":"Dignified Redirect When Needs Do Not Match","journey_phases":["discovery","search"],"problem":"When Sophie learned she was ineligible, the emotional experience was polite dismissal. The agent said 'That's unfortunate that we cannot help you' -- emotionally appropriate but structurally empty. Sophie's response was gracious ('It sounds like a good thing you have'), but she left with nothing: no future path, no alternative, no sense that her time was valued beyond the courtesy of the apology. The emotional pattern is: you invested effort, we cannot help, goodbye. This leaves the guest feeling like an inconvenience to be processed rather than a person whose need matters even when it does not match. The Nudge principle of 'expect error' applies emotionally: the system should expect that some guests will not match and should make the emotional experience of non-matching feel cared-for rather than dismissed.","solution":"The emotional principle for ineligible guests is: you matter even when you do not match. The redirect experience should make the guest feel that the platform took their specific need seriously, understood exactly why it did not fit, and offered something concrete for the future. This is the emotional difference between a closed door and a door that opens onto a different path. The guest should leave feeling that this was a helpful interaction -- they learned something specific ('my need is 4 weeks; they need 6'), they received something actionable ('here is what would match if my timing changes'), and they were invited to return on specific terms ('we will notify you when your timing works'). The emotional residue should be respect, not rejection.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The agent's tone is warm and genuine -- emotionally, this is the right instinct. But the words offer nothing concrete. 'If you ever need something' is vague and future-tense in a way that signals 'we do not expect to see you again.' The guest hears politeness but feels finality."},{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie declines the offer to receive more information because it is not relevant to her. The emotional subtext: 'you are offering me something generic when my situation is specific.' The redirect failed to match its emotional offer to her specific context."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Humans make mistakes. A well-designed system expects its users to err and is as forgiving as possible.","insight":"Emotional forgiveness means the guest should not feel that arriving with the wrong need was their mistake. The system's emotional posture should be: 'it is our job to help you understand what works here, and to help you find what works for you even when it is not us.' The guest is not the error; the gap between their expectation and the service is the error, and the system should own that gap emotionally."}],"priority":"high","target_emotion":"relief","emotion_rationale":"After the tension of learning the service cannot help, the guest needs emotional relief -- the sense that even though this particular door closed, they are not stranded. Relief comes from specificity: knowing exactly what happened, what could change, and what to do next.","copy_guidelines":{"voice":"specific, warm, forward-looking","do":["State the mismatch in concrete, comparative terms: 'Your need is 1 month; our minimum is 6 weeks'","Offer a specific reframe: 'If your timing changes, 12 options are available for 6+ week stays starting in June'","Make the future invitation concrete: 'Leave your email and we will notify you when stays under 6 weeks become available in New York'"],"dont":["Use generic apology language that treats all mismatches the same: 'Sorry we could not help'","Offer vague future invitations: 'Check back sometime'","End the interaction without giving the guest something specific to take away"],"example_good":"Your need: 1 month in May. Our minimum: 6 weeks, starting 3+ weeks out. If your plans change, we have 12 options in New York for June. Want us to let you know when shorter stays open up?","example_bad":"Unfortunately, we cannot accommodate your request at this time. Please visit our website for more information about our services."},"animation_feel":{"easing":"cubic-bezier(0.16, 1, 0.3, 1) -- settled, not apologetic","feel_description":"The redirect information appears with a steady, grounded presence. Not a dramatic reveal, not a sheepish fade-in. The motion should feel like a calm pivot: the conversation shifts direction without losing momentum. The three-tier redirect (diagnosis, reframe, capture) appears as a single settled block, communicating completeness -- the guest sees the entire redirect as one coherent response, not a fragmented apology.","duration_range":"300-400ms"},"tension_relief":{"tension_point":"The guest learns their need does not match -- the moment of disappointment","relief_point":"The redirect shows a specific reframe with real numbers (12 options in June) and a concrete future action (email capture)","timing":"Under 2 seconds between mismatch disclosure and the full redirect appearing"},"personalization_signals":["Name the guest's specific need in the mismatch statement: 'Your 1-month stay in May' not 'your request'","Show alternatives that are geographically relevant: 'in New York' not 'on our platform'","If the guest provided any context (like Sophie mentioning a family member), acknowledge it: 'For your family member's visit'"],"anti_patterns":[{"pattern":"Ending the interaction with only an apology and no forward path","reason":"An apology without a concrete next step leaves the guest feeling dismissed. The emotional residue is 'they were polite but unhelpful' rather than 'they could not help now but gave me something useful.' Dignity requires specificity.","example_bad":"We are sorry we could not help you today. We hope you find what you are looking for!"}]},{"id":"feels-003","type":"emotional_element","title":"Comprehension Before Commitment in an Unfamiliar Model","journey_phases":["listing_evaluation","proposal_creation"],"problem":"The co-tenancy model is emotionally charged because it involves sharing personal living space with a stranger on a split schedule -- a concept most guests have never experienced. Even the agent struggled to explain it coherently: 'the way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.' The emotional challenge is not just comprehension; it is the anxiety of committing to something you cannot fully imagine. Thaler and Sunstein's ice cream analogy captures the emotional dimension: choosing a familiar ice cream flavor is emotionally easy because you can predict the outcome. Choosing a medical treatment is emotionally hard because you cannot predict the experience. Co-tenancy falls closer to the medical treatment end: the guest is being asked to commit to a living arrangement they have never tried, with a stranger they have never met, on a schedule they have never lived. The emotional barrier is not information -- it is imaginability.","solution":"The emotional principle is: the guest must be able to imagine the daily reality of the arrangement before being asked to commit to it. Comprehension must precede commitment. The platform should evoke the feeling of 'I can see myself doing this' through concrete, experiential representation -- not abstract explanation. The weekly calendar with interactive day selection serves this emotional function: the guest does not just read about complementary schedules; they manipulate them, see their own days light up in color, and experience the split as a tangible reality they control. The emotional target is the same as the ice cream store's free taste: the guest tastes the arrangement before buying it. Every moment of hands-on exploration reduces the anxiety of the unfamiliar and builds the confidence to commit.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule. So let's say for example, somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The agent's explanation creates confusion rather than clarity. Emotionally, a confused explanation of a novel living arrangement increases anxiety rather than reducing it. If the expert cannot articulate it clearly, the guest's confidence in the arrangement drops. The emotional experience of this explanation is 'this sounds complicated and uncertain.'"},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"The 'free taste' is an emotional mechanism, not just an informational one. It reduces the anxiety of choosing something unfamiliar by converting abstract description into concrete experience. The guest needs to emotionally taste what co-tenancy feels like -- to see their specific days, their specific space, their specific schedule -- before the unfamiliar feels safe enough to commit to."},{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes and hence to select options that will make them better off.","insight":"Emotional mapping means the guest can predict not just the logistics (which days are mine) but the feeling (what will Monday evening arrival feel like? What does it mean to share a kitchen with someone I have never met?). The system must translate abstract arrangements into felt experiences."}],"priority":"high","target_emotion":"confidence","emotion_rationale":"At listing evaluation, the guest is deciding whether this arrangement could work for them. The dominant emotional need is confidence -- the feeling that they understand what they are getting into well enough to make a sound decision, not a leap of faith.","copy_guidelines":{"voice":"concrete, daily-life language, never jargon","do":["Describe the arrangement in first-person daily terms: 'You arrive Monday evening. The space is set up for you.'","Use plain words for the split: 'your days' and 'the other guest's days'","Name specific moments the guest can imagine: 'Monday evening arrival', 'Friday morning departure'"],"dont":["Use industry terminology: 'complementary schedule', 'co-tenancy arrangement', 'split lease model'","Describe the business model when the guest needs to understand the living experience","Leave the guest to imagine the unfamiliar on their own -- always provide concrete sensory detail"],"example_good":"Your week at this listing: arrive Monday evening, the space is yours through Friday morning. Over the weekend, another guest uses it. Your things stay in your private storage area.","example_bad":"This listing operates on a complementary co-tenancy schedule where two guests share the space on alternating timeframes."},"animation_feel":{"easing":"cubic-bezier(0.16, 1, 0.3, 1) for calendar state changes; cubic-bezier(0.34, 1.56, 0.64, 1) for the success moment","feel_description":"Calendar day toggles should feel playful and exploratory -- like tasting flavors at an ice cream counter. Each tap produces an immediate, satisfying color response. The overall motion feel is curiosity-driven: light, responsive, reversible. Nothing feels permanent or committed until the guest explicitly proceeds. When the guest finds a viable schedule, the success animation (spring easing) should feel like a small 'aha' moment -- the arrangement clicked into place.","duration_range":"100-200ms for day toggles, 500ms for success confirmation"},"tension_relief":{"tension_point":"The guest encounters a living arrangement they have never experienced and cannot fully imagine","relief_point":"Through interactive exploration of the calendar, the guest builds a concrete mental model of their specific week -- seeing their days in color, understanding the split viscerally","timing":"15-30 seconds of calendar interaction to build sufficient understanding for the arrangement to feel imaginable"},"personalization_signals":["Show the guest's specific days highlighted in a color that feels like 'mine' (accent green with subtle elevation)","If the guest has searched with specific criteria (Monday through Friday), pre-select those days on the calendar so the listing immediately feels relevant to them","Update the price in real time as the guest explores different day configurations, making the financial impact of their specific choices tangible"],"anti_patterns":[{"pattern":"Presenting the co-tenancy model as a text explanation without interactive or visual support","reason":"Text-only explanations of unfamiliar arrangements increase anxiety because they force the guest to imagine something they have no reference for. The agent's verbal explanation failed precisely because words are insufficient for mapping an unfamiliar experience. If the trained agent cannot explain it clearly in words, a text paragraph on a webpage will fare worse.","example_bad":"At Split Lease, two guests share the same apartment on complementary schedules. One guest uses the space during weekdays while the other uses it on weekends. Both guests have access to all amenities during their allocated time."}]},{"id":"feels-004","type":"emotional_element","title":"Guided Starting Point Instead of Blank-Slate Paralysis","journey_phases":["proposal_creation","negotiation"],"problem":"Creating a proposal for an arrangement the guest has never experienced requires configuring multiple parameters (start date, duration, days of the week, schedule pattern) from scratch. The emotional experience of a blank form for an unfamiliar choice is paralysis -- the guest does not know what a 'normal' configuration looks like and fears making a mistake they will not recognize until too late. Thaler and Sunstein's analogy of the restaurant default captures this: 'the default option is to take the dish as the chef usually prepares it, with the option to ask that certain ingredients be added or removed.' Without a default, the guest is being asked to give the chef the recipe -- for a dish they have never tasted. The emotional burden is not just cognitive load; it is the anxiety of making consequential choices without expertise. The agent in Sophie's call implicitly offered the emotional comfort of a default: 'minimum 6 weeks, 3 weeks from now -- is that going to work for you?' This verbal default offered the emotional relief of 'here is a starting point; you just need to react.'","solution":"The emotional principle is: start the guest at a viable answer and let them adjust, never start them at a blank question. The proposal form should feel like reviewing a recommendation, not filling out an application. Pre-filled defaults derived from the guest's prior exploration and the listing's common patterns transform the emotional experience from 'I must figure this out from scratch' to 'someone who knows this arrangement has suggested a starting point for me.' Every pre-filled field is an act of emotional generosity: it says 'we have done the hard part; you just need to confirm or tweak.' The emotional trajectory should be: curiosity (exploring the calendar) leads to confidence (finding a viable schedule) leads to ease (seeing that schedule pre-populated in a proposal) leads to commitment (confirming with a single action).","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:45-1:00","type":"guest_call","quote":"I don't think we can help you with anything, um, before like three weeks. So is that the minimum commitment we require is minimum six weeks after that? Is that something which is going to work for you?","insight":"The agent offers a verbal default and asks 'is that going to work for you?' -- a confirmation prompt, not a construction task. The guest's emotional experience of this pattern is relief: someone knowledgeable stated the standard and asked me to react, rather than requiring me to invent my own parameters."},{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.","insight":"The emotional word here is 'appreciate.' A sensible default is not just cognitively easier; it is emotionally welcome. The guest feels cared for -- someone anticipated their difficulty and provided a starting point. The absence of a default communicates indifference: 'figure it out yourself.'"},{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"required choosing is often more appropriate for simple yes-or-no decisions than it is for more complex choices. At a restaurant, the default option is to take the dish as the chef usually prepares it.","insight":"The restaurant analogy captures the emotional dynamic perfectly. The chef's recommendation is not just informationally helpful; it is emotionally reassuring. It says 'I am the expert and here is what I suggest.' A blank proposal form is the emotional equivalent of asking the diner to write the recipe -- anxiety-inducing for someone who has never cooked this dish."}],"priority":"high","target_emotion":"calm","emotion_rationale":"At proposal creation, after the exploratory excitement of the calendar, the guest needs to feel calm and in control. The proposal should feel like confirming a plan that already exists, not constructing one from nothing. Calm comes from having a clear starting point and knowing that adjustments are easy and reversible.","copy_guidelines":{"voice":"supportive, expert, non-prescriptive","do":["Label defaults with their source: 'Based on your calendar exploration' or 'Most guests at this listing choose Mon-Fri, 8 weeks'","Frame the proposal as confirmation: 'Does this look right?' rather than 'Fill in your details'","Acknowledge customization without pressure: 'Adjust anything that does not fit'"],"dont":["Present blank fields without guidance or context","Use imperative language that implies the guest should already know what to enter: 'Enter your preferred duration'","Lock the guest into defaults -- every field must feel freely adjustable"],"example_good":"Here is your proposed schedule, based on your exploration. Most guests at this listing book Mon-Fri for 8 weeks. Adjust anything that does not fit, or submit as-is.","example_bad":"Create your proposal. Select your start date, end date, preferred days, and schedule pattern."},"animation_feel":{"easing":"Instant state change for field edits (no easing needed); cubic-bezier(0.16, 1, 0.3, 1) at 200ms for dependent field ripple updates; cubic-bezier(0.34, 1.56, 0.64, 1) at 500ms for submission confirmation","feel_description":"The proposal form should feel like a tuning instrument, not a construction site. Adjusting one parameter produces a calm ripple through dependent fields -- the end date shifts, the price updates -- creating the sensation of fine-tuning a plan rather than building it. The submission confirmation uses spring easing to mark the transition from 'configuring' to 'committed' -- a distinct emotional beat that says 'your plan is real now.'","duration_range":"100-200ms for direct edits, 200-300ms for dependent updates, 500ms for submission"},"tension_relief":{"tension_point":"The guest faces a multi-parameter form for an arrangement they have no prior experience configuring","relief_point":"The form appears pre-filled with a viable configuration derived from the guest's own exploration, requiring only confirmation or adjustment","timing":"Instant relief on form load -- the guest sees a complete proposal, not a blank form"},"personalization_signals":["Carry forward the exact days the guest selected on the interactive calendar as the pre-filled schedule","Show how the proposal compares to the listing's typical booking: 'This is similar to what most guests at this listing choose'","After editing a field, show the guest's custom choice alongside the default: 'You chose 10 weeks (most guests choose 8)'"],"anti_patterns":[{"pattern":"Presenting a blank multi-step form wizard that forces sequential parameter entry","reason":"A multi-step wizard compounds the emotional burden: the guest cannot see the whole picture, must make each choice in isolation without context, and feels like they are in a bureaucratic process rather than confirming a plan. The emotional trajectory is anxiety at each step, not calm overview.","example_bad":"Step 1 of 4: Select your start date. [Next] Step 2 of 4: How many weeks would you like? [Next] Step 3 of 4: Which days? [Next] Step 4 of 4: Review and submit."}]},{"id":"feels-005","type":"emotional_element","title":"Accomplishment Through Post-Acceptance Preparation","journey_phases":["acceptance","move_in"],"problem":"After accepting a proposal, the guest experiences the emotional relief of 'it is done' -- they secured housing. This relief is genuine and deserved, but it triggers what Thaler and Sunstein call postcompletion error: the main task feels finished, so attention to follow-up details (lease terms, payment confirmation, move-in preparation) drops precipitously. The emotional danger is not carelessness; it is the natural human tendency to disengage after achieving a goal. The guest who skips lease review or ignores move-in instructions will arrive unprepared, generating anxiety at the worst possible moment (first night in an unfamiliar co-tenancy arrangement). The challenge is that forcing the guest through post-acceptance steps risks converting their relief into annoyance -- 'I already said yes, why are you making me do more work?'","solution":"The emotional principle is: frame post-acceptance steps as preparation for something exciting, not compliance with something bureaucratic. Each checkpoint should feel like getting ready for a trip, not signing legal documents. The forcing functions (gated sequence: lease summary, payment confirmation, move-in prep) are structurally necessary to prevent postcompletion errors, but their emotional tone must be forward-looking and celebratory. Each completed checkpoint should produce a small moment of accomplishment -- a progress bar advancing, a checkmark appearing -- building the emotional narrative 'I am getting ready' rather than 'I am being forced to read fine print.' The final state ('You are ready for move-in') should feel like the emotional peak of the sequence: all preparation is done, and the guest can look forward to arrival with confidence rather than anxiety.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Leaving the gas cap behind is a special kind of mistake psychologists call a postcompletion error. The idea is that when you have finished your main task, you tend to forget things relating to previous steps.","insight":"The postcompletion error is emotionally driven: the relief of completion overrides the attention needed for follow-up. The system cannot rely on the guest's post-decision motivation to process details. It must use the guest's existing positive emotions (excitement about the upcoming move) as fuel for the preparation steps."},{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Another strategy, suggested by Don Norman, is to use what he calls a 'forcing function,' meaning that in order to get what you want, you have to do something else first.","insight":"The forcing function is structurally necessary, but its emotional framing determines whether the guest experiences it as protection or as obstruction. 'You must review these terms before proceeding' feels like obstruction. 'Here is what to expect when you arrive -- got it? Great, next step' feels like helpful preparation."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well and when they are making mistakes.","insight":"Each checkpoint completed is an opportunity for positive emotional feedback: 'You are doing well, you are getting ready.' The progress bar, the checkmarks, the positive framing of each acknowledge button -- these are emotional signals that transform a compliance task into an accomplishment sequence."}],"priority":"medium","target_emotion":"momentum","emotion_rationale":"At acceptance, the guest has just made a commitment and feels relief. The system needs to convert that relief into forward momentum -- the feeling of 'I am actively preparing for something good' -- before the relief becomes complacency. Momentum keeps the guest engaged through the post-decision steps.","copy_guidelines":{"voice":"forward-looking, warm, celebratory-practical","do":["Frame each checkpoint as preparation: 'Getting ready for your move-in' not 'Terms and conditions'","Use positive acknowledge language: 'Got it, next step' not 'I confirm I have read and understood'","End with an emotionally satisfying completion message: 'You are ready for move-in' with a summary of what the guest confirmed"],"dont":["Use legal language at the checkpoint level: 'By clicking confirm, you acknowledge...'","Present checkpoints as obstacles between the guest and their goal","Combine all post-acceptance information into a single overwhelming document"],"example_good":"Almost there -- 3 quick steps to get you ready. Step 1: Your lease at a glance (5 key points). Step 2: Confirm your payment. Step 3: Your move-in day plan. [Got it, next step]","example_bad":"Before you can access your move-in details, please review and accept the following lease agreement (12 pages). By clicking Accept, you confirm that you have read and understood all terms and conditions."},"animation_feel":{"easing":"cubic-bezier(0.16, 1, 0.3, 1) for checkpoint transitions; cubic-bezier(0.34, 1.56, 0.64, 1) for the final completion celebration","feel_description":"Checkpoint transitions should feel like steady forward progress -- a completed card collapses upward as the next one appears from below, creating a spatial metaphor of moving forward. The pace is deliberate but not slow -- each transition takes about 400ms, which is slightly slower than the exploratory calendar interactions, communicating that each step deserves attention. The final completion moment uses spring easing to create a distinct celebration beat: the arrangement is confirmed, the preparation is done, and the guest can feel genuinely ready.","duration_range":"350-450ms for checkpoint transitions, 500ms for final celebration"},"tension_relief":{"tension_point":"The guest has committed but has not yet reviewed the details of what they committed to -- a low-grade anxiety that 'I might have missed something important'","relief_point":"The final checkpoint completion: 'You are ready for move-in' -- the guest has reviewed everything and can look forward without nagging uncertainty","timing":"Under 3 minutes for the entire checkpoint sequence"},"personalization_signals":["Show the guest's specific lease terms (their listing, their dates, their price) rather than generic lease language","Include the guest's move-in date and address in the final confirmation: 'You are arriving at [address] on [date]'","After completion, store the checkpoint summaries in the guest's dashboard as reference -- showing that the platform remembers what they reviewed"],"anti_patterns":[{"pattern":"Presenting a single 'I agree to all terms' checkbox that gates the entire post-acceptance flow","reason":"A single checkbox is emotionally dishonest -- it asks the guest to affirm something they almost certainly did not do (read every term). It also misses the opportunity to build accomplishment through progressive checkpoints. The guest clicks without reading and arrives unprepared, which is exactly the postcompletion error the system should prevent.","example_bad":"I have read and agree to the lease terms, house rules, payment schedule, and move-in instructions. [Check to proceed]"}]},{"id":"feels-006","type":"emotional_element","title":"Visible Value Counterbalancing Ongoing Friction","journey_phases":["active_lease"],"problem":"During the active lease phase, per-stay tasks (cleaning photo uploads, arrival notifications, schedule confirmations) are emotionally salient because they require effort at specific moments -- they are the 'taxi meter' of co-tenancy. The ongoing benefit (savings vs. solo rental, schedule flexibility, guaranteed housing) is emotionally invisible because it is diffuse and chronic. Thaler and Sunstein's observation that 'every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks' captures the emotional dynamic precisely: the guest feels the friction of each cleaning photo upload but does not feel the $780/month they are saving compared to a solo rental. Over time, this salience imbalance erodes satisfaction: the arrangement feels burdensome even when it is objectively advantageous. The guest's emotional experience is dominated by micro-obligations, not by the macro-benefit that makes those obligations worthwhile.","solution":"The emotional principle is: make the invisible benefit felt at the moment the visible cost is experienced. At every friction touchpoint, surface one personalized, data-driven benefit metric -- not as a justification ('this is why you should not complain') but as a reminder of reality ('here is what your arrangement is actually doing for you'). The emotional positioning is gratitude, not persuasion: the guest should feel 'oh right, this is saving me a lot' rather than 'they are trying to make me feel better about this chore.' The benefit strip appears after the task is completed, not before -- the guest does the work first (no manipulation), then absorbs the benefit signal during the cognitive release after task completion. The data must be real, personalized, and current -- generic marketing claims would feel manipulative; real savings numbers feel validating.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"The most important modification that must be made to a standard analysis of incentives is salience. Do choosers actually notice the incentives they face?","insight":"The benefit of co-tenancy is an incentive the guest does not emotionally notice because it is chronic and invisible. Making it salient at friction touchpoints is not manipulation; it is correcting a perceptual imbalance. The guest is already 'noticing' the costs (they are performing them); they deserve to equally notice the benefits."},{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"every time the family uses a taxi, the cost will be in their face, with the meter clicking every few blocks. So a behavioral analysis of the incentives of car ownership will predict that people will underweight the opportunity costs of car ownership.","insight":"Per-stay tasks are emotionally experienced as the 'taxi meter' -- each one makes the guest feel the cost of the arrangement. Without the benefit strip, the guest emotionally overweights these salient micro-costs and underweights the diffuse macro-benefit. The benefit strip is the emotional equivalent of showing the guest their monthly savings every time the taxi meter clicks."},{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"An excellent way to help Humans improve their performance is to provide feedback. Well-designed systems tell people when they are doing well.","insight":"The benefit strip is positive performance feedback: 'you are doing well, your arrangement is working for you.' During active lease, the only other feedback the guest receives is task-related ('upload your photo'). Without positive benefit feedback, the guest's emotional experience of active lease is pure obligation -- no sense of reward or progress."}],"priority":"medium","target_emotion":"confidence","emotion_rationale":"During active lease, the guest needs ongoing emotional confidence that their decision to choose co-tenancy was the right one. Each friction touchpoint is a micro-moment of doubt ('is this worth it?'). The benefit strip provides a micro-answer ('yes, here is the evidence') that sustains confidence across the lease duration.","copy_guidelines":{"voice":"factual, personalized, quietly affirming","do":["Use real, personalized data: 'You have saved $2,340 vs. solo rental this quarter'","Rotate benefit categories across touchpoints: savings, flexibility usage, positive host feedback","Keep the benefit statement to a single line -- a quiet aside, not a sales pitch"],"dont":["Use generic marketing claims: 'Split Lease guests save up to 40%!'","Frame benefits as justification for the friction task: 'Uploading photos keeps your savings going!'","Show benefit data before the task is completed -- it would feel like a bribe"],"example_good":"This quarter: $2,340 saved vs. solo rental in Midtown. [Appears below the completed cleaning photo upload]","example_bad":"Remember, your Split Lease arrangement saves you money every month! Keep up the great work by uploading your cleaning photos on time."},"animation_feel":{"easing":"No entrance animation -- the strip is simply present. cubic-bezier(0.16, 1, 0.3, 1) at 500ms for the post-task fade. cubic-bezier(0.34, 1.56, 0.64, 1) at 500ms for quarterly milestone expansions.","feel_description":"The benefit strip should feel like a quiet, stable presence -- not an intrusion. It does not animate in; it is simply there when the task is done, like a note left on a table. The guest discovers it rather than being presented with it. At milestone moments (quarterly summaries, 6-month anniversaries), a brief spring expansion creates a gentle celebratory beat that distinguishes rare affirmations from routine reinforcement.","duration_range":"0ms entrance (instant), 3000ms linger after task, 500ms fade"},"tension_relief":{"tension_point":"The guest is performing a per-stay friction task and feeling the micro-cost of the arrangement","relief_point":"After completing the task, the benefit strip provides a data-driven reminder of the macro-benefit, rebalancing the guest's perception","timing":"Benefit strip visible for 3 seconds after task completion, ensuring the freed cognitive resources can absorb it"},"personalization_signals":["Use the guest's actual cumulative savings, not projected or average figures","Reference the guest's specific listing and neighborhood: '$2,340 saved vs. solo rental in Midtown' not 'vs. average market rate'","Adapt the benefit category to what matters most at the guest's tenure stage: savings for new guests, flexibility for mid-tenure, relationship quality for long-tenure"],"anti_patterns":[{"pattern":"Showing benefit reinforcement during error-recovery flows (e.g., re-uploading rejected photos)","reason":"When the guest is frustrated (task failed, must redo), showing a savings number feels tone-deaf and dismissive -- as if the platform is saying 'stop complaining, look how much you save.' Benefit reinforcement should only appear during standard, non-error friction touchpoints to avoid the perception of emotional manipulation.","example_bad":"Your cleaning photos were not accepted. Please re-upload. [Benefit strip below: 'You have saved $2,340 this quarter!']"}]}]}</script>
  <!-- INJECT:layer-6 -->
  <script id="data-layer-6" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"reinforcements":[{"new_element_id":"works-001","existing_element_id":"works-001 (System 1 Trust Gate at Every Phase Transition)","similarity":"Both address the critical first-contact qualification moment. The existing library element prescribes passing System 1's automatic assessment at every phase transition through visual consistency and familiar language. The new element prescribes surfacing hard eligibility constraints (6-week minimum, 3-week lead time) before any engagement to prevent ineligible prospects from investing effort. Both share the core principle: the system must communicate its fundamental nature before demanding the user's commitment.","combined_evidence":"Library evidence from Kahneman: System 1 generates impressions in under 2 seconds that determine whether System 2 engages. New evidence from Thaler/Sunstein: stimulus-response compatibility requires the discovery signal to match the actual service constraints. Combined insight: the discovery phase must pass both the System 1 trust check (does this look legitimate?) AND the stimulus-response compatibility check (does this match my need?). The Sophie Charvet call proves that even when System 1 trust is achieved (she called willingly), stimulus-response incompatibility still causes 100% dropout. Both checks are necessary; neither alone is sufficient.","recommendation":"keep_both"},{"new_element_id":"works-005","existing_element_id":"works-002 (Design for the Depleted User at Every Step After the First)","similarity":"Both address the problem of users facing complex, multi-parameter decisions without guidance. The existing library element prescribes smart defaults that produce good outcomes when accepted without deliberation, citing Kahneman's ego depletion research. The new element prescribes smart defaults for the proposal form specifically, citing Thaler/Sunstein's defaults chapter. The theoretical foundation is identical: depleted or unfamiliar users need pre-populated starting points, not blank forms.","combined_evidence":"Library evidence: Kahneman's parole judge study shows depleted decision-makers default to denial (abandonment). New evidence: Thaler/Sunstein show that the path of least resistance dominates -- without defaults, abandonment is the easiest option. Combined: both lenses independently identify smart defaults as the single most impactful intervention for complex configuration tasks. The host lens applies it to listing creation (6-step wizard); the guest lens applies it to proposal creation (multi-parameter co-tenancy configuration). The principle generalizes: every multi-parameter form in the platform should arrive pre-filled.","recommendation":"keep_both"},{"new_element_id":"works-004","existing_element_id":"works-003 (Match Platform Cognitive Speed to Phone Call Speed)","similarity":"Both address the gap between conversational comprehension and platform comprehension. The existing element prescribes matching the platform's cognitive speed to the phone call's conversational speed. The new element prescribes concrete visual representations (calendar, daily-life narratives) to make the co-tenancy model comprehensible without verbal explanation. Both identify the same root problem: the phone call communicates complex arrangements in seconds, while the platform fails to achieve equivalent clarity.","combined_evidence":"Library evidence: Andreas describes two units in 7 seconds; the platform must match this density. New evidence: the agent's 23-second verbal explanation of the co-tenancy model is incomprehensible even in conversation. Combined: some information (unit descriptions) transfers well from speech to digital if the platform matches conversational speed. Other information (the co-tenancy model) is so complex that even speech fails -- the platform must exceed conversational clarity by using visual representations (calendar, day-by-day narrative) that are impossible in a phone call.","recommendation":"keep_both"},{"new_element_id":"feels-001","existing_element_id":"works-004 (Bridge Human Trust to Digital Trust Through Continuity Priming)","similarity":"Both address the emotional quality of first contact. The existing element focuses on bridging human trust (from the agent call) to digital trust (on the platform). The new element focuses on creating emotional safety through immediate clarity about service constraints. Both share the principle that the first seconds of interaction must establish emotional legitimacy before asking for engagement.","combined_evidence":"Library evidence: Kahneman's priming research shows that prior exposure shapes evaluation. The platform must echo the human call to inherit trust. New evidence: Thaler/Sunstein's stimulus-response compatibility shows that emotional signals must match outcomes. Combined insight: the discovery phase must achieve both trust priming (existing) AND constraint clarity (new). A guest who trusts the platform but discovers it cannot serve their need (Sophie) is just as lost as a host who finds the platform but does not trust it (unprimed Andreas). Both emotional conditions must be met.","recommendation":"keep_both"}],"contradictions":[{"new_element_id":"looks-003","existing_element_id":"tokens.json accent color","conflict":"The looks-003 element specifies accent (#2d5a3d) for guest day fills in the co-tenancy calendar. The MEMORY.md notes a token drift: tokens.json uses warm green accent (#2d5a3d) but production uses purple (#31135D). If the calendar is built with the tokens.json green but the production environment uses purple, the calendar's color-coded day system would clash with the surrounding UI. The green accent is semantically appropriate for the calendar (guest days feel 'active' and 'natural'), but if the production accent is purple, the calendar would need its own semantic token.","evidence_comparison":"The tokens.json file is the canonical design token system and specifies #2d5a3d. However, MEMORY.md notes production CSS uses purple #31135D. The new elements were designed against tokens.json and are internally consistent. The production drift is the weaker source (undocumented, informal note). Recommendation: resolve the token drift at the system level before implementing any new visual patterns.","recommendation":"Flag for human review. The calendar color system in looks-003 is coherent with tokens.json but may conflict with production CSS. Resolve the accent color token drift first, then implement visual patterns against the resolved token.","severity":"warning"}],"extensions":[{"new_element_id":"works-001","gap_filled":"Pre-call eligibility qualification for guests. The existing library has strong coverage of host qualification (agent-to-platform handoff) but no element addressing the scenario where an ineligible guest reaches a human agent before learning basic service constraints. This is the first element to address automated disqualification before human contact.","confidence_note":"High confidence from a single lens. The Sophie Charvet call is a clean, unambiguous example of the problem -- a 100% preventable wasted interaction. The Nudge chapter on stimulus-response compatibility provides strong theoretical grounding. However, this single lens cannot determine the frequency of ineligible arrivals. Future lenses should quantify how often this pattern occurs."},{"new_element_id":"works-002","gap_filled":"Graceful redirect path for ineligible or mismatched prospects. The library has no element addressing what happens after disqualification. All existing elements assume the user is a viable prospect. This element fills the 'dead-end recovery' gap -- designing the exit path to capture future value rather than abandoning the prospect.","confidence_note":"Moderate confidence. The Sophie call provides strong qualitative evidence (the agent's verbal dead end captured zero future value). The Nudge 'expect error' principle is well-grounded. However, the proposed mechanisms (email capture, share link, referral path) are untested hypotheses. Future lenses should validate whether ineligible prospects would actually engage with redirect mechanisms."},{"new_element_id":"works-006","gap_filled":"Proxy-guest accommodation. The library has no element addressing the scenario where the person searching is not the person who will live in the space. Sophie was searching for a visiting family member -- a pattern that likely recurs (corporate arrangers, family members, relocation agents). This is entirely new territory for the library.","confidence_note":"Moderate confidence from a single lens. Sophie is one clear example of the proxy pattern. The Nudge 'Who chooses? Who uses?' framework provides strong theoretical grounding. However, the frequency and diversity of proxy-guest scenarios is unknown. Future lenses should seek additional proxy-guest instances to validate the pattern's prevalence."},{"new_element_id":"communicates-002","gap_filled":"Zero-result state information architecture. The library covers information architecture for states where options exist but not for states where the choice set is empty. This element addresses the design of structured dead-end experiences -- what the platform communicates when it has nothing to offer the current user.","confidence_note":"High confidence. Zero-result states are a guaranteed occurrence for any platform with eligibility constraints. The Nudge 'Structure Complex Choices' principle extends naturally to structuring zero-result states. The three-tier model (diagnosis, reframe, capture) is a sound architectural pattern regardless of specific implementation."},{"new_element_id":"communicates-006","gap_filled":"Transferable information format for proxy guests. The library's information architecture assumes the viewer is the end user. This element introduces a distinct information layer designed for transfer: compact, objective, shareable summaries that a proxy can forward to the actual decision-maker without requiring them to have an account or context.","confidence_note":"Moderate confidence. Sophie's explicit signal ('I won't read that myself') provides clear evidence that the standard information format fails for proxies. The proposed shareable summary card is a reasonable solution but would benefit from validation with additional proxy-guest scenarios."},{"new_element_id":"looks-007","gap_filled":"Benefit salience reinforcement during active lease friction. The library has no visual element that counterbalances per-stay friction costs with visible benefit data. This is the first element to address the salience asymmetry between visible costs and invisible benefits during ongoing platform use.","confidence_note":"Moderate confidence. The Nudge taxi-meter analogy provides excellent theoretical grounding for the salience problem. The proposed benefit strip is a reasonable visual intervention. However, the emotional impact of benefit reinforcement during friction moments needs empirical validation -- it could feel supportive or patronizing depending on execution."},{"new_element_id":"behaves-005","gap_filled":"Counter-proposal change-diff feedback during negotiation. The library has no element addressing how the system communicates changes between proposal versions during negotiation. This element introduces a diff-view interaction pattern that isolates what changed, why it matters, and what the guest should do about it.","confidence_note":"Moderate confidence. The Nudge 'Give Feedback' and 'Expect Error' principles provide strong theoretical grounding. The diff-view pattern is well-established in other domains (code review, document editing) but is novel for rental proposal negotiation. Needs validation that guests interpret a diff view correctly in this context."}],"token_compliance":{"new_tokens_flagged":["constraint-bg (looks-001): a slightly tinted surface color for constraint data containers","redirect-card-bg (looks-002): a warm surface color for the redirect card, between surface-warm and accent-light","calendar-guest-active / accent-bright (looks-003): a brighter variant of accent for active/selected guest days -- NOTE: accent-bright (#3a7a52) already exists in tokens.json, so this may not need a new token","calendar-cotenant-fill (looks-003): a warm neutral for co-tenant days, possibly bg-deep (#eae7e1)","default-field-bg (looks-004): a barely-there tint for pre-filled default fields","card-share-width (looks-006): a fixed max-width token for the shareable card (~360px)","card-share-photo-height (looks-006): a fixed height for listing photo thumbnails (~120px)","progress-complete (looks-005): may reuse accent or accent-bright for progress bar fill","checkpoint-active-border (looks-005): a 2px accent border for the active checkpoint card"],"recommendation":"Of the 9 flagged tokens, 3 are likely reusable from existing tokens (calendar-guest-active maps to accent-bright, calendar-cotenant-fill maps to bg-deep, progress-complete maps to accent). The remaining 6 are genuinely new semantic tokens. Recommend adding constraint-bg, redirect-card-bg, and default-field-bg as semantic surface variants to tokens.json since they address distinct UI states (qualification, dead-end, pre-filled) that will recur across the platform. The card-share-width and card-share-photo-height are layout tokens that belong in a component token layer rather than the global token file. The checkpoint-active-border can be expressed as a border style using existing accent and radius tokens."},"emotional_arc_check":{"journey_emotion_map":[{"phase":"discovery","target_emotions":["safety","clarity"],"source_element":"feels-001"},{"phase":"search","target_emotions":["safety","relief"],"source_element":"feels-001, feels-002"},{"phase":"listing_evaluation","target_emotions":["confidence","curiosity"],"source_element":"feels-003"},{"phase":"proposal_creation","target_emotions":["calm","ease"],"source_element":"feels-004"},{"phase":"negotiation","target_emotions":["control","clarity"],"source_element":"feels-004 (negotiation overlap)"},{"phase":"acceptance","target_emotions":["momentum","accomplishment"],"source_element":"feels-005"},{"phase":"move_in","target_emotions":["readiness","confidence"],"source_element":"feels-005"},{"phase":"active_lease","target_emotions":["confidence","validation"],"source_element":"feels-006"}],"arc_conflicts":["Minor: the discovery phase targets 'safety' while the search phase targets both 'safety' and 'relief.' For guests who pass the eligibility check (eligible prospects), the safety emotion at discovery should transition to confidence at search, not linger as safety. The 'relief' target at search applies specifically to the dead-end redirect path (ineligible prospects), creating a fork in the emotional arc. This is not a contradiction but should be documented: eligible and ineligible guests have different emotional arcs from search onward.","Minor: the transition from 'curiosity' at listing_evaluation to 'calm' at proposal_creation assumes the guest has resolved their uncertainty about the co-tenancy model. If the interactive calendar fails to build sufficient confidence, the guest may arrive at the proposal form still anxious. The feels-003 to feels-004 transition depends on the success of the calendar interaction -- if the calendar is skipped or poorly implemented, the emotional arc breaks."],"arc_assessment":"The emotional arc is coherent end-to-end and well-grounded in the Nudge choice architecture framework. The progression from safety (discovery) through curiosity (evaluation) to calm (proposal) to momentum (acceptance) to confidence (active lease) follows a natural escalation of emotional investment that mirrors the guest's increasing commitment. The arc's strongest feature is its treatment of ineligible guests: the safety-to-relief transition for mismatched prospects is emotionally respectful and distinct from the eligible-guest arc. The arc's weakest point is the calendar-dependent transition from curiosity to calm -- this is a single-point-of-failure in the emotional journey. If the calendar interaction does not build confidence, the entire downstream arc (calm, momentum, confidence) is undermined. Recommendation: ensure the calendar interaction is tested for emotional impact, not just informational comprehension."},"coverage_map":{"discovery":{"element_count":14,"coverage":"strong"},"search":{"element_count":12,"coverage":"strong"},"listing_evaluation":{"element_count":10,"coverage":"moderate"},"proposal_creation":{"element_count":10,"coverage":"moderate"},"negotiation":{"element_count":4,"coverage":"thin"},"acceptance":{"element_count":6,"coverage":"moderate"},"move_in":{"element_count":6,"coverage":"moderate"},"active_lease":{"element_count":4,"coverage":"thin"}},"loop_back_recommendations":[{"layer":"1","reason":"Works layer should examine whether the eligibility disqualification gate (works-001) needs to handle not just duration/lead-time mismatches but also geographic mismatches (guest searching in a city where Split Lease does not operate) and price mismatches (guest's budget below minimum). The Sophie call exposed only the temporal dimension of mismatch; other dimensions likely exist.","new_input":"Data on inbound call topics: what percentage of calls involve temporal mismatches (like Sophie) vs. geographic, price, or model mismatches? This would prioritize which qualification dimensions to automate first."},{"layer":"3","reason":"The looks layer proposes several new tokens (constraint-bg, redirect-card-bg, default-field-bg) that should be validated against the existing token system and the production accent color drift before implementation. The calendar visualization (looks-003) is the single most critical visual element in this run and should receive dedicated visual design iteration.","new_input":"Resolve the accent color token drift (tokens.json #2d5a3d vs. production #31135D) before finalizing any visual elements that depend on accent as a primary semantic color. The calendar color system specifically requires this resolution."},{"layer":"5","reason":"The feels layer has strong coverage for the discovery-through-acceptance arc but thinner coverage for active lease. The benefit salience reinforcement (feels-006) is the only emotional element for the ongoing lease experience. Given that active lease is the longest phase (13+ weeks minimum), additional emotional elements may be needed for milestone moments, friction-fatigue recovery, and renewal consideration.","new_input":"Cross-reference with the library's existing active-lease emotional elements from other runs (particularly the Stays Manager convergence pattern). The Sophie lens did not produce active-lease call evidence, but the Nudge framework's salience and feedback principles have additional implications for long-duration engagement that were not fully explored."}]}</script>
  <!-- INJECT:layer-7 -->
  <script id="data-layer-7" type="application/json">{"lens":{"guest_call":"Sophie Charvet - 18 April 2022.txt","book_extract":"nudge-choice-architecture.txt"},"elements":[{"id":"tests-001","type":"validation_strategy","title":"Upfront Eligibility Disqualification Gate Validation","validates_element":"works-001","journey_phases":["discovery","search"],"problem":"If the eligibility gate is poorly implemented, ineligible prospects may still reach human agents (gate too subtle or positioned too late), or eligible prospects may be falsely turned away (gate too aggressive or poorly worded). Both failure modes waste resources and lose potential guests.","solution":"Run a quantitative comparison of inbound call qualification rates before and after gate deployment, combined with a task-based usability test to verify that both eligible and ineligible prospects correctly self-classify within 10 seconds of encountering the gate.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 0:26-1:00","type":"guest_call","quote":"I need to understand how I can help you the best, because you mentioned something because you need it almost next week and, uh, zap something too quick.","insight":"Sophie's call is the baseline failure: an ineligible prospect consuming agent time. The test must verify this scenario is eliminated or dramatically reduced."},{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action.","insight":"The validation must confirm stimulus-response alignment: ineligible prospects receive a redirect signal, eligible prospects receive a proceed signal, and neither group misreads the gate."}],"priority":"high","validation_method":"analytics","test_description":"Track the percentage of inbound calls where the caller's need falls below service minimums (sub-6-week duration or sub-3-week lead time). Measure this baseline before deploying the eligibility gate, then compare after deployment. Complement with a task-based usability test: give 10 participants a scenario (5 eligible, 5 ineligible) and observe whether they correctly identify their eligibility status within 10 seconds of encountering the gate.","success_criteria":"60% or greater reduction in inbound calls from prospects with sub-6-week needs within 30 days of gate deployment. In the usability test, 9 out of 10 participants correctly self-classify (eligible proceeds, ineligible redirects) within 10 seconds. Zero false-disqualification errors (eligible prospect incorrectly told they do not qualify).","failure_meaning":"If ineligible calls do not decrease, the gate is not visible or not positioned early enough in the discovery flow. If eligible prospects are falsely turned away, the constraint language is too aggressive or ambiguous. If self-classification takes longer than 10 seconds, the constraint information requires fewer words or more visual prominence.","implementation_hint":"Analytics: tag inbound calls with caller-stated duration and lead time. Compare pre/post gate deployment. Usability: Maze or UserTesting.com unmoderated test with 10 participants, 2 scenarios each. Playwright: verify that entering a duration under 6 weeks triggers the inline eligibility feedback within 200ms."},{"id":"tests-002","type":"validation_strategy","title":"Graceful Redirect Email Capture Validation","validates_element":"works-002","journey_phases":["discovery","search"],"problem":"If the redirect path is poorly implemented, ineligible prospects may leave without engaging with any capture mechanism (email field not prominent enough, value proposition not compelling), or may feel manipulated (the redirect feels like a sales trap rather than a helpful pivot).","solution":"Measure email capture rate from ineligible prospects and qualitative sentiment of the redirect experience through post-interaction surveys.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you... if you ever need something in this type of arrangement, but it was a little more lead time. We'll be happy to help you.","insight":"The current verbal redirect captures zero future value. Any email capture rate above 0% represents improvement over the baseline."}],"priority":"high","validation_method":"analytics","test_description":"Track email capture rate from prospects who trigger the ineligibility state. Measure: (1) percentage of ineligible prospects who see the redirect card, (2) percentage who interact with the email field, (3) percentage who submit an email. Additionally, send a one-question follow-up to captured emails within 24 hours: 'How did the experience of learning we could not help you feel?' with a 5-point satisfaction scale.","success_criteria":"20% or greater email capture rate from ineligible prospects. Follow-up satisfaction score of 3.5 or above out of 5 (indicating the redirect felt helpful, not manipulative). Secondary: 15% of shared links (from the redirect card's share mechanism) result in a new prospect interaction within 30 days.","failure_meaning":"If email capture is below 10%, the redirect card's value proposition is not compelling or the email field is not prominent enough. If satisfaction is below 3.0, the redirect feels like a sales trap -- the emotional framing needs revision. If shares are near zero, the share mechanism is not discoverable or not relevant to the proxy/referral use case.","implementation_hint":"Analytics: event tracking on redirect card impression, email field focus, email submission, share button click. Follow-up: automated email via SendGrid or similar, triggered by redirect-card email submission. Include unsubscribe to comply with CAN-SPAM."},{"id":"tests-003","type":"validation_strategy","title":"Elimination-by-Aspects Search Filter Validation","validates_element":"works-003","journey_phases":["search","listing_evaluation"],"problem":"If search filters are poorly implemented, guests may not discover or use them (filters not prominent enough), may find them confusing (filter labels do not match mental models), or may receive zero results without helpful guidance (empty state is a dead end).","solution":"Measure filter adoption rate, zero-result recovery rate, and search-to-listing-click conversion to verify that filters improve the search experience rather than creating new dead ends.","evidence":[{"source":"nudge-choice-architecture.txt, Structure Complex Choices section","type":"book","quote":"Someone using this strategy first decides what aspect is most important, establishes a cutoff level, then eliminates all the alternatives that do not come up to this standard.","insight":"The test must verify that guests naturally apply elimination-by-aspects behavior through the filters, and that the filters surface the right cutoff criteria (duration, timing) as primary options."}],"priority":"high","validation_method":"analytics","test_description":"Track: (1) percentage of search sessions where the guest applies at least one filter before viewing a listing, (2) percentage of zero-result states that produce a guest interaction with the 'what would match' suggestion, (3) search-to-listing-click conversion rate before and after filter deployment. Additionally, run a tree-test or card-sort to verify that filter labels match guest mental models for their primary cutoff criteria.","success_criteria":"80% of search sessions include at least one filter application. Zero-result states show a 'what would match' suggestion in 100% of cases, and at least 30% of zero-result sessions result in the guest adjusting criteria based on the suggestion. Search-to-listing-click conversion improves by 15% or more after filter deployment.","failure_meaning":"If filter adoption is below 50%, filters are not prominent enough or labels do not match guest vocabulary. If zero-result recovery is below 15%, the 'what would match' suggestion is not compelling or not visible. If conversion does not improve, filters may be too restrictive or may filter out listings that would have been interesting to the guest.","implementation_hint":"Analytics: Mixpanel or Amplitude event tracking on filter interactions, zero-result impressions, and suggestion clicks. Tree test: Optimal Workshop with 20+ participants to validate filter label taxonomy. Playwright: verify that selecting duration '4 weeks' triggers the zero-result state with a 'what would match' suggestion within 500ms."},{"id":"tests-004","type":"validation_strategy","title":"Co-Tenancy Model Comprehension Validation","validates_element":"works-004","journey_phases":["listing_evaluation","proposal_creation"],"problem":"If the co-tenancy visual mapping is poorly implemented, guests may still not understand the shared-space model after viewing a listing (calendar is confusing, daily-life narrative is insufficient), or may understand it intellectually but not feel confident enough to proceed (comprehension without comfort).","solution":"Run a comprehension test where participants view a listing with the co-tenancy calendar and narrative, then answer factual questions about the arrangement. Complement with a confidence survey measuring whether comprehension translates to willingness to proceed.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 2:10-2:33","type":"guest_call","quote":"The way we do it with the two people was complimentary schedule... somebody needs Monday through Friday and somebody else needs Friday. So Monday they become, goes to amaze, which use the same space, but in different timeframes.","insight":"The agent's verbal explanation is nearly incomprehensible. Any comprehension score above the verbal-explanation baseline represents improvement."}],"priority":"high","validation_method":"usability_test","test_description":"Recruit 10 participants who have never experienced co-tenancy housing. Show them a listing page with the calendar visualization and daily-life narrative. Ask 5 factual questions: (1) Which days would you have access to the space? (2) When would you arrive and depart? (3) Who else uses the space? (4) Where would you keep your belongings? (5) What happens on your transition day? Score: correct answers out of 5. Then ask a confidence question: 'On a scale of 1-5, how confident are you that you understand what living in this arrangement would be like?' Compare against a control group that receives only a text description (mirroring the agent's verbal explanation).","success_criteria":"Treatment group (calendar + narrative) scores an average of 4.0 or above on factual comprehension (out of 5) and 3.5 or above on the confidence scale. Treatment group outperforms control group (text-only) by at least 1.5 points on comprehension and 1.0 points on confidence.","failure_meaning":"If comprehension is below 3.0, the calendar visualization is not clear enough -- likely the day-color distinction is insufficient or the legend is missing. If comprehension is high but confidence is low, the guest understands the model but finds it anxiety-inducing -- the daily-life narrative needs to be more reassuring and concrete. If the control group performs equally, the calendar adds visual complexity without informational gain.","implementation_hint":"Usability: UserTesting.com or Maze unmoderated test, 10 participants per group, screened for no prior co-tenancy experience. Test stimulus: Figma prototype of listing page with interactive calendar. Control stimulus: text-only explanation matching the agent's verbal description. Record time-to-answer for each question as a secondary metric."},{"id":"tests-005","type":"validation_strategy","title":"Smart Default Proposal Completion Rate Validation","validates_element":"works-005","journey_phases":["proposal_creation","negotiation"],"problem":"If smart defaults are poorly calibrated, guests may submit proposals that are unviable (defaults do not reflect listing reality), may feel constrained rather than helped (defaults feel like the platform's preference rather than the guest's), or may not notice that defaults are adjustable (the pre-fill is mistaken for a locked configuration).","solution":"A/B test pre-filled proposal forms against blank proposal forms, measuring completion rate, time-to-completion, and host acceptance rate of submitted proposals.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance.","insight":"The test must verify that smart defaults change the path of least resistance from abandonment to completion. The A/B test directly measures whether defaults achieve this behavioral shift."}],"priority":"medium","validation_method":"a_b_test","test_description":"A/B test with two variants: (A) proposal form pre-filled with smart defaults (based on guest search criteria and listing patterns), (B) blank proposal form with the same fields. Measure: (1) form completion rate (started vs. submitted), (2) median time from form open to submission, (3) percentage of defaults accepted without modification, (4) host acceptance rate of resulting proposals. Run for 4 weeks or until 200 proposals per variant, whichever comes first.","success_criteria":"Variant A (defaults) achieves 50% or higher form completion rate, compared to baseline. Time-to-completion is 60 seconds or less for Variant A vs. baseline for Variant B. At least 40% of defaults are accepted without modification (validating that defaults are reasonable). Host acceptance rate for Variant A proposals is equal to or better than Variant B (defaults do not produce worse proposals).","failure_meaning":"If completion rate does not improve, defaults are not visible enough or the form structure is the bottleneck (not the blank-slate problem). If time-to-completion does not improve, the defaults may not be reducing cognitive load -- possibly because the guest feels compelled to evaluate each default rather than accepting them. If host acceptance drops, defaults are miscalibrated and produce proposals that do not match listing norms. If zero defaults are accepted as-is, the defaults feel prescriptive rather than helpful.","implementation_hint":"A/B test via LaunchDarkly or Optimizely. Assign at variant level per user (not per session) to avoid cross-contamination. Track events: form_opened, field_edited (with field name), form_submitted, proposal_accepted_by_host. Ensure the default calculation logic is logged for each proposal so miscalibrated defaults can be diagnosed."},{"id":"tests-006","type":"validation_strategy","title":"Proxy-Guest Share Link Conversion Validation","validates_element":"works-006","journey_phases":["discovery","search","listing_evaluation","proposal_creation"],"problem":"If the proxy-guest flow is poorly implemented, proxy searchers may not discover the 'search on behalf of someone else' mode (too hidden), may generate share links that the end user ignores (link content not compelling), or the handoff from proxy to actual guest may fail (end user cannot act on the shared information).","solution":"Track the end-to-end proxy-guest funnel: share link generation rate, shared link open rate, and conversion from shared link to actual guest engagement (account creation, listing view, or proposal).","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"Sophie explicitly declined information because she was not the end user. The test must verify that the share link mechanism provides a path Sophie would have used -- forwarding relevant information to her family member."}],"priority":"medium","validation_method":"analytics","test_description":"Track: (1) percentage of listing views that generate a share link (target: 10%), (2) open rate of shared links (via link tracking), (3) conversion from shared link open to a measurable action by the end user (account creation, listing view of 30+ seconds, or proposal initiation). Complement with a qualitative intercept: when a user clicks 'Share this listing,' ask a one-question survey: 'Who are you sharing this with?' with options (family member, colleague, friend, other).","success_criteria":"10% of listing views generate a share link. 40% of shared links are opened by a different user (not the proxy). 15% of opened shared links result in a measurable guest engagement action. The intercept survey reveals the proxy-guest pattern occurs across at least 2 distinct categories (family, corporate, friend).","failure_meaning":"If share link generation is below 5%, the 'Share this listing' button is not discoverable or the proxy-guest mode is not intuitive. If open rate is low, the link preview (as rendered in messaging apps) is not compelling enough to click. If conversion from open to action is near zero, the shared landing page requires too much effort (login wall, missing context) for the end user to engage.","implementation_hint":"Analytics: generate unique trackable links (UTM or custom shortlink) for each share event. Track link generation, link open (via redirect through tracking endpoint), and downstream actions via user session matching. Intercept: one-question modal on share button click, dismissable, non-blocking."},{"id":"tests-007","type":"validation_strategy","title":"Constraint-First Disclosure Scan Time Validation","validates_element":"communicates-001","journey_phases":["discovery","search"],"problem":"If the constraint-first information hierarchy is poorly implemented, prospects may scan past the constraint data without registering it (typography not prominent enough), may be confused by the constraint statement (too technical or ambiguous), or may perceive the constraints as a barrier rather than helpful disclosure (framing too negative).","solution":"Eye-tracking study or first-click test to verify that constraint data is the first information element registered during discovery page scanning.","evidence":[{"source":"nudge-choice-architecture.txt, Make It Easy / Channel Factors section","type":"book","quote":"Often we can do more to facilitate good behavior by removing some small obstacle than by trying to shove people in a certain direction.","insight":"The test must verify that constraint disclosure functions as an obstacle-removal mechanism (clarifying eligibility) rather than an obstacle itself (discouraging eligible prospects). Scan time and first-fixation data reveal whether the constraint is registered before or after engagement CTAs."}],"priority":"high","validation_method":"usability_test","test_description":"First-click test (via Optimal Workshop or similar): show participants the discovery landing page for 5 seconds, then blank the screen and ask: 'What are the minimum requirements to use this service?' Score: percentage who can recall at least one constraint (6-week minimum or 3-week lead time). Complement with a preference test: show two versions of the discovery page (constraint-first vs. constraint-below-fold) and ask which feels more honest and trustworthy.","success_criteria":"80% of participants recall at least one constraint after 5-second exposure. The constraint-first version is rated more honest/trustworthy by at least 60% of participants in the preference test.","failure_meaning":"If recall is below 50%, the constraint typography does not achieve sufficient prominence in the visual scan order -- the mono typeface treatment or positioning needs revision. If the constraint-first version is rated less trustworthy, the constraint framing may feel like a warning or barrier rather than helpful disclosure -- the copy tone needs adjustment.","implementation_hint":"First-click test: Optimal Workshop, 20 participants, 5-second exposure to a Figma prototype. Preference test: same tool, A/B comparison. If eye-tracking hardware is available (Tobii), run a 5-participant lab study for richer fixation data."},{"id":"tests-008","type":"validation_strategy","title":"Zero-Result Redirect Information Completeness Validation","validates_element":"communicates-002","journey_phases":["discovery","search"],"problem":"If the structured dead-end redirect is incomplete, prospects may leave without understanding why no results matched (diagnosis tier missing or unclear), without knowing what would match (reframe tier missing or uncompelling), or without leaving contact information (capture tier missing or too demanding).","solution":"Task-based usability test where participants are given a scenario that produces zero results, then assessed on their understanding of the mismatch, awareness of alternatives, and willingness to provide an email.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you.","insight":"The baseline is a verbal dead end with zero information structure. The test must verify that all three information tiers (diagnosis, reframe, capture) are comprehended in a single interaction."}],"priority":"high","validation_method":"usability_test","test_description":"Give 10 participants a scenario: 'You need a 1-month apartment in New York starting next week. Search on this platform.' After they encounter the zero-result redirect, ask: (1) Why did no results match? (2) What would you need to change to find a match? (3) Would you leave your email? Why or why not? Score each response for accuracy and completeness. All three tiers should be correctly understood without additional prompting.","success_criteria":"9 out of 10 participants correctly identify the specific mismatch (duration too short or lead time too tight). 8 out of 10 can articulate what would need to change (extend to 6 weeks, plan 3 weeks ahead). At least 6 out of 10 express willingness to leave their email with a clear understanding of the value proposition.","failure_meaning":"If participants cannot identify the mismatch, the diagnosis tier is not specific enough or uses unclear language. If they cannot articulate the adjustment, the reframe tier is not showing concrete alternatives. If email willingness is below 40%, the value proposition for future contact is not compelling or feels like spam.","implementation_hint":"Usability: UserTesting.com unmoderated, 10 participants with no prior Split Lease exposure. Prototype the zero-result state in Figma with the three-tier redirect card. Record think-aloud for qualitative analysis. Code responses as: correct/partial/incorrect for each tier."},{"id":"tests-009","type":"validation_strategy","title":"Co-Tenancy Calendar Visual Schedule Translation Validation","validates_element":"communicates-003","journey_phases":["listing_evaluation","proposal_creation"],"problem":"If the visual schedule calendar is poorly designed, guests may not understand which days are theirs vs. the co-tenant's (color distinction insufficient), may not read the 'what to expect' narrative (positioned too far below), or may find the calendar anxiety-inducing rather than clarifying (the visible presence of 'another guest's days' triggers discomfort rather than comprehension).","solution":"Comprehension and sentiment test combining factual recall with emotional response measurement after calendar exposure.","evidence":[{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"The calendar is the 'free taste' of co-tenancy. The test must verify it functions as a taste (reduces anxiety, builds confidence) rather than a warning label (increases anxiety, triggers avoidance)."}],"priority":"high","validation_method":"usability_test","test_description":"Show 10 participants a listing page with the co-tenancy calendar. After 15 seconds of viewing (no interaction), ask: (1) Which days would be yours? (2) How do you feel about sharing the space on the other days? Rate anxiety from 1-5. After allowing 30 seconds of interaction (hover/tap on days), ask the same questions again. Measure whether interaction reduces anxiety and improves comprehension vs. passive viewing alone. Include colorblind participants (at least 2 out of 10) to validate accessibility of the color system.","success_criteria":"Post-interaction comprehension: 10 out of 10 correctly identify their days. Post-interaction anxiety: average below 2.5 out of 5 (moderate-to-low anxiety). Interaction reduces anxiety by at least 0.5 points vs. passive viewing. Colorblind participants achieve the same comprehension score as non-colorblind participants.","failure_meaning":"If comprehension is low even after interaction, the day-color distinction is insufficient or the legend is unclear. If anxiety remains high, the calendar's presentation of 'other guest's days' is triggering discomfort -- consider reframing (e.g., 'open days' vs. 'other guest's days'). If colorblind participants score lower, the color system relies too heavily on hue and needs additional differentiators (shape, shadow, pattern).","implementation_hint":"Usability: lab test preferred (for precise timing control), 10 participants including 2 screened for color vision deficiency (Ishihara test at intake). If lab not available, UserTesting.com with colorblind screening question. Use Figma interactive prototype with hover states."},{"id":"tests-010","type":"validation_strategy","title":"Default-Anchored Proposal Form Cognitive Load Validation","validates_element":"communicates-004","journey_phases":["proposal_creation","negotiation"],"problem":"If the default-anchored proposal form communicates poorly, guests may not notice the defaults (pre-fills blend into the form background), may not understand the default sources (contextual labels are too small or unclear), or may feel the defaults are manipulative (the platform is pushing a preferred configuration rather than helping).","solution":"Cognitive walkthrough combined with a trust survey to verify that defaults are noticed, understood, and perceived as helpful.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select.","insight":"The test must verify that the pre-filled form achieves the emotional effect of 'someone helped me' rather than the cognitive effect of 'someone decided for me.'"}],"priority":"medium","validation_method":"usability_test","test_description":"Cognitive walkthrough with 8 participants. Present the pre-filled proposal form and ask: (1) What do you see? (identify the defaults), (2) Where did these values come from? (identify the source labels), (3) Can you change them? (demonstrate editability), (4) Do these defaults feel helpful or pushy? Rate on a 5-point scale. Measure time-to-first-edit as a proxy for noticing the defaults -- participants who do not notice defaults will start editing from the first field; those who notice will scan first and edit selectively.","success_criteria":"7 out of 8 participants correctly identify the defaults as pre-filled suggestions. 6 out of 8 can articulate at least one default source ('based on my search'). 8 out of 8 demonstrate that they know how to edit defaults. Helpfulness rating averages 3.5 or above out of 5. Median time-to-first-edit is above 5 seconds (indicating the participant scanned the defaults before editing, not immediately overwriting).","failure_meaning":"If participants do not notice defaults, the visual distinction (italic, muted color) is insufficient. If they cannot identify sources, contextual labels are too small or poorly positioned. If helpfulness is below 3.0, the defaults feel prescriptive -- the framing language needs revision. If time-to-first-edit is under 3 seconds, participants are treating the form as blank despite the pre-fills.","implementation_hint":"Cognitive walkthrough: moderated session, 8 participants, 15 minutes each. Figma interactive prototype with editable fields. Think-aloud protocol. Record screen and audio for analysis."},{"id":"tests-011","type":"validation_strategy","title":"Forcing-Function Checkpoint Completion Validation","validates_element":"communicates-005","journey_phases":["acceptance","move_in"],"problem":"If the forcing-function checkpoint sequence is poorly framed, guests may feel trapped (cannot access their move-in details without clicking through bureaucratic gates), may rush through without actually absorbing the information (clicking 'Got it' without reading), or may abandon the sequence entirely (the checkpoints feel like punishment for saying yes).","solution":"Task-based test measuring both completion rate and information retention across the three checkpoints. Complement with a sentiment measure to distinguish 'I completed the checkpoints and feel prepared' from 'I clicked through the checkpoints to get it over with.'","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"Another strategy, suggested by Don Norman, is to use what he calls a 'forcing function,' meaning that in order to get what you want, you have to do something else first.","insight":"The test must verify that the forcing function prevents postcompletion errors (skipping critical steps) without creating resentment (feeling forced). Both outcomes must be measured."}],"priority":"medium","validation_method":"usability_test","test_description":"Give 10 participants the scenario: 'Your proposal has been accepted. Complete the next steps to get your move-in details.' Measure: (1) completion time for all three checkpoints, (2) information retention: after completing all checkpoints, ask 3 recall questions (one per checkpoint -- key lease term, payment amount, move-in instruction), (3) emotional sentiment: 'Did this process feel helpful or annoying?' on a 5-point scale.","success_criteria":"All 10 participants complete all three checkpoints in under 3 minutes. Average recall score is 2.5 or above out of 3 questions. Sentiment averages 3.5 or above out of 5 (helpful rather than annoying). Zero participants express that they felt 'trapped' or 'forced' in think-aloud commentary.","failure_meaning":"If completion time exceeds 5 minutes, the checkpoint content is too dense or the acknowledge button is not clear. If recall is below 2.0, participants are clicking through without reading -- the content is not scannable enough or the forcing function is not effective at compelling engagement. If sentiment is below 3.0, the checkpoints feel punitive -- the positive framing ('Got it, next step') is not sufficient to offset the gating mechanism.","implementation_hint":"Usability: UserTesting.com moderated or unmoderated, 10 participants. Figma prototype with gated checkpoint sequence. Include think-aloud for qualitative sentiment capture. Retention test administered immediately after final checkpoint."},{"id":"tests-012","type":"validation_strategy","title":"Proxy-Guest Information Transfer Validation","validates_element":"communicates-006","journey_phases":["discovery","search","listing_evaluation"],"problem":"If the shareable listing summary is poorly designed, proxies may not find it useful enough to forward (too much or too little information), end users who receive it may not understand it without context (the summary assumes familiarity with the platform), or the handoff may fail because the end user cannot take action from the shared link (login wall, missing context).","solution":"Two-stage usability test: Stage 1 -- proxy generates and evaluates the shareable summary. Stage 2 -- the proxy's actual forwarding target (or a simulated end user) receives and evaluates the shared link.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma. So I won't read that myself.","insight":"The test must simulate Sophie's scenario: a proxy who will not consume the information themselves but needs to evaluate whether it is worth forwarding to the actual user."}],"priority":"medium","validation_method":"usability_test","test_description":"Stage 1: Give 5 participants the proxy scenario ('Your cousin is visiting New York for 2 months. Find and share a listing option with them.'). Measure: (1) time to generate a share link, (2) proxy's assessment of the summary ('Would you feel confident sending this to your cousin?'). Stage 2: Send the generated summary to 5 different participants acting as end users. Measure: (1) comprehension of the listing without prior platform context, (2) willingness to click through and engage further.","success_criteria":"Stage 1: All 5 proxies generate a share link within 30 seconds. At least 4 out of 5 express confidence in forwarding the summary. Stage 2: At least 4 out of 5 end users correctly identify the key facts (schedule, location, price) from the summary alone. At least 3 out of 5 express willingness to click through for more details.","failure_meaning":"If proxies cannot generate a share link quickly, the share mechanism is not discoverable. If proxies lack confidence in forwarding, the summary is either too sparse (missing critical information) or too dense (overwhelming to evaluate). If end users cannot extract key facts, the summary is not self-contained -- it assumes platform context the end user does not have. If end users will not click through, the summary is either sufficient (no need for more) or insufficient (not compelling enough to investigate).","implementation_hint":"Two-stage test: use UserTesting.com or Maze. Stage 1 participants screened for proxy behavior (have previously searched for housing/travel on behalf of another). Stage 2 participants screened for no prior Split Lease exposure. Share the Figma prototype link between stages."},{"id":"tests-013","type":"validation_strategy","title":"Constraint-Gate Typography Hierarchy Eye-Scan Validation","validates_element":"looks-001","journey_phases":["discovery","search"],"problem":"If the constraint-gate typography does not achieve Position 1 in the visual scan order, the constraint data will be registered after the CTA or brand messaging, defeating the purpose of constraint-first disclosure. The mono typeface treatment may be too subtle or too alarming depending on execution.","solution":"Five-second test measuring first-noticed element and recall of constraint data to verify the typography hierarchy achieves the intended scan order.","evidence":[{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action.","insight":"The visual stimulus (what the eye sees first) must be the constraint data, not the CTA. If the CTA is the first visual stimulus, the guest's automatic action will be to engage, not to self-qualify."}],"priority":"high","validation_method":"usability_test","test_description":"Five-second test: show the discovery landing page for 5 seconds, blank the screen, ask 'What did you notice first?' and 'What are the minimum requirements?' Compare responses across 15 participants. At least 10 should report constraint data as first-noticed. Complement with a contrast/accessibility check: verify that IBM Plex Mono constraint text in ink on surface-warm meets WCAG AAA (15:1 target).","success_criteria":"10 out of 15 participants report constraint data as the first element noticed. 12 out of 15 can recall at least one specific constraint number (6 weeks or 3 weeks) after 5-second exposure. Contrast ratio meets WCAG AAA (7:1 minimum, 15:1 target).","failure_meaning":"If the CTA or imagery is noticed first, the mono constraint typography is not achieving sufficient visual weight -- increase size, add a background container, or adjust positioning. If constraints are noticed but numbers are not recalled, the typography is prominent but the content is not scannable -- reduce word count or increase numeric emphasis.","implementation_hint":"Five-second test: Usability Hub (now Lyssna) or Optimal Workshop, 15 participants, no platform familiarity required. Contrast check: WebAIM contrast checker against the proposed color combinations. If eye-tracking is available, a 5-participant Tobii lab study would provide fixation-order data."},{"id":"tests-014","type":"validation_strategy","title":"Dead-End Redirect Card Emotional Tone Validation","validates_element":"looks-002","journey_phases":["discovery","search"],"problem":"If the redirect card's visual treatment reads as apologetic, diminished, or alarming (error-state red, sad illustrations, small gray text), the prospect will feel rejected rather than redirected. Conversely, if it reads as too cheerful, the prospect may feel their disappointment is being dismissed.","solution":"Semantic differential survey measuring the emotional associations of the redirect card's visual treatment, comparing against standard error-state patterns.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"A well-designed system expects its users to err and is as forgiving as possible.","insight":"The visual treatment must communicate forgiveness, not failure. The test must verify that participants associate the card with 'helpful redirect' rather than 'rejection notice.'"}],"priority":"medium","validation_method":"usability_test","test_description":"Show 10 participants the redirect card in context (after a simulated zero-result search). Ask them to rate the card on semantic differentials: helpful/unhelpful, warm/cold, honest/evasive, forward-looking/final, respectful/dismissive. Compare against a control: a standard empty-state pattern (sad illustration, 'No results found, try again'). Each differential on a 7-point scale.","success_criteria":"The redirect card scores above 5.0 on helpful, warm, and honest scales. It outperforms the standard empty state by at least 1.5 points on all five differentials. No participant uses the word 'rejection' or 'error' in open-ended response.","failure_meaning":"If 'warm' scores below 4.0, the surface color or typography is too clinical -- increase warmth of the background tint. If 'honest' scores below 4.0, the mismatch data is not specific enough -- the diagnosis tier needs more concrete numbers. If 'forward-looking' scores below 4.0, the reframe tier and email capture are not compelling -- the future value proposition needs strengthening.","implementation_hint":"Semantic differential survey: Google Forms or Typeform, embedded after viewing a Figma prototype screen. 10 participants minimum. Include the standard empty-state control as a within-subjects comparison. Randomize presentation order."},{"id":"tests-015","type":"validation_strategy","title":"Co-Tenancy Calendar Color Accessibility Validation","validates_element":"looks-003","journey_phases":["listing_evaluation","proposal_creation"],"problem":"If the two-tone calendar color system fails for colorblind users, the entire co-tenancy comprehension mechanism breaks for approximately 8% of male users. If the contrast ratios for co-tenant day text fail WCAG AA, the calendar is inaccessible for low-vision users.","solution":"Automated contrast ratio testing combined with colorblind simulation review and real-user testing with colorblind participants.","evidence":[{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes.","insight":"The mapping mechanism must work for all users, not just those with typical color vision. If the calendar fails for colorblind users, the mapping is broken for a significant segment."}],"priority":"high","validation_method":"automated","test_description":"Three-part validation: (1) Automated contrast check: verify white text (#ffffff) on accent (#2d5a3d) for guest days and ink-soft (#4a4640) on bg-deep (#eae7e1) for co-tenant days, using WebAIM contrast checker. (2) Colorblind simulation: run the calendar through Stark or Sim Daltonism for protanopia, deuteranopia, and tritanopia. Verify that the day-type distinction remains clear through saturation/value difference and shadow differentiator, not just hue. (3) User test: 3 participants with confirmed color vision deficiency complete the co-tenancy comprehension task from tests-009.","success_criteria":"Guest days: 7:1+ contrast ratio (AAA). Co-tenant days: 4.5:1+ contrast ratio (AA). All three colorblind simulations show a clear visual distinction between day types. All 3 colorblind participants correctly identify their days in the comprehension task.","failure_meaning":"If guest day contrast fails, the text color needs adjustment (unlikely given 7.5:1 expected). If co-tenant day contrast fails, use ink-soft (#4a4640) instead of ink-muted (#8a857e) as specified in the element. If colorblind simulation shows insufficient distinction, add a secondary differentiator: pattern fill, border style, or icon overlay on co-tenant days. If colorblind participants fail comprehension, the entire color system needs redesign with shape-based differentiation.","implementation_hint":"Contrast: WebAIM contrast checker (web-based, free). Colorblind simulation: Stark plugin for Figma (free tier). User test: recruit through AccessibilityOz or similar service specializing in participants with disabilities. Playwright: automated contrast ratio check on rendered calendar component using axe-core."},{"id":"tests-016","type":"validation_strategy","title":"Smart Default Visual Distinction Perception Validation","validates_element":"looks-004","journey_phases":["proposal_creation","negotiation"],"problem":"If the visual distinction between default values (italic, muted color) and user-edited values (regular weight, full ink) is too subtle, users will not notice that defaults are present. If it is too strong, defaults will look like errors or placeholders rather than suggestions.","solution":"A/B perception test comparing the proposed default styling (italic ink-soft) against alternatives (no distinction, placeholder-style gray, underlined) to identify which treatment best communicates 'suggestion, not constraint.'","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance.","insight":"The default styling must be visible enough to be noticed (so the user knows the form is helping) but gentle enough to be accepted (so the user takes the path of least resistance rather than clearing all fields to start fresh)."}],"priority":"medium","validation_method":"usability_test","test_description":"Show 12 participants three styling variants of the pre-filled proposal form: (A) italic ink-soft with contextual labels (proposed design), (B) standard weight ink-muted with no labels, (C) placeholder-style ink-ghost with 'Suggested:' prefix. For each variant, ask: (1) Are these values pre-filled or empty? (2) Can you change them? (3) Does this feel helpful or controlling? Rate 1-5.","success_criteria":"Variant A (proposed): 10+ out of 12 recognize pre-fills. All 12 know they can edit. Helpfulness rating 3.5+. Variant A outperforms B and C on the combination of noticeability and helpfulness. No variant should have more than 2 participants perceiving the defaults as 'controlling.'","failure_meaning":"If Variant A is not recognized as pre-filled by 8+ participants, the italic + muted styling is too subtle -- increase the distinction (darker muted color, contextual label more prominent). If Variant A scores high on noticeability but low on helpfulness, the styling feels too much like 'the system decided for me' -- reduce the visual weight of default values. If Variant C outperforms, users prefer explicit labeling over typographic subtlety.","implementation_hint":"Preference test: Lyssna (formerly UsabilityHub) or Optimal Workshop, 12 participants, within-subjects design (all participants see all three variants in randomized order). Use static Figma screenshots. 5-minute test."},{"id":"tests-017","type":"validation_strategy","title":"Postcompletion Checkpoint Progress Visual Satisfaction Validation","validates_element":"looks-005","journey_phases":["acceptance","move_in"],"problem":"If the progress bar and checkpoint cards are visually overwhelming, the acceptance flow will feel like a bureaucratic gauntlet. If they are too minimal, the guest will not perceive the structure or feel the accomplishment of completing each step.","solution":"Satisfaction and perceived-effort measurement after completing the checkpoint flow, comparing against a baseline experience (single-page terms acceptance with checkbox).","evidence":[{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Well-designed systems tell people when they are doing well.","insight":"The visual checkpoint system must make 'doing well' visible. The test should measure whether participants perceive the progress feedback as rewarding rather than patronizing."}],"priority":"medium","validation_method":"usability_test","test_description":"A/B comparison: (A) three-checkpoint flow with progress bar, checkmarks, and 'Ready for move-in' completion (proposed design), (B) single-page with all terms and a single 'I agree' checkbox (baseline). 10 participants per variant. Measure: (1) perceived effort (1-5 scale), (2) preparedness ('Do you feel ready for move-in?' 1-5), (3) satisfaction with the acceptance experience (1-5).","success_criteria":"Variant A achieves higher preparedness (4.0+) and higher satisfaction (3.5+) than Variant B, even if perceived effort is slightly higher. The three-checkpoint flow should feel like 'more effort but worth it' not 'more effort and annoying.'","failure_meaning":"If Variant A has higher effort AND lower satisfaction, the checkpoints feel punitive. If preparedness scores are equal, the forcing functions are not adding informational value -- participants are clicking through without absorbing. If Variant B outperforms on all measures, the single-page approach is actually preferred (simpler for a post-decision context).","implementation_hint":"A/B: UserTesting.com, 10 participants per variant, between-subjects. Figma interactive prototypes for both variants. Include a 24-hour follow-up for Variant A participants: 'Can you recall 2 of the 5 key lease terms from your checkpoint review?' to test retention."},{"id":"tests-018","type":"validation_strategy","title":"Shareable Listing Card Messaging App Render Validation","validates_element":"looks-006","journey_phases":["discovery","search","listing_evaluation"],"problem":"If the shareable listing summary card does not render correctly in messaging app previews (WhatsApp, iMessage, SMS), the proxy's forwarded link will display as a generic URL rather than a rich information card, dramatically reducing the likelihood that the end user clicks through.","solution":"Cross-platform rendering test across major messaging applications and screen sizes to verify that the card's Open Graph / link preview metadata produces a compelling, self-contained preview.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma.","insight":"Sophie would likely share a link via WhatsApp or iMessage to her family member. If the link preview is a bare URL with no preview card, the family member is unlikely to click through."}],"priority":"medium","validation_method":"automated","test_description":"Generate the shareable listing summary as a page with proper Open Graph meta tags (og:title, og:description, og:image). Test the link preview rendering in: (1) WhatsApp iOS, (2) WhatsApp Android, (3) iMessage, (4) SMS (fallback), (5) Facebook Messenger, (6) Slack. Verify that: the calendar mini-strip is visible in the og:image, the price is included in the og:description, and the listing title is in the og:title. Test on at least 3 screen sizes (iPhone SE, iPhone 14, Samsung Galaxy S23).","success_criteria":"The link preview card renders with a visible image, title, and price in all 5 messaging apps that support rich previews. The og:image includes the calendar strip and at least one listing photo. The preview is legible on all 3 screen sizes. SMS fallback displays a clear URL with title text.","failure_meaning":"If previews do not render, the Open Graph meta tags are missing or misconfigured. If the image is cropped poorly, the og:image dimensions need adjustment for each platform's preview aspect ratio. If the price is missing from the preview, it is not included in the og:description.","implementation_hint":"Use the Facebook Sharing Debugger (for OG tag validation), WhatsApp link preview tester, and real-device testing for iMessage. Playwright: automated check that og:title, og:description, and og:image tags are present and correctly formatted on the share page URL."},{"id":"tests-019","type":"validation_strategy","title":"Benefit Reinforcement Strip Salience Perception Validation","validates_element":"looks-007","journey_phases":["active_lease"],"problem":"If the benefit reinforcement strip is too subtle, guests will not notice it during per-stay friction tasks. If it is too prominent, it will feel manipulative ('they are trying to make me feel better about this chore'). The correct visual weight is a narrow band: noticeable but not attention-competing.","solution":"In-context perception test measuring whether participants notice the benefit strip, find it helpful, and do not perceive it as manipulative.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Do choosers actually notice the incentives they face?","insight":"The test must verify that guests actually notice the benefit data -- the entire purpose is to make invisible incentives visible. If they do not notice, the strip fails its core function."}],"priority":"medium","validation_method":"usability_test","test_description":"In-context test: 10 participants complete a simulated cleaning photo upload task. After the task, ask: (1) Did you notice anything else on the screen besides the upload form? (unprompted recall), (2) If they noticed the strip, what did it say? (content recall), (3) How did it make you feel? (open-ended), (4) Did it feel helpful or manipulative? (5-point scale). If they did not notice it unprompted, point it out and repeat questions 2-4.","success_criteria":"At least 6 out of 10 notice the strip unprompted. Of those who notice, at least 5 can recall the benefit type (savings, flexibility). Helpfulness rating averages 3.5+ out of 5. Zero participants describe the strip as 'manipulative' or 'patronizing' in open-ended response.","failure_meaning":"If fewer than 4 notice it, the strip is too subtle -- increase visual weight (slightly larger type, more contrast with background). If participants notice but feel manipulated, the positioning (below the task, after completion) is not sufficient -- the strip may need to appear on a separate confirmation screen rather than alongside the task. If content recall is low, the benefit data point is not specific enough or the number is not visually prominent.","implementation_hint":"Usability: moderated session preferred (for natural observation of unprompted noticing). 10 participants, 10 minutes each. Figma prototype of the cleaning photo upload flow with benefit strip. Record eye movement if webcam-based eye tracking is available (Lookback or similar)."},{"id":"tests-020","type":"validation_strategy","title":"Inline Eligibility Gate Response Time Validation","validates_element":"behaves-001","journey_phases":["discovery","search"],"problem":"If the eligibility gate responds too slowly (>500ms), the feedback will feel disconnected from the input and the prospect may have already scrolled past. If the state transitions are jarring (abrupt color changes, sudden CTA text swap), the gate will feel like an error message rather than a helpful response.","solution":"Performance benchmark and perception test measuring response latency and transition smoothness.","evidence":[{"source":"nudge-choice-architecture.txt, Stimulus-Response Compatibility section","type":"book","quote":"The idea is that you want the signal you receive (the stimulus) to be consistent with the desired action.","insight":"The response must feel like a natural consequence of the input, not a delayed judgment. Response latency is a component of stimulus-response compatibility -- a delayed response breaks the causal link between input and feedback."}],"priority":"high","validation_method":"automated","test_description":"Two-part validation: (1) Automated performance test: use Playwright or Cypress to enter various duration values and measure the time from input event to feedback element visible. Test with values: 2 weeks (ineligible), 5 weeks (near-miss), 6 weeks (boundary), 8 weeks (eligible). Each test runs 20 iterations to capture variance. (2) Perception test: 8 participants interact with the gate prototype and rate the transition smoothness (1-5) and whether the feedback felt 'instant' or 'delayed.'","success_criteria":"Automated: 95th percentile response time under 200ms for all input values. Zero visual glitches during state transitions (no flash of unstyled content, no layout shift). Perception: 7 out of 8 participants rate feedback as 'instant' (not 'delayed'). Smoothness rating averages 4.0+ out of 5.","failure_meaning":"If response time exceeds 200ms, the evaluation logic has unnecessary complexity or the transition CSS is blocking render. If visual glitches occur, the state transition needs a crossfade rather than a swap. If participants perceive delay, the animation duration may be too long -- reduce from 200ms to 150ms.","implementation_hint":"Playwright: page.evaluate() with performance.now() timestamps around input and element visibility assertions. Run in headless Chrome for consistent timing. Perception test: Figma interactive prototype or deployed staging environment."},{"id":"tests-021","type":"validation_strategy","title":"Dead-End Redirect State Transformation Validation","validates_element":"behaves-002","journey_phases":["discovery","search"],"problem":"If the redirect state transformation feels like a page navigation (jarring, context-lost), the prospect will feel disoriented. If the staggered tier reveal is too slow (>600ms total), the prospect may leave before seeing the email capture tier. If the email submission fails silently, the prospect thinks they submitted but the platform captured nothing.","solution":"End-to-end interaction test measuring the full redirect flow from disqualification to email submission, including error recovery.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"A well-designed system expects its users to err and is as forgiving as possible.","insight":"The redirect interaction itself must be forgiving: if the email submission fails, the system must provide a clear, inline retry -- not lose the prospect's input."}],"priority":"high","validation_method":"automated","test_description":"Playwright end-to-end test: (1) Enter ineligible parameters (duration: 3 weeks), (2) Verify eligibility gate triggers within 200ms, (3) Verify redirect card assembles within 400ms (all three tiers visible), (4) Verify nearest-alternative count renders (not a skeleton), (5) Enter email address and submit, (6) Verify confirmation appears within 300ms, (7) Simulate network failure on email submission, verify inline retry message appears with entered email preserved. Run the full flow 10 times to verify consistency.","success_criteria":"All 10 runs complete without timeout or visual regression. Redirect card fully visible within 400ms in all runs. Email submission confirmation within 300ms. On simulated network failure, retry message appears within 500ms with email field value preserved. No layout shifts during any transition.","failure_meaning":"If redirect card exceeds 400ms, the staggered tier animation timing needs reduction. If email submission confirmation is slow, the server endpoint has latency -- consider optimistic UI. If the email field clears on error, the state management is not preserving input during error handling.","implementation_hint":"Playwright: page.waitForSelector() with timing assertions. Network simulation: page.route() to intercept email submission endpoint and return 500 for error scenario. Visual regression: Playwright screenshot comparison at each state."},{"id":"tests-022","type":"validation_strategy","title":"Calendar Interactive Exploration Engagement Validation","validates_element":"behaves-003","journey_phases":["listing_evaluation","proposal_creation"],"problem":"If the calendar interaction is too slow (hover delay >200ms), guests will perceive it as unresponsive. If tooltips are unclear, guests will interact without gaining comprehension. If the touch interaction fails on mobile (no hover equivalent), a significant percentage of users will get a static calendar with no exploration capability.","solution":"Cross-device interaction test verifying response times, tooltip clarity, and mobile touch behavior.","evidence":[{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"Even if there are some exotic flavors, the ice cream store can solve the mapping problem by offering a free taste.","insight":"Each hover/tap is a 'free taste.' If the taste is stale (slow) or confusing (unclear tooltip), the guest will stop tasting and leave without comprehension."}],"priority":"high","validation_method":"automated","test_description":"Three-part test: (1) Desktop Playwright: hover each of 7 day circles and verify tooltip appears within 100ms with correct content (day name, arrival/departure time, guest vs. co-tenant status). Verify tooltip crossfades when hovering between days (no exit-then-enter flicker). (2) Mobile Playwright: tap each day circle and verify tooltip appears on first tap, dismisses on second tap of same day, and switches on tap of different day. (3) Usability: 5 participants (3 desktop, 2 mobile) explore the calendar for 30 seconds with think-aloud. Measure: number of days explored, comprehension after exploration, any confusion points.","success_criteria":"Automated: tooltip appears within 100ms on all 7 days. No visual flicker during crossfade. Mobile touch behavior works correctly (tap-to-reveal, tap-to-dismiss, tap-other-to-switch). Usability: all 5 participants explore at least 4 of 7 days. Post-exploration comprehension: all 5 correctly identify which days are theirs.","failure_meaning":"If tooltip delay exceeds 150ms, the CSS transition or JS event handler has unnecessary overhead. If crossfade flickers, the tooltip exit and entrance are not properly overlapped -- need simultaneous fade-out/fade-in. If mobile interaction fails, the touch event handling does not properly map tap to hover-equivalent. If participants only explore 1-2 days, the calendar does not invite exploration -- the visual affordance for interactivity needs strengthening.","implementation_hint":"Playwright: page.hover() with timing assertion for desktop; page.tap() for mobile emulation (iPhone 14, Galaxy S23 viewports). Use page.evaluate() with requestAnimationFrame to measure actual render timing. Usability: moderated, 15 minutes, think-aloud."},{"id":"tests-023","type":"validation_strategy","title":"Smart-Default Proposal Pre-Fill Interaction Flow Validation","validates_element":"behaves-004","journey_phases":["proposal_creation","negotiation"],"problem":"If default-to-edited state transitions are not perceptible (too subtle), the guest will not know they have changed a value. If price recalculation is delayed or uses a distracting counter animation, the guest's attention will be captured by the price rather than the field they are editing. If the submission confirmation is too fast, it may feel untrustworthy for a financial commitment.","solution":"End-to-end interaction flow test covering the full path: form load with defaults, selective editing, price recalculation, and submission.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Many people will take whatever option requires the least effort, or the path of least resistance.","insight":"The test must verify that the path of least resistance (accepting all defaults and submitting) works correctly and feels trustworthy, AND that selective editing is smooth and properly reflected in the price."}],"priority":"high","validation_method":"automated","test_description":"Playwright end-to-end: (1) Load proposal form and verify all 5 fields are pre-populated within 500ms. (2) Verify total price is calculated and displayed in accent mono. (3) Click/focus one field and edit its value -- verify visual transition from default state (italic, muted) to edited state (regular, full ink) within 200ms. (4) Verify price recalculates and crossfades within 400ms. (5) Submit without editing any other fields -- verify confirmation appears within 300ms. (6) Test the 'submit without any edits' path (accepting all defaults) -- verify this path works and does not trigger any 'are you sure?' prompts.","success_criteria":"All fields pre-populated within 500ms. Visual state transitions complete within 200ms. Price recalculation crossfade completes within 400ms. Submission confirmation within 300ms. All-defaults submission path works without friction. No layout shifts during any transition.","failure_meaning":"If pre-population exceeds 500ms, default calculation logic needs optimization or partial rendering (show search-based defaults first, backfill listing-based defaults). If state transitions are imperceptible, the color/weight difference between default and edited is insufficient. If price recalculation is distracting, the crossfade duration may need to increase from 400ms to 600ms, or the animation may need to be reduced to a simple fade rather than a number transition.","implementation_hint":"Playwright: page.click() on form fields, page.fill() for edits, visual regression for state transitions. Test both fast-submit (no edits) and selective-edit paths. Mock the default-calculation API to ensure consistent test data."},{"id":"tests-024","type":"validation_strategy","title":"Counter-Proposal Diff View Clarity Validation","validates_element":"behaves-005","journey_phases":["negotiation"],"problem":"If the diff view is unclear, guests may not understand what changed in the counter-proposal. If the undo window is too short or not visible, guests may accidentally accept terms they did not mean to. If the notification preview does not contain the most important change, guests may deprioritize reviewing the counter.","solution":"Task-based test where participants receive a counter-proposal and must identify changes, take an action, and optionally undo.","evidence":[{"source":"nudge-choice-architecture.txt, Give Feedback section","type":"book","quote":"Warning systems have to avoid the problem of offering so many warnings that they are ignored.","insight":"The diff view must be specific enough to be meaningful on first scan. The test must verify that participants can identify the exact changes without reading the entire proposal."}],"priority":"medium","validation_method":"usability_test","test_description":"Give 8 participants a scenario: 'You submitted a proposal for Monday-Friday, 8 weeks, starting June 1. The host has countered.' Present the diff view showing the host changed the start date to June 15 and the duration to 10 weeks. Ask: (1) What did the host change? (2) What stayed the same? (3) What is the price impact? (4) Accept the changes, then immediately try to undo. Measure: accuracy of change identification, time to reach a decision, and undo success rate.","success_criteria":"8 out of 8 correctly identify both changes (start date and duration). 7 out of 8 correctly identify the price impact direction (increase or decrease). Median decision time under 30 seconds. 8 out of 8 successfully undo within the 5-second window. Zero participants confuse 'accept' with 'reject.'","failure_meaning":"If change identification fails, the before/after format is not clear enough -- consider adding explicit labels ('Changed: Start date') rather than relying solely on visual diff. If price impact is missed, the price change line is not prominent enough. If undo fails, the undo affordance (progress bar, button placement) is not discoverable. If accept/reject are confused, the button labels or positioning are ambiguous.","implementation_hint":"Usability: moderated, 8 participants, 15 minutes each. Figma interactive prototype with the diff view, action buttons, and undo mechanism. Time-stamp each participant's first identification of each change for decision-time measurement."},{"id":"tests-025","type":"validation_strategy","title":"Postcompletion Checkpoint Forcing Flow Technical Validation","validates_element":"behaves-006","journey_phases":["acceptance","move_in"],"problem":"If the gating mechanism fails (guest accesses move-in details without completing earlier checkpoints), the forcing function is broken and postcompletion errors will occur. If checkpoint completion state is not persisted across sessions, returning guests must re-complete already-finished steps.","solution":"End-to-end automated test verifying the gating mechanism, state persistence, and edge cases.","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"if you have to remove the card in order to get your cash, you will not forget to do so.","insight":"The test must verify the 'card-before-cash' mechanism: move-in details are genuinely inaccessible until earlier checkpoints are complete. Any bypass would defeat the forcing function."}],"priority":"medium","validation_method":"automated","test_description":"Playwright tests: (1) Attempt to navigate directly to move-in details URL before completing any checkpoints -- verify redirect to first incomplete checkpoint. (2) Complete checkpoint 1, close browser, reopen -- verify checkpoint 1 is still marked complete and checkpoint 2 is active. (3) Complete all three checkpoints -- verify 'Ready for move-in' confirmation appears and move-in details are accessible. (4) Attempt to re-complete an already-completed checkpoint -- verify it shows as done, not re-presented. (5) Test with offline-then-online: acknowledge a checkpoint while offline, reconnect -- verify the acknowledgment is synced.","success_criteria":"All 5 test scenarios pass. Direct URL access to gated content always redirects to the first incomplete checkpoint. State persists across browser sessions. Completed checkpoints are never re-presented. Offline acknowledgments sync correctly on reconnect.","failure_meaning":"If direct URL access bypasses the gate, the routing/middleware is not checking checkpoint state before serving gated content. If state does not persist, the checkpoint completion is stored only in session memory, not in the database. If completed checkpoints re-present, the state query is not filtering correctly. If offline sync fails, the optimistic UI pattern is not implemented with proper retry logic.","implementation_hint":"Playwright: page.goto() for direct URL access test. page.context().clearCookies() and page.context().clearPermissions() for session reset test. page.setOfflineMode(true/false) for offline sync test. Assert on visible elements and URL after each action."},{"id":"tests-026","type":"validation_strategy","title":"Benefit Salience Reinforcement Strip Behavioral Impact Validation","validates_element":"behaves-007","journey_phases":["active_lease"],"problem":"If the benefit strip has no measurable impact on guest satisfaction or retention, it is visual noise that adds complexity without value. If it habituates quickly (the guest stops noticing after 2-3 exposures), the salience correction is temporary and ineffective.","solution":"Longitudinal A/B test measuring satisfaction scores and retention rates for guests who see the benefit strip vs. those who do not, across a full quarter.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"The most important modification that must be made to a standard analysis of incentives is salience.","insight":"The test must measure whether the benefit strip actually changes perceived salience of benefits -- not just whether it is noticed, but whether it shifts the guest's overall evaluation of the arrangement over time."}],"priority":"medium","validation_method":"a_b_test","test_description":"Longitudinal A/B test over 12 weeks (one full quarter): (A) guests see benefit reinforcement strip at every per-stay friction touchpoint, (B) control group sees no strip. Measure: (1) monthly NPS or satisfaction survey (single question: 'How satisfied are you with your co-tenancy arrangement?' 1-10), (2) lease renewal rate at the end of the quarter, (3) support ticket volume related to friction tasks (cleaning photos, schedule issues). Secondary: track whether strip engagement declines over time (measure strip visibility duration via viewport intersection).","success_criteria":"Variant A satisfaction score is at least 0.5 points higher than Variant B by week 12. Lease renewal rate for Variant A is at least 5 percentage points higher than Variant B. Support ticket volume for Variant A is equal to or lower than Variant B (the strip should not generate complaints). Strip engagement does not decline by more than 30% from week 1 to week 12 (indicating the rotation of benefit types prevents complete habituation).","failure_meaning":"If satisfaction scores are equal, the benefit strip is not shifting perceived value -- the salience intervention is insufficient. If renewal rates are equal, the benefit awareness does not translate into retention behavior -- the strip may be noticed but not internalized. If strip engagement drops by more than 50%, habituation is occurring too quickly -- the benefit rotation is not diverse enough. If support tickets increase, guests may feel patronized by the benefit strip during frustrating moments.","implementation_hint":"A/B test: LaunchDarkly or Optimizely, randomized at user level. Satisfaction survey: in-app modal triggered monthly (keep to 1 question to maximize response rate). Renewal tracking: backend event when lease renewal is offered and when it is accepted/declined. Strip engagement: Intersection Observer API to track how long the strip is in the viewport."},{"id":"tests-027","type":"validation_strategy","title":"Immediate Clarity Emotional Safety Validation","validates_element":"feels-001","journey_phases":["discovery","search"],"problem":"If the 'immediate clarity' principle fails emotionally, prospects may feel the constraint disclosure is a barrier (scares away eligible guests), a rejection (makes ineligible guests feel unwelcome), or irrelevant (prospects do not connect the constraints to their own situation). The target emotion is safety; the test must verify that safety is achieved.","solution":"Emotional response survey immediately after discovery page exposure, measuring whether 'safety' is the dominant emotional association.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:09","type":"guest_call","quote":"This was just, uh, for the month of may actually. Um, And, And, uh, yeah, it could have been flexible for earlier than that, but not, not beyond, uh, the end of may, unfortunately.","insight":"Sophie's emotional trajectory was hope -> effort -> disappointment. The test must verify that the new design replaces this with clarity -> self-assessment -> resolution (proceed or redirect)."}],"priority":"high","validation_method":"usability_test","test_description":"10 participants view the discovery page with constraint-first disclosure. 5 are given an eligible scenario (8 weeks, starting in 4 weeks), 5 are given an ineligible scenario (3 weeks, starting next week). After 15 seconds of viewing, each participant answers: (1) How do you feel right now? (open-ended), (2) Rate your feelings: safe/unsafe, respected/dismissed, clear/confused (each on a 5-point scale), (3) What would you do next? (proceed, leave, or other). Code open-ended responses for the presence of safety-related language.","success_criteria":"Eligible participants: safety rating 4.0+, clarity 4.5+, 5 out of 5 say they would proceed. Ineligible participants: respected rating 3.5+ (not dismissed despite mismatch), clarity 4.0+, at least 3 out of 5 engage with the redirect path rather than simply leaving. Open-ended responses contain safety-related language (trusted, honest, clear, helpful) for at least 7 out of 10 participants.","failure_meaning":"If eligible participants feel unsafe, the constraints read as barriers rather than helpful disclosures -- the framing is too negative. If ineligible participants feel dismissed (respected < 3.0), the redirect path is not emotionally adequate -- it needs warmer, more specific language. If clarity scores are low, the constraint statement is ambiguous or too long.","implementation_hint":"Usability: moderated or unmoderated, 10 participants, 10 minutes each. Assign scenarios via screening question. Use Figma prototype with the constraint-first discovery page. Ensure the redirect path is functional in the prototype for ineligible-scenario participants."},{"id":"tests-028","type":"validation_strategy","title":"Dignified Redirect Emotional Residue Validation","validates_element":"feels-002","journey_phases":["discovery","search"],"problem":"If the redirect experience leaves a negative emotional residue (frustration, dismissal, resentment), the prospect will never return and may actively discourage others. The target emotion is relief; the test must verify that ineligible prospects leave with a neutral-to-positive emotional residue rather than a negative one.","solution":"Post-interaction emotional assessment measuring the specific emotional residue of the redirect experience.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 1:25-1:38","type":"guest_call","quote":"That's unfortunate that we cannot help you. It's I'm sorry if you ever need something in this type of arrangement, but it was a little more lead time.","insight":"Sophie's emotional residue from the current experience is 'polite dismissal.' The test must verify the new redirect achieves 'respectful redirection' -- a meaningfully different emotional outcome."}],"priority":"high","validation_method":"usability_test","test_description":"10 participants are given the ineligible scenario and complete the full redirect interaction (disqualification, redirect card, email capture decision). Immediately after, ask: (1) In one sentence, how would you describe this experience to a friend? (2) Would you recommend this platform to someone whose need does match? (Net Promoter-style 1-10), (3) Rate: I felt respected / I felt dismissed / I felt informed / I felt patronized (each 1-5), (4) Would you return to this platform if your housing needs changed? (yes/no/maybe).","success_criteria":"Average 'respected' rating of 4.0+. Average 'dismissed' rating below 2.0. NPS-style recommendation score of 7.0+ (promoter territory, despite personal ineligibility). At least 7 out of 10 would return or share ('yes' or 'maybe' to Q4). Open-ended descriptions use positive language (helpful, clear, honest) rather than negative (waste, rejection, confusing).","failure_meaning":"If 'respected' is below 3.5, the redirect feels like dismissal -- the specific mismatch diagnosis and reframe are not emotionally adequate. If 'patronized' is above 3.0, the benefit reframe ('12 options if you extend') feels condescending rather than helpful. If recommendation score is below 5, the experience actively damages brand perception among ineligible prospects. If return intent is below 50%, the future value proposition (email capture) is not compelling.","implementation_hint":"Usability: moderated preferred (for richer emotional observation), 10 participants, 15 minutes each. Give all participants the Sophie Charvet scenario (family member visiting for 1 month). Administer the emotional assessment immediately after the redirect interaction, before any debrief."},{"id":"tests-029","type":"validation_strategy","title":"Co-Tenancy Comprehension-to-Confidence Bridge Validation","validates_element":"feels-003","journey_phases":["listing_evaluation","proposal_creation"],"problem":"If the interactive calendar builds comprehension but not confidence, guests will understand the co-tenancy model intellectually but still feel too anxious to commit. The target emotion is confidence; the test must distinguish between 'I understand it' and 'I would do it.'","solution":"Two-phase measurement: comprehension (factual understanding) followed by confidence (willingness to proceed), with the gap between them as the key metric.","evidence":[{"source":"nudge-choice-architecture.txt, Understanding Mappings section","type":"book","quote":"A good system of choice architecture helps people to improve their ability to map choices onto outcomes.","insight":"Mapping comprehension is necessary but not sufficient. The test must verify that the interactive calendar closes the gap between comprehension and confidence -- that understanding the arrangement translates into willingness to try it."}],"priority":"high","validation_method":"usability_test","test_description":"10 participants explore the interactive calendar listing page. Measure: (1) Comprehension score (5 factual questions, as in tests-004), (2) Confidence score ('How confident are you that you could live in this arrangement?' 1-5), (3) Willingness score ('Would you proceed to create a proposal?' definitely yes/probably yes/unsure/probably no/definitely no). Calculate the comprehension-confidence gap: if comprehension is 4.5 but confidence is 2.0, the gap is 2.5 -- meaning the calendar informs but does not reassure. Compare against a control group that reads a text-only description.","success_criteria":"Treatment group comprehension: 4.0+. Treatment group confidence: 3.5+. Comprehension-confidence gap: under 1.0 (meaning confidence tracks close to comprehension). Willingness: at least 6 out of 10 respond 'definitely yes' or 'probably yes.' Treatment group outperforms control on confidence by at least 1.0 point.","failure_meaning":"If comprehension is high but confidence is low (gap > 1.5), the calendar explains the model but does not make it feel safe -- the 'what to expect' narrative needs more emotional reassurance (concrete daily-life details, positive framing). If willingness is low despite high confidence, there is a separate barrier (price, location, general reluctance to share space) that the calendar cannot address. If the control group has equal confidence, the interactive calendar adds complexity without emotional benefit.","implementation_hint":"Usability: 10 participants per group (treatment + control = 20 total), unmoderated via UserTesting.com. Treatment: Figma interactive prototype with hover/tap calendar. Control: static text description matching the agent's verbal explanation. Administer identical questionnaire to both groups."},{"id":"tests-030","type":"validation_strategy","title":"Guided Starting Point vs. Blank-Slate Emotional Validation","validates_element":"feels-004","journey_phases":["proposal_creation","negotiation"],"problem":"If the pre-filled proposal form does not achieve the target emotion of 'calm,' it may produce the opposite: anxiety about whether the defaults are correct, or resentment about the platform making decisions on the guest's behalf. The emotional distinction between 'someone helped me' and 'someone decided for me' is narrow and critical.","solution":"Emotional response comparison between the pre-filled form and a blank form, measuring calm, control, and trust.","evidence":[{"source":"nudge-choice-architecture.txt, Defaults section","type":"book","quote":"Most users do not want to have to read an incomprehensible manual to determine which arcane setting to select. When choice is complicated and difficult, people might greatly appreciate a sensible default.","insight":"The test must verify that defaults produce 'appreciation' (emotional calm and trust) rather than 'suspicion' (the platform is choosing for me). The word 'appreciate' is the emotional target."}],"priority":"medium","validation_method":"usability_test","test_description":"A/B emotional test: (A) 5 participants see the pre-filled proposal form, (B) 5 participants see a blank proposal form with the same fields. Both groups attempt to submit a proposal. Measure: (1) Self-reported emotion: calm/anxious, in-control/overwhelmed, trusting/suspicious (each 1-5), (2) Time to first action (scan time before editing or submitting), (3) Open-ended: 'What was your first thought when you saw this form?'","success_criteria":"Group A (pre-filled) scores 3.5+ on calm, 4.0+ on in-control, 3.5+ on trusting. Group A outperforms Group B on calm by at least 1.0 point. Group A open-ended responses include language like 'helpful,' 'easy,' 'already done' rather than 'suspicious,' 'who chose this,' 'wrong values.'","failure_meaning":"If calm is below 3.0, the defaults are anxiety-inducing rather than calming -- the guest does not trust the values. Likely cause: contextual labels are missing or unclear, and the guest does not know where the defaults came from. If in-control is low despite calm being high, the guest feels helped but constrained -- the editability affordance needs to be more prominent. If Group B outperforms on any emotional dimension, the blank form is actually preferred for this user segment.","implementation_hint":"Usability: 5 participants per group, moderated 15-minute sessions. Figma interactive prototypes for both variants. Assign randomly. Administer emotional questionnaire immediately after form interaction, before any debrief."},{"id":"tests-031","type":"validation_strategy","title":"Post-Acceptance Preparation Momentum Validation","validates_element":"feels-005","journey_phases":["acceptance","move_in"],"problem":"If the checkpoint sequence fails emotionally, it will convert the relief of acceptance into resentment ('I said yes and now they are making me do homework'). The target emotion is momentum -- the feeling of actively preparing for something good. The test must verify momentum, not just compliance.","solution":"Emotional trajectory measurement across the three checkpoints, tracking whether the dominant emotion shifts from relief to momentum to readiness (positive trajectory) or from relief to annoyance to resentment (negative trajectory).","evidence":[{"source":"nudge-choice-architecture.txt, Expect Error section","type":"book","quote":"when you have finished your main task, you tend to forget things relating to previous steps.","insight":"The checkpoint system must convert the post-decision state from 'I am done' (postcompletion risk) to 'I am getting ready' (forward momentum). The test must measure this emotional conversion, not just task completion."}],"priority":"medium","validation_method":"usability_test","test_description":"8 participants complete the full three-checkpoint sequence. After each checkpoint (not just at the end), ask a single-word emotion check: 'In one word, how do you feel right now?' Also rate momentum (1-5) after each step. After the final 'Ready for move-in' confirmation, ask: (1) Do you feel prepared for your move-in? (1-5), (2) Did this process feel like preparation or bureaucracy? (5-point scale), (3) Overall: was this a positive experience? (yes/no).","success_criteria":"Momentum scores increase or remain stable across checkpoints (no decline from checkpoint 1 to 3). Final preparedness score averages 4.0+. 'Preparation vs. bureaucracy' averages 3.5+ (toward preparation). At least 7 out of 8 say 'yes' to overall positive experience. One-word emotion checks show positive/neutral words (ready, good, done, clear) rather than negative (annoyed, forced, bored).","failure_meaning":"If momentum declines across checkpoints, the sequence feels like a gauntlet -- each step drains energy rather than building it. If final preparedness is low, the checkpoint content is not informative enough (the guest clicked through but did not absorb). If 'bureaucracy' dominates, the positive framing ('Got it, next step') is not working -- the experience feels institutional. If negative emotion words appear, the forcing function is perceived as punishment.","implementation_hint":"Moderated usability: 8 participants, 20 minutes each. Figma interactive prototype. Pause after each checkpoint for the emotion check (this is the critical measurement point). Audio-record for tone-of-voice analysis as a secondary emotional indicator."},{"id":"tests-032","type":"validation_strategy","title":"Benefit Reinforcement Emotional Validation (Not Patronizing)","validates_element":"feels-006","journey_phases":["active_lease"],"problem":"If the benefit strip feels patronizing ('stop complaining, look how much you save') rather than affirming ('here is what your arrangement is doing for you'), it will damage rather than support the guest's emotional relationship with the platform. The line between validation and manipulation is narrow.","solution":"Qualitative emotional assessment in context: participants complete a friction task with the benefit strip present and provide immediate emotional feedback.","evidence":[{"source":"nudge-choice-architecture.txt, Incentives section","type":"book","quote":"Do choosers actually notice the incentives they face?","insight":"The test must verify not just that the benefit is noticed, but that noticing it produces the right emotional response: gratitude or validation, not resentment or suspicion."}],"priority":"medium","validation_method":"usability_test","test_description":"8 participants complete a simulated cleaning photo upload task with the benefit strip visible after completion. Ask: (1) What emotion did the savings number trigger? (open-ended), (2) Rate: helpful/patronizing, validating/manipulative, reassuring/irrelevant (each 1-5), (3) Would you prefer to see this information? (yes/no/indifferent), (4) When should this NOT appear? (open-ended, to validate the anti-pattern of not showing during error recovery).","success_criteria":"Open-ended emotions are net positive (7+ out of 8 express positive or neutral emotions). Helpful rating averages 3.5+. Patronizing rating averages below 2.5. Manipulative rating averages below 2.0. At least 6 out of 8 say 'yes' to wanting this information. Participants independently identify error-recovery moments as inappropriate contexts for the strip (validating the anti-pattern in the element design).","failure_meaning":"If patronizing exceeds 3.0, the benefit strip's positioning or framing makes it feel like the platform is justifying the friction rather than sharing positive data. If manipulative exceeds 2.5, the timing (alongside the friction task) creates a perception of emotional manipulation. If indifference exceeds 50%, the benefit data is not personally meaningful enough -- the numbers may be too small or too generic.","implementation_hint":"Moderated usability: 8 participants who have experience with recurring tasks (gym check-ins, subscription services) as a proxy for the lease-friction context. Figma prototype of the cleaning photo upload flow. 10 minutes per session."},{"id":"tests-033","type":"validation_strategy","title":"End-to-End Guest Journey Arc Validation","validates_element":"journey-level","journey_phases":["discovery","search","listing_evaluation","proposal_creation","negotiation","acceptance","move_in","active_lease"],"problem":"Individual elements may each test well in isolation but fail when composed into a full journey. The emotional arc (safety -> curiosity -> confidence -> calm -> momentum -> validation) may have gaps or jarring transitions between phases. The information density may accumulate across phases and overwhelm the guest. The interaction patterns may conflict in unexpected ways (e.g., the forcing-function checkpoint flow may feel contradictory after the 'ease' of the pre-filled proposal).","solution":"End-to-end journey walkthrough with a small number of participants who experience the entire guest journey from discovery through active lease in a single session.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt (full transcript)","type":"guest_call","quote":"The full Sophie Charvet interaction lasted approximately 3 minutes and covered discovery through disqualification. The test must cover the full journey that Sophie never reached.","insight":"Sophie's call exposed failures in the earliest phases. This journey-level test must verify that the corrections to early phases (eligibility gate, redirect) produce a coherent experience all the way through active lease."},{"source":"nudge-choice-architecture.txt (full chapter)","type":"book","quote":"The cumulative application of Make It Easy, Give Feedback, Expect Error, Defaults, and Incentive Salience principles across a complete journey must produce a coherent system, not a collection of isolated interventions.","insight":"Choice architecture principles were applied phase-by-phase. The test must verify that the principles compose correctly across the full journey without conflicting or creating cognitive overload."}],"priority":"high","validation_method":"usability_test","test_description":"Recruit 5 participants who have never used a co-tenancy platform. Walk them through a condensed prototype of the full guest journey: (1) Discovery with eligibility check (eligible scenario), (2) Search with filters, (3) Listing evaluation with interactive calendar, (4) Proposal creation with smart defaults, (5) Counter-proposal review, (6) Acceptance with checkpoint flow, (7) Move-in preparation, (8) One simulated active-lease friction task with benefit strip. After each phase, ask a single emotion word and a 1-5 'would you continue?' score. At the end, ask: (1) Overall coherence ('Did this feel like one experience or a collection of different screens?' 1-5), (2) Overall trust ('Would you use this platform for real housing?' 1-5), (3) Open-ended: 'What was the best and worst moment?'","success_criteria":"All 5 participants complete the full journey without wanting to stop. 'Would you continue?' averages above 4.0 at every phase transition. Overall coherence averages 4.0+. Overall trust averages 3.5+. Emotion words trend from neutral-positive at discovery to positive at acceptance. No participant identifies a phase transition as jarring or confusing.","failure_meaning":"If participants want to stop at a specific phase, that phase is the weakest link in the arc -- it needs targeted improvement. If coherence is below 3.5, the visual or interaction patterns shift too dramatically between phases -- need stronger design-system consistency. If trust is below 3.0, the overall experience fails to build cumulative credibility -- likely a specific moment breaks trust (e.g., the forcing-function checkpoints may feel distrustful after the 'ease' of proposal defaults). If a phase transition is identified as jarring, the emotional handoff between elements at that boundary needs attention.","implementation_hint":"Moderated usability: 5 participants, 45-60 minutes each (condensed journey, not real-time). Figma prototype connecting all phases with clickable flow. This is the most resource-intensive test in the suite; run it last, after individual element tests have identified and resolved component-level issues."},{"id":"tests-034","type":"validation_strategy","title":"Ineligible-to-Eligible Prospect Re-Engagement Validation","validates_element":"journey-level","journey_phases":["discovery","search","active_lease"],"problem":"The redirect mechanism captures emails from ineligible prospects, but the long-term value of this capture is unproven. If re-engagement emails never convert, the entire redirect-capture system adds complexity without business value. The journey-level question is: does the graceful dead-end redirect actually produce future guests, or does it only produce a database of emails that never convert?","solution":"Longitudinal tracking of ineligible prospect re-engagement over 6 months, measuring whether captured emails convert to actual platform engagement when the prospect's circumstances change.","evidence":[{"source":"Sophie Charvet - 18 April 2022.txt, 3:07","type":"guest_call","quote":"I know this, this was just for a family member who was visiting me in New York for a ma.","insight":"Sophie lives in New York. She might have future housing needs, know others who commute, or remember Split Lease when circumstances change. The test must verify whether this theoretical future value actually materializes."}],"priority":"medium","validation_method":"analytics","test_description":"Track the cohort of ineligible prospects who submitted emails via the redirect card. Over 6 months, measure: (1) email open rate for re-engagement campaigns, (2) click-through rate from emails to platform, (3) conversion rate from click-through to listing view or proposal, (4) conversion rate from re-engaged prospect to actual guest. Compare against the platform's standard acquisition funnel metrics.","success_criteria":"Email open rate above 20% (indicating the emails are from real, engaged people, not junk submissions). Click-through rate above 5%. At least 2% of captured emails convert to a listing view or proposal within 6 months. At least 0.5% convert to an actual guest. Re-engagement acquisition cost is lower than standard paid acquisition cost per guest.","failure_meaning":"If open rates are below 10%, the emails are low-quality (junk, typos, or disinterested people who submitted under social pressure from the UI). If click-through is near zero, the re-engagement content is not relevant to the prospect's evolved needs. If zero emails convert to guests, the redirect capture is a feel-good mechanism that adds complexity without producing business value -- consider simplifying or removing the email capture tier.","implementation_hint":"Analytics: standard email marketing platform (Mailchimp, Customer.io, or similar). Tag captured emails with the prospect's original stated need (duration, timing, city) for targeted re-engagement. Send quarterly re-engagement emails when new listings match the prospect's approximate need profile. Track the full funnel from email capture through lease signing."}]}</script>

  <header class="report-header">
    <h1>Design Stack v2 Report</h1>
    <div class="lens-label" id="lens-label"></div>
    <div class="report-meta">
      <span id="meta-date"></span>
      <span id="meta-run-id"></span>
      <span class="badge" id="meta-status"></span>
      <span id="meta-elements"></span>
    </div>
  </header>

  <div class="coherence-bar" id="coherence-bar">
    <span class="count" id="coherence-count"></span>
    <span id="coherence-summary"></span>
  </div>

  <nav class="tab-nav" id="tab-nav">
    <button class="active" data-tab="overview"><span class="layer-num">*</span> Overview</button>
    <button data-tab="layer-0"><span class="layer-num">0</span> Journey</button>
    <button data-tab="layer-1"><span class="layer-num">1</span> Works</button>
    <button data-tab="layer-2"><span class="layer-num">2</span> Communicates</button>
    <button data-tab="layer-3"><span class="layer-num">3</span> Looks</button>
    <button data-tab="layer-4"><span class="layer-num">4</span> Behaves</button>
    <button data-tab="layer-5"><span class="layer-num">5</span> Feels</button>
    <button data-tab="layer-6"><span class="layer-num">6</span> Coherence</button>
    <button data-tab="layer-7"><span class="layer-num">7</span> Tests</button>
  </nav>

  <main class="main-content">

    <!-- Overview Tab -->
    <div class="tab-panel active" id="panel-overview">
      <div class="element-card">
        <h3 style="font-family:'Instrument Serif',serif;font-size:24px;font-weight:400;margin-bottom:16px;">Lens Summary</h3>
        <p id="overview-lens-summary" style="font-size:16px;color:var(--ink-soft);margin-bottom:20px;"></p>
        <h4 style="font-size:13px;font-weight:600;color:var(--ink-muted);text-transform:uppercase;letter-spacing:0.05em;margin-bottom:12px;font-family:'IBM Plex Mono',monospace;">Journey Phase Coverage</h4>
        <div class="coverage-grid" id="overview-coverage"></div>
        <h4 style="font-size:13px;font-weight:600;color:var(--ink-muted);text-transform:uppercase;letter-spacing:0.05em;margin:20px 0 12px;font-family:'IBM Plex Mono',monospace;">Run Statistics</h4>
        <div id="overview-stats" style="display:grid;grid-template-columns:repeat(auto-fill,minmax(150px,1fr));gap:10px;"></div>
      </div>
      <div id="overview-highlights"></div>
    </div>

    <!-- Layer 0: Journey Context -->
    <div class="tab-panel" id="panel-layer-0">
      <div class="element-card">
        <h3 style="font-family:'Instrument Serif',serif;font-size:24px;font-weight:400;margin-bottom:16px;">Layer 0: Journey Context</h3>
        <div id="content-layer-0"></div>
      </div>
    </div>

    <!-- Layers 1-5: Element Cards -->
    <div class="tab-panel" id="panel-layer-1"><div id="content-layer-1"></div></div>
    <div class="tab-panel" id="panel-layer-2"><div id="content-layer-2"></div></div>
    <div class="tab-panel" id="panel-layer-3"><div id="content-layer-3"></div></div>
    <div class="tab-panel" id="panel-layer-4"><div id="content-layer-4"></div></div>
    <div class="tab-panel" id="panel-layer-5"><div id="content-layer-5"></div></div>

    <!-- Layer 6: Coherence -->
    <div class="tab-panel" id="panel-layer-6">
      <div id="content-layer-6"></div>
    </div>

    <!-- Layer 7: Tests -->
    <div class="tab-panel" id="panel-layer-7"><div id="content-layer-7"></div></div>

  </main>

  <footer style="text-align:center;padding:32px;color:var(--ink-ghost);font-size:12px;font-family:'IBM Plex Mono',monospace;">
    SplitLease Design Stack v2.0 — Element Pipeline
  </footer>

  <script>
    function loadJSON(id) { try { return JSON.parse(document.getElementById(id)?.textContent || '{}'); } catch { return {}; } }

    const config = loadJSON('run-config');
    const layers = {};
    for (let i = 0; i <= 7; i++) layers[i] = loadJSON(`data-layer-${i}`);

    // Header
    const lens = config.lens || layers[0]?.lens || {};
    document.getElementById('lens-label').textContent = `Lens: ${lens.guest_call || '?'} + ${lens.book_extract || '?'}`;
    document.getElementById('meta-date').textContent = config.started_at ? new Date(config.started_at).toLocaleDateString() : '';
    document.getElementById('meta-run-id').textContent = config.run_id || '';
    const statusEl = document.getElementById('meta-status');
    statusEl.textContent = config.status || 'pending';
    statusEl.className = `badge badge-${config.status || 'partial'}`;

    // Count elements
    let totalElements = 0;
    for (let i = 1; i <= 5; i++) totalElements += (layers[i]?.elements || []).length;
    totalElements += (layers[7]?.elements || []).length;
    document.getElementById('meta-elements').textContent = `${totalElements} elements`;

    // Coherence bar
    const coherence = layers[6] || {};
    const contradictions = coherence.contradictions || [];
    const reinforcements = coherence.reinforcements || [];
    if (contradictions.length > 0) {
      const bar = document.getElementById('coherence-bar');
      bar.classList.add('has-flags');
      document.getElementById('coherence-count').textContent = `${contradictions.length} contradiction${contradictions.length !== 1 ? 's' : ''}`;
      document.getElementById('coherence-summary').textContent = `${reinforcements.length} reinforcement${reinforcements.length !== 1 ? 's' : ''} found`;
    }

    // Tab navigation
    document.getElementById('tab-nav').addEventListener('click', (e) => {
      const btn = e.target.closest('button');
      if (!btn) return;
      document.querySelectorAll('.tab-nav button').forEach(b => b.classList.remove('active'));
      document.querySelectorAll('.tab-panel').forEach(p => p.classList.remove('active'));
      btn.classList.add('active');
      document.getElementById(`panel-${btn.dataset.tab}`).classList.add('active');
    });

    // Evidence toggle
    document.addEventListener('click', (e) => {
      if (e.target.classList.contains('evidence-toggle')) {
        const list = e.target.nextElementSibling;
        list.classList.toggle('open');
        e.target.textContent = list.classList.contains('open') ? 'Hide evidence' : `Show evidence (${list.children.length})`;
      }
    });

    // Render element card
    function renderElementCard(el) {
      const phases = (el.journey_phases || []).map(p => `<span class="phase-tag">${p}</span>`).join('');
      const evidenceItems = (el.evidence || []).map(ev =>
        `<div class="evidence-item">
          <div class="source">${ev.source || ''}</div>
          ${ev.quote ? `<div class="quote">"${ev.quote}"</div>` : ''}
          ${ev.insight ? `<div class="insight">${ev.insight}</div>` : ''}
        </div>`
      ).join('');
      const evidenceCount = (el.evidence || []).length;

      let extras = '';
      // Layer-specific fields
      if (el.user_goal) extras += `<div class="extra-field"><label>User Goal</label> <span class="value">${el.user_goal}</span></div>`;
      if (el.company_goal) extras += `<div class="extra-field"><label>Company Goal</label> <span class="value">${el.company_goal}</span></div>`;
      if (el.success_metric) extras += `<div class="extra-field"><label>Success Metric</label> <span class="value">${el.success_metric}</span></div>`;
      if (el.time_budget) extras += `<div class="extra-field"><label>Time Budget</label> <span class="value">${el.time_budget}</span></div>`;
      if (el.hierarchy_principle) extras += `<div class="extra-field"><label>Hierarchy</label> <span class="value">${el.hierarchy_principle}</span></div>`;
      if (el.disclosure_pattern) extras += `<div class="extra-field"><label>Disclosure</label> <span class="value">${el.disclosure_pattern}</span></div>`;
      if (el.cognitive_load_constraint) extras += `<div class="extra-field"><label>Cognitive Load</label> <span class="value">${el.cognitive_load_constraint}</span></div>`;
      if (el.brand_alignment) extras += `<div class="extra-field"><label>Brand Alignment</label> <span class="value">${el.brand_alignment}</span></div>`;
      if (el.visual_hierarchy_rule) extras += `<div class="extra-field"><label>Visual Hierarchy</label> <span class="value">${el.visual_hierarchy_rule}</span></div>`;
      if (el.transition_principle) extras += `<div class="extra-field"><label>Transitions</label> <span class="value">${el.transition_principle}</span></div>`;
      if (el.journey_state_awareness) extras += `<div class="extra-field"><label>Journey Awareness</label> <span class="value">${el.journey_state_awareness}</span></div>`;
      if (el.target_emotion) extras += `<div class="extra-field"><label>Target Emotion</label> <span class="value" style="font-size:16px;font-weight:600;">${el.target_emotion}</span></div>`;
      if (el.emotion_rationale) extras += `<div class="extra-field"><label>Why</label> <span class="value">${el.emotion_rationale}</span></div>`;
      if (el.validation_method) extras += `<div class="extra-field"><label>Method</label> <span class="value">${el.validation_method}</span></div>`;
      if (el.success_criteria) extras += `<div class="extra-field"><label>Success Criteria</label> <span class="value">${el.success_criteria}</span></div>`;
      if (el.failure_meaning) extras += `<div class="extra-field"><label>Failure Means</label> <span class="value">${el.failure_meaning}</span></div>`;
      if (el.test_description) extras += `<div class="extra-field"><label>Test</label> <span class="value">${el.test_description}</span></div>`;

      // Copy guidelines
      if (el.copy_guidelines) {
        const cg = el.copy_guidelines;
        extras += `<div class="extra-field" style="margin-top:8px;"><label>Copy Voice</label> <span class="value">${cg.voice || ''}</span></div>`;
        if (cg.example_good) extras += `<div class="extra-field"><label>Good Example</label> <span class="value" style="color:var(--signal-success);">"${cg.example_good}"</span></div>`;
        if (cg.example_bad) extras += `<div class="extra-field"><label>Bad Example</label> <span class="value" style="color:var(--signal-danger);text-decoration:line-through;">"${cg.example_bad}"</span></div>`;
      }

      // Anti-goals / anti-patterns
      const antiItems = el.anti_goals || (el.anti_patterns || []).map(a => typeof a === 'string' ? a : a.pattern);
      let antiHTML = '';
      if (antiItems && antiItems.length) {
        antiHTML = `<div style="margin-top:12px;"><label style="font-size:11px;font-weight:600;text-transform:uppercase;letter-spacing:0.05em;color:var(--signal-danger);font-family:'IBM Plex Mono',monospace;">Anti-goals</label><ul style="margin-top:4px;padding-left:18px;font-size:13px;color:var(--ink-soft);">${antiItems.map(a => `<li>${a}</li>`).join('')}</ul></div>`;
      }

      return `<div class="element-card">
        <div class="element-card-header">
          <h3>${el.title || el.id}</h3>
          <span class="type-badge type-${el.type || ''}">${(el.type || '').replace(/_/g, ' ')}</span>
          <span class="priority-badge priority-${el.priority || 'low'}">${el.priority || 'low'}</span>
        </div>
        <div class="phase-tags">${phases}</div>
        <div class="ps-grid">
          <div class="ps-box problem"><label>Problem</label>${el.problem || 'N/A'}</div>
          <div class="ps-box solution"><label>Solution</label>${el.solution || 'N/A'}</div>
        </div>
        ${extras ? `<div class="extra-fields">${extras}</div>` : ''}
        ${antiHTML}
        ${evidenceCount > 0 ? `<div style="margin-top:16px;">
          <button class="evidence-toggle">Show evidence (${evidenceCount})</button>
          <div class="evidence-list">${evidenceItems}</div>
        </div>` : ''}
      </div>`;
    }

    // Render element layers (1-5, 7)
    [1,2,3,4,5,7].forEach(i => {
      const container = document.getElementById(`content-layer-${i}`);
      if (!container) return;
      const data = layers[i];
      const elements = data?.elements || [];
      if (elements.length === 0) {
        container.innerHTML = '<div class="element-card"><p style="color:var(--ink-ghost);font-style:italic;">No elements discovered by this layer.</p></div>';
        return;
      }
      const layerNames = {1:'Process Patterns',2:'Info Architecture',3:'Visual Patterns',4:'Interaction Patterns',5:'Emotional Elements',7:'Validation Strategies'};
      container.innerHTML = `<h2 style="font-family:'Instrument Serif',serif;font-size:24px;font-weight:400;margin-bottom:20px;">Layer ${i}: ${layerNames[i]} <span style="font-size:14px;color:var(--ink-muted);font-family:'IBM Plex Mono',monospace;">(${elements.length} element${elements.length!==1?'s':''})</span></h2>` + elements.map(renderElementCard).join('');
    });

    // Render Layer 0: Journey Context
    (function renderJourney() {
      const container = document.getElementById('content-layer-0');
      if (!container) return;
      const data = layers[0];
      if (!data || !data.phases) { container.innerHTML = '<p style="color:var(--ink-ghost);font-style:italic;">No journey context data.</p>'; return; }

      const phaseOrder = ['discovery','search','listing_evaluation','proposal_creation','negotiation','acceptance','move_in','active_lease'];
      let html = '';
      if (data.lens?.lens_summary) html += `<p style="font-size:15px;color:var(--ink-soft);margin-bottom:20px;">${data.lens.lens_summary}</p>`;
      phaseOrder.forEach(phase => {
        const p = data.phases[phase];
        if (!p) return;
        const risk = p.dropout_risk?.level || 'low';
        html += `<div class="phase-card">
          <h4>${phase.replace(/_/g, ' ')}</h4>
          <p>${p.what_this_lens_reveals || 'No data for this phase.'}</p>
          ${p.user_state ? `<p style="font-size:12px;color:var(--ink-muted);"><strong>Emotional:</strong> ${p.user_state.emotional_state || '?'} | <strong>Knowledge:</strong> ${p.user_state.knowledge_level || '?'} | <strong>Commitment:</strong> ${p.user_state.commitment_level || '?'}</p>` : ''}
          <span class="risk risk-${risk}">${risk} dropout risk</span>
        </div>`;
      });
      if (data.cross_phase_patterns?.length) {
        html += '<h4 style="font-family:\'IBM Plex Mono\',monospace;font-size:13px;font-weight:600;color:var(--accent);margin:20px 0 10px;text-transform:uppercase;">Cross-Phase Patterns</h4>';
        data.cross_phase_patterns.forEach(cp => {
          html += `<div class="phase-card"><p><strong>${cp.pattern}</strong></p><p style="font-size:12px;color:var(--ink-muted);">Affects: ${(cp.phases_affected||[]).join(', ')} | ${cp.evidence || ''}</p></div>`;
        });
      }
      container.innerHTML = html;
    })();

    // Render Layer 6: Coherence
    (function renderCoherence() {
      const container = document.getElementById('content-layer-6');
      if (!container) return;
      const data = layers[6];
      if (!data || Object.keys(data).length === 0) { container.innerHTML = '<div class="element-card"><p style="color:var(--ink-ghost);font-style:italic;">No coherence data.</p></div>'; return; }

      let html = '';

      // Reinforcements
      if (data.reinforcements?.length) {
        html += `<div class="coherence-section"><h3>Reinforcements (${data.reinforcements.length})</h3>`;
        data.reinforcements.forEach(r => {
          html += `<div class="reinforcement-card"><div class="card-label" style="color:var(--signal-success);">Reinforcement</div>
            <p><strong>${r.new_element_id}</strong> reinforces <strong>${r.existing_element_id}</strong></p>
            <p style="font-size:13px;color:var(--ink-soft);margin-top:4px;">${r.similarity || ''}</p>
            <p style="font-size:12px;color:var(--ink-muted);margin-top:4px;">Recommendation: ${r.recommendation || ''}</p>
          </div>`;
        });
        html += '</div>';
      }

      // Contradictions
      if (data.contradictions?.length) {
        html += `<div class="coherence-section"><h3>Contradictions (${data.contradictions.length})</h3>`;
        data.contradictions.forEach(c => {
          html += `<div class="contradiction-card"><div class="card-label" style="color:var(--signal-danger);">${c.severity || 'warning'}</div>
            <p><strong>${c.new_element_id}</strong> conflicts with <strong>${c.existing_element_id}</strong></p>
            <p style="font-size:13px;color:var(--ink-soft);margin-top:4px;">${c.conflict || ''}</p>
            <p style="font-size:12px;color:var(--ink-muted);margin-top:4px;">Recommendation: ${c.recommendation || ''}</p>
          </div>`;
        });
        html += '</div>';
      }

      // Extensions
      if (data.extensions?.length) {
        html += `<div class="coherence-section"><h3>Extensions (${data.extensions.length})</h3>`;
        data.extensions.forEach(ext => {
          html += `<div class="extension-card"><div class="card-label" style="color:var(--signal-info);">New Territory</div>
            <p><strong>${ext.new_element_id}</strong> — ${ext.gap_filled || ''}</p>
            <p style="font-size:12px;color:var(--ink-muted);margin-top:4px;">${ext.confidence_note || ''}</p>
          </div>`;
        });
        html += '</div>';
      }

      // Coverage Map
      if (data.coverage_map) {
        html += '<div class="coherence-section"><h3>Journey Coverage</h3><div class="coverage-grid">';
        Object.entries(data.coverage_map).forEach(([phase, info]) => {
          const cov = info.coverage || 'none';
          html += `<div class="coverage-cell coverage-${cov}">
            <div class="phase-name">${phase.replace(/_/g, ' ')}</div>
            <div class="count">${info.element_count || 0}</div>
            <div class="level">${cov}</div>
          </div>`;
        });
        html += '</div></div>';
      }

      // Emotional Arc
      if (data.emotional_arc_check) {
        const arc = data.emotional_arc_check;
        html += `<div class="coherence-section"><h3>Emotional Arc</h3>`;
        if (arc.journey_emotion_map?.length) {
          html += '<div style="display:flex;gap:8px;flex-wrap:wrap;margin-bottom:12px;">';
          arc.journey_emotion_map.forEach(em => {
            html += `<div style="padding:8px 12px;border:1px solid var(--border);border-radius:var(--radius-sm);font-size:12px;text-align:center;">
              <div style="font-family:'IBM Plex Mono',monospace;font-size:10px;color:var(--ink-muted);text-transform:uppercase;">${em.phase}</div>
              <div style="font-weight:600;color:var(--accent);margin-top:2px;">${(em.target_emotions||[]).join(', ')}</div>
            </div>`;
          });
          html += '</div>';
        }
        if (arc.arc_assessment) html += `<p style="font-size:14px;color:var(--ink-soft);">${arc.arc_assessment}</p>`;
        html += '</div>';
      }

      container.innerHTML = html || '<div class="element-card"><p style="color:var(--ink-ghost);font-style:italic;">No coherence issues detected.</p></div>';
    })();

    // Overview tab
    (function renderOverview() {
      // Coverage
      const coverageContainer = document.getElementById('overview-coverage');
      const coverageData = layers[6]?.coverage_map;
      if (coverageData && coverageContainer) {
        Object.entries(coverageData).forEach(([phase, info]) => {
          const cov = info.coverage || 'none';
          coverageContainer.innerHTML += `<div class="coverage-cell coverage-${cov}">
            <div class="phase-name">${phase.replace(/_/g,' ')}</div>
            <div class="count">${info.element_count||0}</div>
            <div class="level">${cov}</div>
          </div>`;
        });
      }

      // Lens summary
      const summaryEl = document.getElementById('overview-lens-summary');
      if (summaryEl) summaryEl.textContent = layers[0]?.lens?.lens_summary || 'No lens summary available.';

      // Stats
      const statsEl = document.getElementById('overview-stats');
      if (statsEl) {
        const stats = [
          { label: 'Elements', value: totalElements },
          { label: 'Reinforcements', value: reinforcements.length },
          { label: 'Contradictions', value: contradictions.length },
          { label: 'Extensions', value: (coherence.extensions||[]).length }
        ];
        statsEl.innerHTML = stats.map(s =>
          `<div style="padding:14px;background:var(--surface-warm);border:1px solid var(--border);border-radius:var(--radius-md);text-align:center;">
            <div style="font-size:28px;font-weight:700;color:var(--accent);">${s.value}</div>
            <div style="font-size:11px;font-family:'IBM Plex Mono',monospace;color:var(--ink-muted);text-transform:uppercase;">${s.label}</div>
          </div>`
        ).join('');
      }

      // High-priority highlights
      const highlightsEl = document.getElementById('overview-highlights');
      if (highlightsEl) {
        let highPriority = [];
        [1,2,3,4,5,7].forEach(i => {
          (layers[i]?.elements || []).forEach(el => {
            if (el.priority === 'high') highPriority.push(el);
          });
        });
        if (highPriority.length) {
          highlightsEl.innerHTML = `<h2 style="font-family:'Instrument Serif',serif;font-size:22px;font-weight:400;margin:24px 0 16px;">High-Priority Elements</h2>` + highPriority.map(renderElementCard).join('');
        }
      }
    })();
  </script>
</body>
</html>
