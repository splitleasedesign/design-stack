{
  "lens": {
    "guest_call": "user-stories-initial-analysis.md",
    "book_extract": "campbell-initiation-heros-journey.txt"
  },
  "elements": [
    {
      "id": "tests-2103-001",
      "type": "validation_strategy",
      "title": "Recursive Trial Progression Perception Test",
      "validates_element": "works-001",
      "journey_phases": ["active_lease"],
      "problem": "If the platform treats all stays identically in the UI -- same messaging, same visual weight, same emotional tone -- the guest cannot perceive their own growth across the Road of Trials. Campbell's 'preliminary victories' become invisible, and stay 10 feels identical to stay 1. Without visible progression, the guest restricts consciousness to transactional repetition rather than experiencing cumulative initiation.",
      "solution": "Measure whether guests perceive and report different levels of comfort, competence, and belonging at different stay numbers within the same lease. Correlate per-stay review completion rates with stay number to verify that ritual engagement increases with progression.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 428-431)",
          "type": "book",
          "quote": "Dragons have now to be slain and surprising barriers passed -- again, again, and again. Meanwhile there will be a multitude of preliminary victories, unretainable ecstasies, and momentary glimpses of the wonderful land.",
          "insight": "Campbell predicts that the hero's experience of each trial should differ from the last -- each should feel like a 'preliminary victory.' If the platform does not differentiate stays, the prediction fails and the guest's experience is flat repetition."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "An experienced guest applying to a new host is cross-activation in action. Their history, their reviews, their familiarity with how things work -- it all reduces the host's anxiety.",
          "insight": "The guest's accumulating competence is a measurable asset. If review completion and quality increase with stay number, the progression system is working. If they stagnate or decline, the rituals feel like chores rather than growth markers."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "Track per-stay metrics across all active leases: (1) Review completion rate by stay number (stay 1, stay 2, ..., stay N). (2) Average review length by stay number (proxy for engagement depth). (3) Time from stay-end to review submission by stay number (shorter = more internalized ritual). (4) Date Change Tool usage rate by stay number (higher usage = more confident navigation). Plot all four metrics against stay number to test for positive correlation.",
      "success_criteria": "Review completion rate increases across stays: 60% at stay 1, 75% at stay 3, 85% at stay 6. Time-to-review decreases: under 72h at stay 1, under 48h by stay 4, under 24h by stay 7. Date Change Tool usage increases from stay 1 to stay 5, indicating growing agency. All correlations should be positive (r > 0.2).",
      "failure_meaning": "Flat or declining metrics across stay numbers indicate the progression system is not perceived by the guest. The stays feel identical despite differentiated messaging. Root cause may be: progression markers too subtle, milestone messages not distinctive enough, or the three-beat ritual cadence not establishing rhythm.",
      "implementation_hint": "Instrument review submission with a stay_number field. Track Date Change Tool usage per stay period. Create a cohort dashboard that shows all metrics plotted against stay sequence within a lease."
    },
    {
      "id": "tests-2103-002",
      "type": "validation_strategy",
      "title": "Seven-Gate Move-In Orientation Effectiveness Test",
      "validates_element": "works-002",
      "journey_phases": ["acceptance", "move_in"],
      "problem": "If the seven-gate move-in orientation does not reduce the guest's reality shock at physical arrival, the Belly of the Whale remains an unmediated crisis. Campbell's Inanna survives the seven gates because the descent is ritualized; the guest who receives no preparation -- or receives all information at once -- faces the throne naked and unprepared.",
      "solution": "Compare first-stay review scores between guests who engage with the full gate sequence and those who do not. Measure House Manual access timing (pre-arrival vs. post-arrival) as a proxy for orientation uptake.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Inanna's Descent (lines 349-396)",
          "type": "book",
          "quote": "Upon her entering the first gate, the shugurra, the 'crown of the plain' of her head, was removed... Naked, she was brought before the throne.",
          "insight": "The ritualized stripping of expectations (gate by gate) should produce a better first-night experience than unstructured expectation collapse. If first-stay reviews are not improved by the gate sequence, the ritual is not functioning as progressive preparation."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Value before the ask' section",
          "type": "guest_call",
          "quote": "Show something useful first. Offer to refine after.",
          "insight": "Each gate delivers value (neighborhood context, access details, house rules) before requesting engagement. The test verifies that this value-first delivery produces measurably better first-stay outcomes."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "For all guests with upcoming move-ins: (1) Track gate engagement: how many of the 7 gates does each guest open before arrival? (2) Track House Manual first-access timestamp relative to move-in date: before arrival (Gates 1-3 effective) or after (gates missed). (3) Compare first-stay review scores between high-engagement guests (5+ gates opened pre-arrival) and low-engagement guests (0-2 gates opened). (4) Track first-evening check-in response rate (Gate 6) and first-morning debrief participation (Gate 7).",
      "success_criteria": "First-stay review scores for high-engagement guests (5+ gates) average within 0.3 points of their lease-wide average (no first-stay penalty). Low-engagement guests show a first-stay penalty of 0.5+ points below lease average. House Manual pre-arrival access rate above 60%. Gate 6 check-in response rate above 50%.",
      "failure_meaning": "If high-engagement guests still show a first-stay penalty, the gate content is not addressing the right uncertainties -- the stripping of expectations is targeting the wrong ornaments. If pre-arrival access rate is below 60%, the gate delivery timing or notification channel is failing to reach guests.",
      "implementation_hint": "Tag each gate notification with an open/read event. Create a move-in cohort report segmented by gate engagement level. Ensure Gate 6 and Gate 7 prompts use one-tap response options to maximize participation."
    },
    {
      "id": "tests-2103-003",
      "type": "validation_strategy",
      "title": "Counter-Offer Person-First Scan Order Test",
      "validates_element": "works-003",
      "journey_phases": ["negotiation"],
      "problem": "If the counter-offer surface leads with changed terms rather than host identity and reasoning, the guest experiences the Fergus reflex: they see ugliness (unfavorable numbers) before they see the person (the host's intent). Campbell's tale predicts that terms-first presentation produces rejection; person-first presentation produces acceptance. The test must verify this prediction.",
      "solution": "Conduct moderated usability tests measuring the guest's first verbal reaction to a counter-offer and correlating it with the scan order of the counter-offer surface.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Tale of Niall (lines 694-709)",
          "type": "book",
          "quote": "'Sooner than give thee a kiss I would perish of thirst!' ... 'Forby giving thee a kiss, I will even hug thee!'",
          "insight": "Fergus sees the surface and refuses. Niall sees the person and embraces. The test must verify whether person-first presentation produces Niall responses (acceptance, dialogue) and terms-first produces Fergus responses (rejection, disengagement)."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Messaging is the highest cross-activation story' section",
          "type": "guest_call",
          "quote": "When a guest messages a host, that's not just UX convenience -- it's the moment two strangers begin to trust each other through the platform.",
          "insight": "The message path on the counter-offer is the mechanism for converting Fergus into Niall. The test must measure whether the person-first layout increases messaging rate on counter-offers."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Recruit 8-10 guests who have previously submitted proposals. Show each a counter-offer mock-up with person-first layout (host photo + name + note at top, terms below). Measure: (1) First verbal reaction: classify as positive-relational ('she seems reasonable'), negative-transactional ('they cut my duration'), or neutral. (2) Eye-tracking: does the guest look at the host identity zone before the terms zone? (3) Chosen response path: accept, counter, or message? (4) Compare with a control group seeing terms-first layout.",
      "success_criteria": "Person-first layout: at least 6 of 10 guests produce positive-relational first reactions. Eye-tracking confirms host zone scanned before terms zone in 7+ of 10. Message path chosen by at least 3 of 10 (vs. baseline expectation of 1 of 10 for terms-first). Counter-offer acceptance or dialogue rate (accept + message) above 60%.",
      "failure_meaning": "If person-first layout does not shift first reactions toward relational framing, the host identity zone may be visually too small, the note field may be empty (hosts not prompted to explain), or the guest's Fergus reflex is stronger than visual layout can redirect. Consider making the host's note mandatory for counter-offers.",
      "implementation_hint": "Mock-up two variants: person-first (host zone top, terms middle, actions bottom) and terms-first (terms top, host sidebar, actions bottom). Run within-subjects comparison with counterbalanced order. Record think-aloud protocol for qualitative insight."
    },
    {
      "id": "tests-2103-004",
      "type": "validation_strategy",
      "title": "Host Transfiguration Progressive Avatar Recognition Test",
      "validates_element": "works-004",
      "journey_phases": ["listing_evaluation", "negotiation", "move_in", "active_lease"],
      "problem": "If the host's visual representation remains static across all phases -- the same 40px circular avatar throughout -- the guest experiences what Campbell calls the goddess 'spellbound to banality.' The host-as-person does not deepen as the relationship deepens. The progressive avatar system (larger size, engagement ring, response time badge, communication status dot) should produce measurably increased perception of the host as a relational partner across phases.",
      "solution": "Survey guests at different phases about their perception of the host as a person vs. a listing feature. Measure whether avatar enhancement correlates with relational language in reviews.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Meeting with the Goddess (lines 662-677)",
          "type": "book",
          "quote": "The form of the goddess undergoes for him a series of transfigurations... By deficient eyes she is reduced to inferior states; by the evil eye of ignorance she is spellbound to banality.",
          "insight": "A static avatar system IS the 'deficient eyes.' If the progressive system produces no measurable change in the guest's perception of the host-as-person, the transfiguration is not being perceived."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "A skeptical guest who sees verified reviews, ID checks, and real host history doesn't need the platform to convince them -- another user already did.",
          "insight": "The avatar enhancements (engagement ring, response time badge) ARE trust signals made visual. The test must verify that guests process these signals as trust-relevant rather than decorative."
        }
      ],
      "priority": "medium",
      "validation_method": "analytics",
      "test_description": "Track guest-host messaging initiation rates across phases: (1) During listing evaluation (standard avatar): baseline messaging rate. (2) During negotiation (enhanced avatar with engagement ring and response badge): messaging rate. (3) During active lease (relational avatar with communication status): messaging rate. Also analyze review text for relational language ('helpful,' 'responsive,' 'friendly,' 'welcoming') vs. transactional language ('clean,' 'as described,' 'adequate').",
      "success_criteria": "Messaging initiation rate increases from listing_evaluation to negotiation by at least 20%. Reviews during active_lease contain relational language in at least 60% of entries. Communication status dot on the active-lease avatar correlates with higher host-initiated messaging rates (active status prompts guest confidence that the host is available).",
      "failure_meaning": "If messaging rates do not increase across phases, the avatar enhancements are not being noticed or are perceived as decorative. If review language remains transactional despite progressive avatar, the visual system alone is insufficient -- copy and interaction design may need to carry more of the transfiguration load.",
      "implementation_hint": "A/B test the progressive avatar system against static avatar to isolate the visual variable. Use NLP sentiment analysis on review text to classify relational vs. transactional language at scale."
    },
    {
      "id": "tests-2103-005",
      "type": "validation_strategy",
      "title": "Apotheosis Transformation Credential Retention Impact Test",
      "validates_element": "works-005",
      "journey_phases": ["active_lease"],
      "problem": "Without a visible transformation narrative at lease end, the guest exits feeling 'done' rather than 'initiated.' The Bodhisattva who carries the boon forward is replaced by a consumer who has consumed. Retention depends on whether the guest recognizes their transformation as a portable credential, not just a completed transaction.",
      "solution": "A/B test the end-of-lease reflection surface with transformation credential visibility against a standard lease-end notification. Measure re-engagement rates within 90 days.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Apotheosis (lines 1806-1812)",
          "type": "book",
          "quote": "He paused: he made a vow that before entering the void he would bring all creatures without exception to enlightenment.",
          "insight": "The Bodhisattva's pause is the critical moment. If the platform rushes past it ('Browse new listings!'), the guest does not recognize their transformation. If it provides a mirror ('You completed 12 stays -- here is what hosts say about you'), the transformation becomes visible and portable."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "An experienced guest applying to a new host is cross-activation in action.",
          "insight": "Cross-activation requires the guest to carry their credential forward. The test measures whether showing the credential at lease end actually produces forward motion (new lease initiation) at a higher rate than not showing it."
        }
      ],
      "priority": "medium",
      "validation_method": "a_b_test",
      "test_description": "At lease end, randomly assign guests to: (A) control -- standard lease-end notification ('Your lease with [Host] is complete') with 'Browse listings' CTA; (B) treatment -- transformation reflection card showing completed stays, cumulative nights, composite review quote, and credential visibility statement ('Future hosts will see your X completed stays'), followed by dual CTA: 'Continue with [Host]' and 'Explore new spaces.' Measure: (1) New lease initiation within 90 days. (2) Time to first search action post-lease. (3) Engagement with the reflection card (dwell time, scroll depth).",
      "success_criteria": "Treatment group new-lease initiation rate exceeds control by at least 10 percentage points within 90 days. Treatment group time-to-first-search is shorter than control. Reflection card dwell time averages above 15 seconds (indicating absorption, not skip).",
      "failure_meaning": "If the transformation credential does not improve retention, either the narrative is not compelling (the mirror is not clear enough), or the guest's retention decision is driven by external factors (life changes, budget) that no credential can address. Investigate with qualitative follow-up: 'What influenced your decision about your next living arrangement?'",
      "implementation_hint": "Compile the transformation card from existing data (stays, reviews, nights). Use the host's review quotes selectively -- only positive composite. If the lease had poor reviews, emphasize quantitative completion ('12 stays completed') over qualitative assessment."
    },
    {
      "id": "tests-2103-006",
      "type": "validation_strategy",
      "title": "Seven-Gate Progressive Disclosure Cognitive Load Test",
      "validates_element": "communicates-001",
      "journey_phases": ["acceptance", "move_in"],
      "problem": "If the seven-gate sequence delivers too much information per gate or compresses gates when move-in is imminent, the progressive disclosure fails -- the guest is overwhelmed despite the structured sequence. Inanna's gates work because each strips exactly ONE ornament. A gate that strips three produces the same trauma as no gates at all.",
      "solution": "Measure gate content engagement metrics (open rate, read time, completion rate) and correlate with gate content length. Test the compressed gate variant (for last-minute acceptances) against the full sequence.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Inanna's Descent (lines 354-356)",
          "type": "book",
          "quote": "'Extraordinarily, O Inanna, have the decrees of the nether world been perfected. Do not question the rites.'",
          "insight": "The rites are 'perfected' because each gate addresses exactly one concern. The test must verify that each gate's content is narrow enough to be processed in under 60 seconds -- if it is not, the rite is imperfect."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Value before the ask' section",
          "type": "guest_call",
          "quote": "Any flow that requires users to give information before seeing results will lose most of them.",
          "insight": "Each gate delivers information before requesting engagement. The test must verify that the value-first principle holds at every gate: content is consumed before any action is requested."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "For every gate notification delivered: (1) Track open rate (gate opened / gate delivered). (2) Track read time (time from open to dismissal or next action). (3) Track action completion rate (arrival confirmation at Gate 4, check-in response at Gate 6, debrief participation at Gate 7). (4) Correlate gate content word count with open rate and read time. (5) For compressed gates (last-minute move-ins): compare engagement with the single compressed card vs. full 7-gate sequence.",
      "success_criteria": "Individual gate open rate above 70% for Gates 1-3 (pre-arrival). Read time under 60 seconds per gate. Gate 4 arrival confirmation rate above 80%. Compressed gate engagement (for last-minute move-ins) above 60%. No gate with more than 150 words of content.",
      "failure_meaning": "Low open rates on early gates indicate delivery timing is wrong (too early, guest not yet thinking about move-in) or channel is wrong (push notification not reaching guest). High read times indicate gate content is too long (more than one ornament per gate). Low compressed-gate engagement indicates the single-card variant is overwhelming.",
      "implementation_hint": "A/B test gate content length: current length vs. 50% reduction. Track per-gate metrics separately to identify which gates succeed and which fail. If Gate 3 (house rules) consistently underperforms, the rules may need further distillation."
    },
    {
      "id": "tests-2103-007",
      "type": "validation_strategy",
      "title": "Amulet Framing Agency Perception Test",
      "validates_element": "communicates-004",
      "journey_phases": ["active_lease"],
      "problem": "If the Date Change Tool, cleaning photo submission, and arrival notification are perceived as compliance requirements rather than hero's amulets, the guest restricts consciousness to tenant-mode rather than expanding to active-navigator mode. Campbell's Woman as Temptress warns: 'every failure to cope with a life situation must be laid to a restriction of consciousness.' The framing of platform tools determines which consciousness the guest develops.",
      "solution": "Conduct qualitative interviews with active-lease guests about their perception of platform tools. Compare language: do they describe tools as 'things I have to do' (compliance) or 'things I use' (agency)?",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 22-24)",
          "type": "book",
          "quote": "The hero is covertly aided by the advice, amulets, and secret agents of the supernatural helper.",
          "insight": "Amulets are 'covert' -- the hero experiences them as extensions of their own capacity, not external rules. The test measures whether the reframed tools ('Adjust Your Schedule' vs. 'Request Date Change') shift the guest's perception from compliance to agency."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Authentication should be invisible until it matters' section",
          "type": "guest_call",
          "quote": "Authentication should be invisible until it matters.",
          "insight": "The invisibility principle extends to tool framing: the approval process should be invisible in the interaction's framing even if it exists in the backend. The test measures whether guests perceive host approval as the primary interaction (compliance) or their own schedule manipulation as the primary interaction (agency)."
        }
      ],
      "priority": "medium",
      "validation_method": "usability_test",
      "test_description": "Recruit 6-8 active-lease guests. Ask each to: (1) Walk through making a date change. Record their verbal description of what they are doing ('I am requesting a change' vs. 'I am adjusting my schedule'). (2) Walk through submitting cleaning photos. Record their framing ('I have to submit these' vs. 'I am showing the space is ready'). (3) Ask: 'Who is in control of your schedule during the lease?' Record whether they say 'me,' 'the host,' 'the platform,' or 'we both are.' (4) Compare A (current compliance framing) vs. B (reframed agency language).",
      "success_criteria": "In the reframed variant (B), at least 5 of 8 guests use agency language ('I am adjusting,' 'I am showing') rather than compliance language ('I have to,' 'I need to submit'). At least 5 of 8 answer 'me' or 'we both are' to the control question. Date Change Tool usage rate increases by 15% in the reframed variant.",
      "failure_meaning": "If guests continue to use compliance language despite reframing, the label change alone is insufficient. The entire interaction flow may need redesign: the host-approval step may be too prominent, the calendar-first interface may not be calendar-first enough, or the guest's pre-existing mental model of 'tenant-requesting-landlord' may override copy changes.",
      "implementation_hint": "Run the usability test with high-fidelity prototypes of both framings. Focus on the Date Change Tool as the highest-frequency interaction. If label changes succeed, extend the agency framing to all active-lease tools."
    },
    {
      "id": "tests-2103-008",
      "type": "validation_strategy",
      "title": "Stay Cycle Ritual Cadence Internalization Test",
      "validates_element": "behaves-003",
      "journey_phases": ["active_lease"],
      "problem": "The three-beat ritual cadence (Arrival, Evidence, Reflection) must be internalized by the guest such that by stay 3 the ritual feels natural and by stay 6 it is automatic. If the cadence is not internalized -- if the guest continues to need prompts at stay 8 identical to stay 1 -- the ritual is perceived as external obligation rather than internalized rhythm. Campbell's Road of Trials produces mastery; a failed cadence produces fatigue.",
      "solution": "Track the time between beat trigger and beat completion across stays. Faster completion at later stays indicates internalization. Track unprompted behavior: does the guest mark arrival before the prompt fires?",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 428-431)",
          "type": "book",
          "quote": "Dragons have now to be slain and surprising barriers passed -- again, again, and again.",
          "insight": "The 'again, again, and again' should produce skill, not tedium. The test measures whether the ritual becomes faster and more automatic with repetition -- the behavioral signature of skill acquisition."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "Every review is a past guest activating a future one.",
          "insight": "The reflection beat (review) is cross-activation infrastructure. Its completion rate directly determines marketplace trust density. The test must verify that the cadence produces reliably high review completion."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "For every stay cycle in every active lease: (1) Track time from arrival-beat prompt to arrival-mark completion (stay 1 vs. stay 3 vs. stay 6). (2) Track time from evidence-beat prompt to cleaning photo submission (same comparison). (3) Track time from reflection-beat prompt to review submission (same comparison). (4) Track unprompted arrivals: does the guest mark arrival BEFORE the dashboard prompt surfaces? Count unprompted arrivals as a percentage by stay number. (5) Track review completion rate by stay number.",
      "success_criteria": "Time-to-completion for all three beats decreases by at least 30% between stay 1 and stay 6. Unprompted arrival marks reach 20% by stay 4 and 40% by stay 8. Review completion rate reaches 85% by stay 5 and maintains above 80% thereafter.",
      "failure_meaning": "If time-to-completion does not decrease, the ritual is not becoming internalized -- the prompts are being processed as interruptions each time rather than as familiar cadence markers. If unprompted behavior does not emerge, the guest has not developed the rhythm. Root cause may be: prompts not delivered at consistent times (breaking temporal pattern), or prompt styling not evolving (same visual weight at stay 8 as stay 1, failing to reflect growing competence).",
      "implementation_hint": "Store beat-completion timestamps per stay cycle. Create a per-lease cadence report showing all three beat metrics plotted against stay number. Alert on leases where review completion drops below 60% after stay 3 -- this may indicate cadence breakdown."
    },
    {
      "id": "tests-2103-009",
      "type": "validation_strategy",
      "title": "Date Change Amulet Response Time Test",
      "validates_element": "behaves-004",
      "journey_phases": ["active_lease"],
      "problem": "If the Date Change Tool does not respond within 50ms to calendar interactions, the amulet feels bureaucratic rather than responsive. Campbell's hero's instrument must feel like an extension of will. Any perceptible delay between intent (tapping a date) and response (visual toggle) breaks the illusion of agency and returns the guest to tenant-requesting-permission mode.",
      "solution": "Measure calendar interaction response times in production and compare with user-perceived responsiveness thresholds.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 22-24)",
          "type": "book",
          "quote": "The hero is covertly aided by the advice, amulets, and secret agents of the supernatural helper.",
          "insight": "The amulet is 'covert' -- it must not draw attention to itself as a separate system. Responsive performance (sub-50ms) makes the tool feel like the guest's own calendar rather than a platform mediation layer."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Authentication should be invisible until it matters' section",
          "type": "guest_call",
          "quote": "Authentication should be invisible until it matters. Inline auth pop-up, not a full-page redirect.",
          "insight": "The Date Change Tool's host-confirmation step is its 'authentication.' It should be invisible until the guest taps 'Confirm Changes.' Before that moment, the calendar must respond with zero perceived latency."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "Instrument the Date Change Tool calendar view with performance metrics: (1) Time from date-tap to visual toggle (target: <50ms). (2) Time from drag-start to drag-visual-update (target: 60fps, <16ms per frame). (3) Time from 'Confirm Changes' tap to status-line appearance (target: <200ms perceived, optimistic UI). (4) Time from server confirmation receipt to pending-to-confirmed visual transition (target: <400ms animation). (5) Track abandonment rate: guests who open the calendar but do not confirm any changes.",
      "success_criteria": "P95 date-tap response time under 50ms. P95 drag frame rate above 55fps. Optimistic confirmation perceived in under 200ms. Calendar abandonment rate below 20% (most openers should complete at least one change).",
      "failure_meaning": "If response times exceed 50ms, the calendar interface is not using local-state manipulation -- it may be making server roundtrips on every interaction. Fix: ensure all calendar interactions are local until 'Confirm Changes.' If abandonment is above 20%, the calendar UI may be confusing (unclear which dates are toggleable) or the confirmation step may be introducing friction.",
      "implementation_hint": "Use client-side state for all calendar interactions. Only send to server on explicit 'Confirm Changes.' Use requestAnimationFrame for drag interactions. Profile with browser DevTools Performance tab."
    },
    {
      "id": "tests-2103-010",
      "type": "validation_strategy",
      "title": "Transformation Mirror Emotional Impact Test",
      "validates_element": "behaves-005",
      "journey_phases": ["active_lease"],
      "problem": "If the mid-lease and end-of-lease reflection surfaces are perceived as dashboard clutter rather than meaningful mirrors, the Apotheosis moment is lost. The guest dismisses the card without absorbing it, and the transformation goes unrecognized. Campbell's hero must 'rise to a glimpse of the source' -- if the reflection card does not induce this rising, it is functionally inert.",
      "solution": "Measure dwell time on reflection cards and correlate with subsequent guest behavior (re-lease rate, profile enhancement, new lease initiation).",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Apotheosis (lines 1719-1721)",
          "type": "book",
          "quote": "The hero transcends life with its peculiar blind spot and for a moment rises to a glimpse of the source.",
          "insight": "The 'glimpse' requires a moment of absorption. Dwell time on the reflection card is the behavioral proxy for this absorption. A card dismissed in under 3 seconds did not produce a glimpse."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "An experienced guest applying to a new host is cross-activation in action.",
          "insight": "The reflection card's forward-looking element ('Future hosts will see your X completed stays') should produce forward behavior. The test measures whether guests who absorb the reflection card are more likely to initiate new leases."
        }
      ],
      "priority": "medium",
      "validation_method": "analytics",
      "test_description": "Track for every reflection card (mid-lease and end-of-lease): (1) Dwell time from card render to dismissal (target: >15 seconds for absorption). (2) Scroll depth within the card (did the guest read the full summary?). (3) Interaction with optional elements: 'Share what is working' (mid-lease) or 'Continue with [Host]' / 'Explore new spaces' (end-of-lease). (4) Correlate dwell time >15s with 90-day re-engagement rate. (5) Track profile edits within 7 days of seeing the end-of-lease reflection (proxy for identity investment).",
      "success_criteria": "Average dwell time above 15 seconds for end-of-lease reflection, above 10 seconds for mid-lease reflection. Scroll depth: at least 70% of guests scroll to the credential statement. Guests with dwell time >15s show a 15+ percentage point higher re-engagement rate within 90 days. Profile edit rate increases by 20% within 7 days of reflection card exposure.",
      "failure_meaning": "Low dwell time (<5 seconds average) indicates the card is being dismissed as noise. The entrance animation may not be sufficiently differentiated from standard dashboard cards (it should be the slowest, most dignified animation in the system). If scroll depth is low, the most important content (credential statement) may be too far below the fold.",
      "implementation_hint": "Track card_rendered, card_scrolled, card_dismissed events with timestamps. Compute dwell and scroll metrics per card. Ensure the reflection card entrance animation (500-600ms) is distinctly slower than any other dashboard element to signal importance."
    },
    {
      "id": "tests-2103-011",
      "type": "validation_strategy",
      "title": "Prepared Vulnerability Emotional State Test",
      "validates_element": "feels-001",
      "journey_phases": ["move_in"],
      "problem": "If the move-in emotional design produces comfort rather than prepared vulnerability, the platform is being dishonest about the threshold crossing. If it produces anxiety rather than preparation, the seven-gate sequence is failing. The target emotion -- prepared vulnerability -- is a narrow band between false comfort and unmediated crisis.",
      "solution": "Survey guests within 24 hours of move-in about their emotional state. Classify responses on the prepared-vulnerability spectrum.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 176-178)",
          "type": "book",
          "quote": "I stood before a dark cave, wanting to go in, and I shuddered at the thought that I might not be able to find my way back.",
          "insight": "The shudder is expected. The test must distinguish between guests who shudder with support (prepared vulnerability) and guests who shudder alone (unmediated crisis). Both experience the shudder; only the first are prepared."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Value before the ask' section",
          "type": "guest_call",
          "quote": "Show something useful first.",
          "insight": "The emotional value the platform delivers at move-in is validation ('first evenings can feel strange -- that is completely normal'). The test must measure whether this validation is received and effective."
        }
      ],
      "priority": "medium",
      "validation_method": "usability_test",
      "test_description": "Deploy a one-question pulse survey at Gate 7 (morning after first night): 'How did you feel when you first walked in?' with four options mapped to the emotional spectrum: (A) 'Comfortable and at home' (over-comfort -- gate sequence may be creating false expectations), (B) 'A bit nervous but I felt prepared' (prepared vulnerability -- target), (C) 'Anxious and unsure' (unmediated crisis -- gates failed), (D) 'Excited and curious' (positive but not the target -- may indicate the guest's personality rather than the gate effect). Track distribution across options. Correlate with gate engagement level.",
      "success_criteria": "At least 50% of respondents select option B ('nervous but prepared'). Combined B+D above 70%. Option C below 15%. Guests who engaged with 5+ gates show higher B rates than guests who engaged with 0-2 gates.",
      "failure_meaning": "If option A dominates, the gates may be over-promising comfort that the physical space cannot deliver. If option C dominates, the gates are not reaching the guest or their content is not addressing the right anxieties. If no correlation between gate engagement and emotional state, the gates are not the mechanism producing the emotional effect.",
      "implementation_hint": "Embed the pulse survey as the Gate 7 morning debrief interaction. Keep it to a single tap. Track the response alongside gate engagement data for correlation analysis."
    },
    {
      "id": "tests-2103-012",
      "type": "validation_strategy",
      "title": "Competent Rhythm Progressive Scaffolding Reduction Test",
      "validates_element": "feels-003",
      "journey_phases": ["active_lease"],
      "problem": "If the progressive scaffolding reduction (full explanation at stay 1, icon-only at stay 6) occurs too fast, early guests feel unsupported. If too slow, experienced guests feel patronized. Campbell's hero grows competent through the Road of Trials, and the platform must match this growth rate.",
      "solution": "Track the relationship between scaffolding level and guest satisfaction. Identify the optimal stay number at which each scaffolding reduction should occur.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Road of Trials (lines 428-431)",
          "type": "book",
          "quote": "Meanwhile there will be a multitude of preliminary victories.",
          "insight": "Each 'preliminary victory' (successful stay) builds competence. The scaffolding reduction should track these victories, not a fixed schedule. The test measures whether the reduction schedule matches guests' actual competence growth."
        },
        {
          "source": "user-stories-initial-analysis.md, Cross-Activation section",
          "type": "guest_call",
          "quote": "Their history, their reviews, their familiarity with how things work -- it all reduces the host's anxiety.",
          "insight": "'Familiarity with how things work' is the competent rhythm. The test must verify that the platform's scaffolding reduction tracks this familiarity rather than imposing an arbitrary schedule."
        }
      ],
      "priority": "medium",
      "validation_method": "analytics",
      "test_description": "Deploy three scaffolding reduction schedules: (A) fast (full scaffolding stays 1-2, reduced 3-4, minimal 5+), (B) medium (full 1-3, reduced 4-5, minimal 6+), (C) slow (full 1-4, reduced 5-6, minimal 7+). Measure per-stay: (1) Beat completion rate (arrival, evidence, reflection). (2) Time-to-completion per beat. (3) Guest satisfaction with the stay cycle (embedded in the reflection beat: 'Did the prompts feel right for you?' yes/no). Compare across schedules.",
      "success_criteria": "The optimal schedule shows both: (1) no drop in beat completion rate at any scaffolding reduction point, and (2) highest satisfaction ('prompts feel right') at the minimal scaffolding level. Expected winner: schedule B (medium), based on typical habit formation research suggesting 3-4 repetitions for internalization.",
      "failure_meaning": "If all schedules show completion drops at reduction points, the scaffolding content is load-bearing -- guests rely on explanations even at later stays. This would indicate the stay cycle UI is not self-evident enough to work without labels. Redesign the interaction to be more self-explanatory rather than relying on progressive copy reduction.",
      "implementation_hint": "Randomize guests into the three schedules at lease start. Track all metrics with a schedule_variant field. Run for at least 100 leases per variant to achieve statistical power."
    },
    {
      "id": "tests-2103-013",
      "type": "validation_strategy",
      "title": "Journey-Level Cross-Phase Coherence Test: The Stripping of Expectations Arc",
      "validates_element": "cross_phase_pattern (Stripping of Expectations Arc, from L0)",
      "journey_phases": ["discovery", "search", "listing_evaluation", "proposal_creation", "negotiation", "acceptance", "move_in", "active_lease"],
      "problem": "Campbell's Inanna loses one ornament at each of seven gates. The guest journey should similarly produce progressive expectation calibration from discovery (maximum fantasy) through active_lease (full experiential reality). If the platform fails to calibrate expectations at each phase -- if the listing promises more than reality delivers, or if negotiation does not adequately reset the guest's terms-fantasy -- the expectation gap compounds and produces crisis at move-in.",
      "solution": "Track the delta between guest expectations (expressed at proposal creation) and reported reality (expressed in first-stay review). If the seven-gate orientation and the negotiation-as-revelation system work, this delta should be small.",
      "evidence": [
        {
          "source": "campbell-initiation-heros-journey.txt, Inanna's Descent (lines 349-410)",
          "type": "book",
          "quote": "Upon her entering the first gate, the shugurra, the 'crown of the plain' of her head, was removed... Naked, she was brought before the throne.",
          "insight": "The seven-gate model predicts that expectations must be stripped progressively. A large expectation-reality gap at move-in means the stripping failed at earlier gates."
        },
        {
          "source": "user-stories-initial-analysis.md, 'Reality vs. listing expectations' section",
          "type": "guest_call",
          "quote": "Accurate listing photos and descriptions are critical.",
          "insight": "Listing accuracy is Gate 0 -- the ornament that should never be false. The test must verify that by the time the guest reaches move-in, their expectations have been calibrated by every preceding phase."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "At proposal creation, capture the guest's stated expectations via structured fields: expected space quality (1-5), expected host responsiveness (1-5), expected neighborhood quality (1-5). At first-stay review, capture the same three dimensions. Calculate the expectation-reality delta per dimension. Segment by: (1) gate engagement level (high vs. low), (2) whether a counter-offer was received (negotiation calibration), (3) whether the guest messaged the host before move-in (relational preparation).",
      "success_criteria": "Expectation-reality delta below 0.5 points on all three dimensions for guests with high gate engagement + counter-offer + pre-move-in messaging. Overall delta below 1.0 points. Guests with high gate engagement show significantly smaller delta than low-engagement guests.",
      "failure_meaning": "Large deltas (>1.0) indicate the platform is not stripping expectations effectively. If the delta is largest on 'space quality,' listing photos are misleading (a pre-Gate-1 failure). If largest on 'host responsiveness,' the negotiation phase did not reveal the host-as-person effectively (a Meeting-with-the-Goddess failure). If largest on 'neighborhood quality,' Gate 1 (neighborhood orientation) is not reaching guests or its content is inadequate.",
      "implementation_hint": "Add three 1-5 slider fields to the proposal creation flow (framed as 'What are you expecting?'). Mirror the same three sliders in the first-stay review ('How was it actually?'). Compute delta automatically. Flag leases with delta >1.5 for manual review."
    }
  ]
}