{
  "lens": {
    "guest_call": "Taline  Bryant.txt",
    "book_extract": "creativeacts-dschool-exercises.txt"
  },
  "elements": [
    {
      "id": "tests-001",
      "type": "validation_strategy",
      "title": "Category Comprehension Speed Validation",
      "validates_element": "works-001",
      "journey_phases": ["discovery", "search"],
      "problem": "If the product-category label fails to communicate what Split Lease is within 30 seconds, guests will continue to arrive with false mental models, waste agent time on basic explanations, and drop out when they discover the mismatch mid-evaluation.",
      "solution": "Measure whether guests can correctly identify the Split Lease model (part-time, not full-time rental) within 30 seconds of encountering any guest-facing touchpoint, without human assistance.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 0:52",
          "type": "guest_call",
          "quote": "I just wanted to know, like that, is it for a certain time?",
          "insight": "Taline's first question reveals zero comprehension of the product category after encountering the Craigslist ad. The test must verify that the redesigned touchpoints prevent this comprehension failure."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 86",
          "type": "book",
          "quote": "What the students thought might be the need and what they actually found turned out to be two very different things.",
          "insight": "Misaligned expectations at the start corrupt all subsequent work. The test measures whether the expectation-reality gap is closed at first contact."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Recruit 10 participants unfamiliar with Split Lease. Show them the redesigned Craigslist ad (or equivalent external listing) for 30 seconds. Then ask: 'What kind of rental is this? How many nights per week would you stay?' Separately, show 10 participants the original ad format and ask the same questions. Compare comprehension rates between groups.",
      "success_criteria": "At least 7 of 10 participants (70%) in the redesigned group correctly identify this as a part-time rental (2-5 nights/week), compared to baseline. If the baseline group also achieves 70%, the element may not be necessary; if the baseline is below 30%, the element addresses a confirmed critical gap.",
      "failure_meaning": "If fewer than 7 of 10 understand the model after 30 seconds, the category label is insufficient. Possible causes: the label is too small, the language is too abstract, the visual calendar icon is not parsed correctly, or the label competes with other listing elements for attention. Redesign the label's visual weight, simplicity, or placement.",
      "implementation_hint": "For a Playwright-based automated proxy: create a test page with the redesigned listing card. Use a timed overlay that hides the page after 30 seconds. Present a multiple-choice question: 'This listing is for: (a) a full-time apartment, (b) a part-time rental, 2-5 nights/week, (c) a short-term vacation stay, (d) a shared room.' Track selection accuracy across test sessions. For live usability: record eye-tracking to verify the category badge is in the first fixation zone."
    },
    {
      "id": "tests-002",
      "type": "validation_strategy",
      "title": "Self-Adaptation Conversion Rate Validation",
      "validates_element": "works-002",
      "journey_phases": ["listing_evaluation", "negotiation", "proposal_creation"],
      "problem": "If the platform cannot replicate Bryant's ability to suggest alternatives in real time, guests whose initial need does not match the model will bounce at the mismatch moment instead of adapting their needs.",
      "solution": "Measure the percentage of guests who enter with a non-matching need (e.g., full-time, 7 nights/week) and successfully convert to a matching pattern (e.g., M-F) through the platform's structured alternatives, without agent intervention.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:02-3:53",
          "type": "guest_call",
          "quote": "Yeah, my full time... [Bryant: Five nights a week is likely something that you would be interested in] ... And I just do it like Monday through Friday.",
          "insight": "Taline adapted in under 60 seconds because Bryant offered a specific alternative. The test measures whether the platform's self-service alternatives achieve the same conversion."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 86",
          "type": "book",
          "quote": "They went into the situation without being fixed on the exact problem they would tackle.",
          "insight": "Productive adaptation requires support and frameworks, not just rejection and self-reliance. The test validates that the platform provides this support."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "Track all guest sessions where the initial search or filter input indicates a non-matching need (7 nights/week, full-time, 30-day stay). For these sessions, measure: (1) how many encounter the mismatch bridge / alternative suggestion, (2) how many interact with the alternative (tap 'Try this pattern' or similar), (3) how many complete a proposal with an adapted pattern. Compare against baseline dropout rate for guests who encounter a mismatch with no alternative shown.",
      "success_criteria": "Adaptation conversion rate above 30% (of guests who encounter a mismatch, at least 30% successfully adapt to a matching pattern through the platform's alternatives). Baseline is assumed to be near 0% without agent intervention, based on Taline's call evidence.",
      "failure_meaning": "If adaptation conversion is below 30%, the alternatives are either not visible enough, not specific enough, not priced clearly enough, or presented too late in the flow. Check: (1) is the bridge card appearing when mismatches are detected? (2) are the suggested patterns relevant to the guest's area and listing? (3) is the estimated cost visible on the alternative? (4) is the 'Try this pattern' action prominent enough?",
      "implementation_hint": "Analytics events to implement: 'mismatch_detected' (guest selects 7 nights or indicates full-time), 'alternative_shown' (bridge card rendered), 'alternative_interacted' (guest taps any element on the bridge card), 'alternative_accepted' (guest loads the suggested pattern into the pattern builder), 'proposal_with_adapted_pattern' (guest submits a proposal using a pattern different from their initial input). Funnel: mismatch_detected -> alternative_shown -> alternative_interacted -> alternative_accepted -> proposal_submitted."
    },
    {
      "id": "tests-003",
      "type": "validation_strategy",
      "title": "Pricing Visibility Before Agent Contact Validation",
      "validates_element": "works-003",
      "journey_phases": ["listing_evaluation", "proposal_creation"],
      "problem": "If indicative pricing is not visible before the guest's first agent interaction, guests will continue to ask 'how much does it cost?' as their first or second question, consume agent time on information that could be self-service, and drop out when they cannot get a number to plan around.",
      "solution": "Measure whether 100% of guest-facing listing surfaces show a price signal (range, estimate, or confirmed) before the guest initiates any human contact.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 2:51",
          "type": "guest_call",
          "quote": "So I just want to know how much would it cost.",
          "insight": "The most direct evaluation question a guest can ask. If this question is answered by the listing page before the call, the call's purpose shifts from basic information to qualified discussion."
        },
        {
          "source": "Taline  Bryant.txt, 5:33-5:50",
          "type": "guest_call",
          "quote": "I have sort of a general idea, but not exact, just because typically these nightly pricing will be set specific on the situation.",
          "insight": "Even the agent cannot provide pricing. The test validates that the platform fills this gap with visible estimates."
        }
      ],
      "priority": "high",
      "validation_method": "automated",
      "test_description": "Automated audit of all guest-facing listing surfaces (Craigslist ads, landing pages, listing cards, listing detail pages). For each surface, verify: (1) a price signal is present (per-night range, estimated monthly total, or confirmed price), (2) the price signal is visible without scrolling on the default viewport (1280x720 desktop, 375x667 mobile), (3) the price signal is not obscured by overlays, loading states, or conditional rendering. Run weekly.",
      "success_criteria": "100% of guest-facing listing surfaces show a price signal above the fold. Zero listing pages render without any price indication. If any listing lacks pricing data entirely (new listing, host has not set a range), a fallback range based on area averages must appear.",
      "failure_meaning": "If any listing surface lacks a price signal, the pricing architecture has a gap. Check: (1) does the listing have a nightly rate range set by the host? If not, is the area-average fallback rendering? (2) is the price element's CSS positioning placing it below the fold? (3) is the price element conditionally hidden behind a loading state that fails to resolve?",
      "implementation_hint": "Playwright test: for each listing URL in the database, navigate to the page, wait for load, take a screenshot of the viewport. Use image analysis or DOM query to verify that an element matching [data-testid='price-signal'] exists within the viewport boundaries. For Craigslist ads: since these are off-platform, create a checklist validation that runs during ad creation -- no ad is published without a price range in the first 3 lines of the ad body."
    },
    {
      "id": "tests-004",
      "type": "validation_strategy",
      "title": "Post-Call Engagement Retention Validation",
      "validates_element": "works-004",
      "journey_phases": ["proposal_creation", "negotiation", "acceptance"],
      "problem": "If guests are released into a void after their first interaction with no status tracking, no summary, and no timeline, the highest-risk dropout gap in the guest journey remains open. Guests with urgent needs will find alternatives during the unstructured wait.",
      "solution": "Measure the percentage of guests who receive a post-call summary within 5 minutes AND return to the platform at least once before receiving a formal proposal.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 5:22-5:33",
          "type": "guest_call",
          "quote": "I can talk to him and talk to him about your situation. And I get back to you on that.",
          "insight": "The entire forward path depends on a single human follow-up with no timeline and no status visibility. The test measures whether the platform fills this void."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 69",
          "type": "book",
          "quote": "But success is never about a single moment of insight.",
          "insight": "The status tracker communicates that the process has multiple steps. The test validates that this multi-step visibility maintains guest engagement."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "Track all guest interactions that result in a substantive call or chat. Measure: (1) time from interaction end to summary delivery (target: under 5 minutes), (2) percentage of guests who open the summary/status page within 24 hours, (3) percentage of guests who return to the status page at least once before receiving a proposal, (4) proposal acceptance rate for guests who engaged with the status tracker vs. those who did not.",
      "success_criteria": "Post-call summary delivered within 5 minutes for 95% of interactions. Status page return rate above 50% within the wait period. Proposal acceptance rate at least 20% higher for guests who engaged with the tracker vs. those who did not.",
      "failure_meaning": "If summary delivery exceeds 5 minutes, the automation pipeline has a latency issue. If status page return is below 50%, the summary may not be compelling enough or the URL delivery (SMS/email) may have open-rate issues. If there is no acceptance rate difference, the tracker may be providing status without reducing anxiety -- check whether the timeline commitments (e.g., '24 hours') are being met.",
      "implementation_hint": "Analytics events: 'call_ended' (timestamp), 'summary_sent' (timestamp, channel), 'summary_opened' (timestamp), 'status_page_viewed' (timestamp, count), 'proposal_sent' (timestamp), 'proposal_accepted' (timestamp). Calculate: summary_latency = summary_sent - call_ended. Return_rate = guests with status_page_viewed > 0 / guests with summary_sent. Compare acceptance rates: cohort A (status_page_viewed > 0) vs. cohort B (status_page_viewed = 0)."
    },
    {
      "id": "tests-005",
      "type": "validation_strategy",
      "title": "Life-Context Data Capture and Usage Validation",
      "validates_element": "works-005",
      "journey_phases": ["search", "listing_evaluation", "move_in", "active_lease"],
      "problem": "If the platform does not capture life-context data (workplace, child's school, weekly pattern), it cannot provide personalized commute times or proactive matching, and guests like Taline must evaluate listings using generic property data that does not answer their actual evaluation question: 'Does this work for my daily logistics?'",
      "solution": "Measure the percentage of guests who provide at least 3 life-context data points, and validate that commute-enhanced listing pages produce higher engagement than generic pages.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 4:25-4:41",
          "type": "guest_call",
          "quote": "I don't want to stay at my mom because my job for me to commute and have to pick up my son from school far from me.",
          "insight": "Taline's evaluation criterion is commute geometry, not property features. The test measures whether the platform captures this and uses it."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 52",
          "type": "book",
          "quote": "Engaging people intentionally to learn more about their lives and spark new ideas.",
          "insight": "The d.school principle of learning about people's lives maps to capturing life-context data. The test validates the full loop: capture, use, and guest perception of value."
        }
      ],
      "priority": "medium",
      "validation_method": "a_b_test",
      "test_description": "A/B test: Group A sees listing pages with commute time badges (after providing life-context data). Group B sees standard listing pages with no commute data. Measure for both groups: (1) time spent on listing detail pages, (2) number of listings viewed per session, (3) proposal submission rate, (4) post-session survey: 'How confident are you that this listing works for your daily routine?' (1-5 scale).",
      "success_criteria": "Group A (commute-enhanced) shows at least 15% higher proposal submission rate and at least 0.8 points higher confidence score than Group B. Life-context completion rate above 40% of guests who reach listing evaluation.",
      "failure_meaning": "If proposal rates are not higher, the commute data may not be the deciding factor for most guests -- the feature may be valuable for a subset (parents with school commutes) but not universal. If completion rate is below 40%, the data collection prompt is too intrusive, too early, or asks for too many data points. Reduce to 2 required fields (workplace, weekly pattern) and make the rest optional.",
      "implementation_hint": "A/B test setup: feature flag 'commute_badges_enabled' on listing detail pages. Group A: flag on, commute badges rendered. Group B: flag off, standard layout. Analytics events: 'life_context_prompted', 'life_context_completed' (with count of fields filled), 'listing_viewed_with_commute', 'listing_viewed_without_commute', 'proposal_submitted'. Post-session survey triggered after 3rd listing view in a session."
    },
    {
      "id": "tests-006",
      "type": "validation_strategy",
      "title": "Negotiation Dignity Preservation Validation",
      "validates_element": "works-006",
      "journey_phases": ["listing_evaluation", "negotiation"],
      "problem": "If the negotiation experience feels like rejection rather than exploration, guests will either abandon at the mismatch moment or carry resentment into the booking. The platform cannot rely on guest resilience as a design input.",
      "solution": "Validate that guests who encounter a mismatch experience the bridge card as supportive rather than rejecting, and that they do not feel required to justify their personal circumstances.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:09-3:53",
          "type": "guest_call",
          "quote": "Unfortunately I won't be able to help you with that... And I just do it like Monday through Friday.",
          "insight": "The rejection-to-adaptation arc required human skill and guest resilience. The test validates that the platform achieves the same outcome without requiring either."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 43",
          "type": "book",
          "quote": "We're hard on work but soft on people, and we don't confuse kindness with weakness.",
          "insight": "The test measures whether the bridge card embodies this principle: clear about constraints, kind about alternatives."
        }
      ],
      "priority": "medium",
      "validation_method": "usability_test",
      "test_description": "Recruit 8 participants. Give each a scenario: 'You need full-time housing, 7 nights a week, near [location]. You found this listing.' Have them interact with the listing page and encounter the bridge card. After the interaction, conduct a structured interview: (1) 'Did you feel rejected at any point? When?' (2) 'Did the platform suggest an alternative that could work for you?' (3) 'Did you feel you needed to explain your personal situation to get help?' (4) 'How would you describe the tone of the experience?' Rate on a scale: adversarial (1) to supportive (5).",
      "success_criteria": "At least 6 of 8 participants rate the experience as supportive (4 or 5 on the scale). Zero participants report feeling they needed to justify their personal circumstances. At least 5 of 8 identify a viable alternative without prompting.",
      "failure_meaning": "If fewer than 6 rate supportive, the bridge card's visual balance may be wrong -- the constraint may be too prominent relative to the alternative. If any participant feels required to justify personal circumstances, there may be a form field or prompt requesting 'why' the guest needs their pattern. If fewer than 5 identify alternatives, the suggested patterns may be too abstract or the estimated cost may be missing.",
      "implementation_hint": "Usability test prototype: create a clickable prototype of a listing page where entering '7 nights' in the pattern builder triggers the bridge card. Record the interaction and the post-task interview. Score the interview responses on the 1-5 scale and tag qualitative responses for themes. Run with both desktop and mobile prototypes to capture context differences."
    },
    {
      "id": "tests-007",
      "type": "validation_strategy",
      "title": "Category Badge Visual Gateway Validation",
      "validates_element": "looks-001",
      "journey_phases": ["discovery", "search"],
      "problem": "If the category badge is not the first element in the visual scan path, guests will process listing photos, prices, or locations before understanding the product category -- repeating Taline's comprehension failure in a digital context.",
      "solution": "Validate that the category badge is the first element fixated on when guests view a listing card or listing detail page.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 0:52",
          "type": "guest_call",
          "quote": "I just wanted to know, like that, is it for a certain time?",
          "insight": "Taline's first question would be answered by a visible category badge. The test measures whether the badge occupies the primary fixation position."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 89",
          "type": "book",
          "quote": "Like so many great tales, this story starts with a miscommunication.",
          "insight": "The badge resolves the miscommunication at the first visual contact. The test validates that visual hierarchy achieves this."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Eye-tracking study with 6 participants. Show each participant 5 listing cards (with the category badge in the specified top-left position) and 5 listing cards (without the badge, current design). Measure: (1) first fixation location on badge-present cards, (2) time to first fixation on the badge, (3) whether participants can correctly identify the product category after 5-second exposure to badge-present vs. badge-absent cards.",
      "success_criteria": "The category badge is the first or second fixation point for at least 4 of 6 participants. Time to first fixation on the badge is under 1.5 seconds. Category identification accuracy is at least 80% for badge-present cards vs. baseline for badge-absent cards.",
      "failure_meaning": "If the badge is not fixated early, its visual weight is too low relative to the listing photo or price. Increase the badge size, contrast, or position. If identification accuracy is not higher with the badge, the badge content may be unclear -- test alternative label phrasings.",
      "implementation_hint": "If eye-tracking is not available, use a 5-second exposure test: show the listing card for 5 seconds, then hide it and ask the participant what type of rental it is and what they noticed first. Record the order of recalled elements. The badge should be in the first two recalled items for at least 4 of 6 participants."
    },
    {
      "id": "tests-008",
      "type": "validation_strategy",
      "title": "Interactive Calendar Comprehension and Pricing Feedback Validation",
      "validates_element": "looks-002",
      "journey_phases": ["discovery", "listing_evaluation", "proposal_creation"],
      "problem": "If the interactive stay pattern calendar does not produce comprehension of the Split Lease model faster than verbal explanation, and if the live cost feedback does not answer 'how much does it cost' in under 200ms, the component fails its core purpose.",
      "solution": "Validate that the calendar produces faster comprehension than text and that the cost feedback is perceived as instantaneous.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 1:06-1:51",
          "type": "guest_call",
          "quote": "It's a couple of times a week... repeat renters or multi local guests... part of the week each week.",
          "insight": "Bryant's 45-second verbal explanation failed. The calendar must succeed in under 10 seconds."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 32",
          "type": "book",
          "quote": "These kinds of realizations don't come from just understanding an idea -- they come through the experience of trying.",
          "insight": "Interactive manipulation produces understanding. The test validates that the calendar's interactivity achieves this."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Two-condition test with 12 participants (6 per condition). Condition A: participants read a text description of the Split Lease model (equivalent to Bryant's verbal explanation). Condition B: participants interact with the calendar component (no text explanation). After exposure, both groups answer: (1) 'How does Split Lease work?' (2) 'If you stayed Monday through Friday, approximately how much would it cost per month?' (3) 'How many nights per week can you stay?' Measure comprehension accuracy and time-to-comprehension for both groups. Additionally, for Condition B, measure perceived latency of cost updates: 'Did the price update feel instant, fast, or slow?'",
      "success_criteria": "Condition B (calendar) achieves at least 80% comprehension accuracy in under 15 seconds, compared to Condition A (text) baseline. All Condition B participants rate cost update speed as 'instant' or 'fast.' At least 5 of 6 Condition B participants can correctly state an approximate monthly cost from memory.",
      "failure_meaning": "If calendar comprehension is not higher, the visual design may be unclear -- the day blocks may not read as selectable, the active/inactive distinction may be too subtle, or the default M-F pattern may not be obvious. If cost updates feel slow, the animation timing exceeds 200ms or the counter-style transition is not implemented. If participants cannot recall the cost, the cost display is not visually prominent enough relative to the calendar.",
      "implementation_hint": "Build a standalone prototype page with the calendar component. Condition A: same page layout but with a text paragraph replacing the calendar. Use screen recording to measure time from first interaction to correct verbal response. For cost update latency: instrument the component to log time from tap event to cost DOM update. Target: under 200ms measured, under 300ms perceived."
    },
    {
      "id": "tests-009",
      "type": "validation_strategy",
      "title": "Bridge Card Emotional Tone Validation",
      "validates_element": "looks-004",
      "journey_phases": ["listing_evaluation", "negotiation"],
      "problem": "If the bridge card's visual design communicates 'error' or 'warning' rather than 'redirect with a better option,' guests will perceive the mismatch moment as their fault or as a dead end, recreating the emotional damage of Taline's rejection moment in a visual medium.",
      "solution": "Validate that the bridge card is perceived as supportive and solution-oriented, not as an error state or warning.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:09",
          "type": "guest_call",
          "quote": "Unfortunately I won't be able to help you with that.",
          "insight": "The word 'unfortunately' signals bad news. The bridge card must avoid this emotional signature in its visual language."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 43",
          "type": "book",
          "quote": "We're hard on work but soft on people.",
          "insight": "The visual balance between constraint (hard on work) and alternative (soft on people) must be perceived correctly."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Show 8 participants the bridge card in isolation (outside the listing context). Ask: (1) 'What is this telling you?' (2) 'Is this an error message, a warning, or a suggestion?' (3) 'What would you do next after seeing this?' (4) 'Rate the tone: hostile (1) to helpful (5).' Then show the bridge card within the listing flow context and repeat questions 3 and 4.",
      "success_criteria": "At least 6 of 8 identify it as a 'suggestion' (not an error or warning). At least 6 of 8 say they would interact with the alternative (tap 'Try this pattern' or equivalent). Mean tone rating of 4.0 or higher on the 1-5 scale.",
      "failure_meaning": "If participants identify it as an error, the signal-warn amber accent is too prominent or the constraint text is too large relative to the alternative. If they identify it as a warning, the alternative section needs more visual weight (larger type, more prominent accent-light background). If tone ratings are below 4.0, test with the amber accent removed entirely and the constraint rendered in ink-muted instead.",
      "implementation_hint": "Create a static image of the bridge card at both desktop and mobile sizes. Present in a survey tool (Maze, UserTesting) with the structured questions. For the contextual version, create a short clickable prototype where the participant enters '7 nights' and the bridge card appears inline. Record qualitative responses and score the 1-5 ratings."
    },
    {
      "id": "tests-010",
      "type": "validation_strategy",
      "title": "Status Tracker Anxiety Reduction Validation",
      "validates_element": "looks-005",
      "journey_phases": ["proposal_creation", "negotiation", "acceptance"],
      "problem": "If the post-interaction status artifact does not reduce the guest's anxiety about being forgotten or abandoned, the visual stepper and summary card are cosmetic rather than functional -- they look like progress tracking but do not produce the emotional effect of being held by the process.",
      "solution": "Validate that guests who use the status tracker report lower anxiety and higher confidence that their request is being handled, compared to guests who receive only an unstructured text message.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 6:13-6:20",
          "type": "guest_call",
          "quote": "Let me know if you have any questions about the space or anything else that comes up, feel free to text me.",
          "insight": "The baseline: an unstructured text channel with no status visibility. The test compares this against the structured status tracker."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 69",
          "type": "book",
          "quote": "But success is never about a single moment of insight.",
          "insight": "The stepper communicates multi-step progress. The test validates that this visual communication reduces the emotional weight of waiting."
        }
      ],
      "priority": "high",
      "validation_method": "a_b_test",
      "test_description": "A/B test during the post-call waiting period. Group A receives a structured summary (SMS/email with status page link) within 5 minutes of call end. Group B receives a standard text message ('Thanks for your interest, we will be in touch'). After 24 hours, both groups receive a 3-question survey: (1) 'How confident are you that your request is being handled?' (1-5), (2) 'How anxious are you about hearing back?' (1-5, reversed), (3) 'Would you contact another housing option while waiting?' (yes/no). Also measure: frequency of guest-initiated texts/calls during the wait period.",
      "success_criteria": "Group A: mean confidence score at least 1.0 point higher than Group B. Group A: mean anxiety score at least 1.0 point lower. Group A: 'contact another option' rate at least 20% lower. Group A: guest-initiated contact frequency at least 30% lower (indicating reduced need to chase status).",
      "failure_meaning": "If confidence and anxiety scores are not significantly different, the status tracker may provide information without providing reassurance -- check whether the timeline commitment ('within 24 hours') is visible and credible. If 'contact another option' rates are similar, the tracker is not creating enough engagement to hold attention during the wait. If guest-initiated contact is not lower, the tracker may not answer the questions guests are actually asking.",
      "implementation_hint": "A/B split at the point of summary delivery: feature flag 'structured_summary_enabled'. Group A: summary with status page URL sent via Twilio SMS within 5 minutes. Group B: standard text sent at the same time. Survey delivered via the same SMS channel at 24 hours. Track all guest-initiated messages in the interval for both groups."
    },
    {
      "id": "tests-011",
      "type": "validation_strategy",
      "title": "Category Comprehension Gate Interaction Validation",
      "validates_element": "behaves-001",
      "journey_phases": ["discovery", "search"],
      "problem": "If the category comprehension gate feels like a barrier rather than an invitation, guests will be annoyed by an extra step before seeing listings, and the gate will increase bounce rate rather than improve comprehension.",
      "solution": "Validate that the gate is perceived as helpful, completes in under 5 seconds, and does not increase bounce rate compared to a gated-free experience.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 0:52",
          "type": "guest_call",
          "quote": "I just wanted to know, like that, is it for a certain time?",
          "insight": "The gate answers exactly this question. The test validates that guests perceive it as an answer, not as an obstacle."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 80",
          "type": "book",
          "quote": "When faced with an open-ended challenge that doesn't have one fixed, right solution, we can all feel like beginners.",
          "insight": "The gate must resolve beginner anxiety in seconds, not compound it with an additional interaction requirement."
        }
      ],
      "priority": "high",
      "validation_method": "a_b_test",
      "test_description": "A/B test on the landing page. Group A: category comprehension gate appears before listings. Group B: no gate, direct access to listings with a passive category label. Measure: (1) bounce rate from the landing page, (2) time to first meaningful interaction (click on a listing, use a filter), (3) category comprehension (measured via a one-question survey after first listing view: 'This platform offers: full-time / part-time / both'), (4) gate completion time (Group A only).",
      "success_criteria": "Group A bounce rate no more than 5% higher than Group B (the gate does not significantly increase abandonment). Group A comprehension at least 30% higher than Group B. Gate completion time under 5 seconds for 90% of users. If bounce rate is more than 5% higher, the gate is doing more harm than good despite better comprehension.",
      "failure_meaning": "If bounce rate increases significantly, the gate is perceived as a barrier. Possible fixes: make the gate visually lighter (no overlay, inline instead), reduce to a single tap (remove the 'I need something different' option on first visit), or replace the gate with a more prominent passive label. If comprehension is not higher, the gate's content is unclear -- test alternative wording or visual treatments.",
      "implementation_hint": "Feature flag 'category_gate_enabled'. Group A: gate component renders on landing page, tracking gate_shown, gate_completed (which option), gate_time. Group B: no gate, passive category label. Both groups: track bounce (session < 10 seconds and no click), first_interaction_time, and comprehension_survey_response. Run for 2 weeks minimum to get statistically significant results."
    },
    {
      "id": "tests-012",
      "type": "validation_strategy",
      "title": "Stay Pattern Builder Responsiveness and Learning Validation",
      "validates_element": "behaves-002",
      "journey_phases": ["listing_evaluation", "proposal_creation"],
      "problem": "If the stay pattern builder's tap response exceeds 60ms or the cost update exceeds 200ms, the interaction will feel laggy rather than playful, breaking the tinkering quality that makes it an experiential learning tool rather than a form.",
      "solution": "Validate that the pattern builder meets its timing targets and that guests learn the pricing model through interaction.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:21-3:37",
          "type": "guest_call",
          "quote": "Five nights a week is likely something that you would be interested in... Five nights and then I can do the weekends at my mom.",
          "insight": "Comprehension came through a concrete, countable pattern. The builder must provide this concreteness with the responsiveness of a physical object."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 75",
          "type": "book",
          "quote": "None of these assignments has to be used exactly as written. Each is meant to be tinkered with, adapted, and remixed.",
          "insight": "The tinkering principle requires that the interaction feel lightweight and reversible. Latency destroys tinkerability."
        }
      ],
      "priority": "high",
      "validation_method": "automated",
      "test_description": "Automated performance test: instrument the pattern builder component to log (1) time from touchstart/click event to visual state change of the day block (target: under 60ms), (2) time from last input event to cost figure DOM update (target: under 200ms), (3) frame rate during the spring animation on day-block selection (target: 60fps). Run on representative devices: iPhone SE (low-end), iPhone 14 (mid-range), desktop Chrome. Separately, qualitative test with 6 participants: after 2 minutes of free interaction with the builder, ask 'If you add one more night, what happens to the price?' Correct answer indicates pricing model comprehension through interaction.",
      "success_criteria": "Tap-to-visual response under 60ms on all tested devices. Cost update under 200ms on all tested devices. 60fps animation on mid-range and above. At least 5 of 6 qualitative participants correctly predict the price direction when adding a night.",
      "failure_meaning": "If tap response exceeds 60ms, the component may be doing too much work on the main thread -- offload the cost calculation to a web worker. If cost update exceeds 200ms, the pricing API round-trip is too slow -- implement client-side estimation using the listing's rate range. If participants cannot predict pricing direction, the cost display may not be prominent enough or the cause-and-effect relationship between taps and cost changes may not be visually clear.",
      "implementation_hint": "Performance instrumentation: use Performance.now() around the tap handler and the cost update render. Log to analytics: component: 'pattern_builder', event: 'tap_response_ms', value: [number]. For frame rate: use requestAnimationFrame to measure frame intervals during animation. Report p50, p95, and p99 for each metric. For the qualitative test: screen-record the interaction and note the moment of comprehension (when the participant starts deliberately adding/removing nights to explore cost changes)."
    },
    {
      "id": "tests-013",
      "type": "validation_strategy",
      "title": "Mismatch Redirect Emotional Continuity Validation",
      "validates_element": "behaves-003",
      "journey_phases": ["listing_evaluation", "negotiation"],
      "problem": "If the mismatch-to-alternative redirect produces a perceptible delay between the constraint and the alternative, or if the transition feels like an interruption rather than an expansion, the bridge loses its core emotional principle: the guest must never feel rejected.",
      "solution": "Validate that the bridge appears within 400ms, feels like an expansion of content rather than an interruption, and that guests who encounter it continue interacting rather than bouncing.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:09-3:21",
          "type": "guest_call",
          "quote": "Unfortunately I won't be able to help you with that... Five nights a week is likely something that you would be interested in.",
          "insight": "The gap between rejection and alternative was ~12 seconds in the call. In the UI, it must be under 400ms."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 33",
          "type": "book",
          "quote": "The product is important, but how to get there deserves at least as much attention, if not more.",
          "insight": "The transition IS the product. The test validates that the transition process produces a positive experience."
        }
      ],
      "priority": "high",
      "validation_method": "analytics",
      "test_description": "Track all sessions where the mismatch bridge is triggered. Measure: (1) time from mismatch detection to bridge card fully rendered (target: under 400ms), (2) post-bridge interaction rate (percentage of users who interact with the bridge card after it appears), (3) bounce rate within 10 seconds of bridge appearance vs. overall listing page bounce rate, (4) 'Try this pattern' acceptance rate.",
      "success_criteria": "Bridge render time under 400ms for 95% of triggers. Post-bridge interaction rate above 60%. Bounce rate within 10 seconds of bridge appearance no more than 10% higher than overall listing bounce. 'Try this pattern' acceptance rate above 40%.",
      "failure_meaning": "If render time exceeds 400ms, the alternative pattern and cost calculation are too slow -- precompute alternatives when the listing loads, not when the mismatch is detected. If interaction rate is below 60%, the bridge card may not be visually prominent enough or its CTA may not be clear. If bounce rate spikes, the bridge may feel like an error state -- review the visual treatment (amber may be too alarming). If acceptance is below 40%, the suggested pattern may not be relevant to the guest's situation.",
      "implementation_hint": "Analytics events: 'mismatch_detected' (timestamp, guest_input, listing_id), 'bridge_rendered' (timestamp), 'bridge_interacted' (timestamp, action), 'bridge_accepted' (timestamp, accepted_pattern), 'bridge_dismissed' (timestamp). Calculate: render_time = bridge_rendered - mismatch_detected. Post-bridge bounce: session ends within 10 seconds of bridge_rendered with no bridge_interacted event. For precomputation: on listing page load, compute the top 3 viable patterns and cache them so the bridge can render from cache."
    },
    {
      "id": "tests-014",
      "type": "validation_strategy",
      "title": "Discovery-Phase Calm Emotion Validation",
      "validates_element": "feels-001",
      "journey_phases": ["discovery", "search"],
      "problem": "If the discovery experience produces excitement or curiosity instead of calm orientation, confused newcomers will process the emotional tone as noise layered on top of their existing confusion, accelerating dropout rather than preventing it.",
      "solution": "Validate that the discovery experience produces calm comprehension as the primary emotional response, not confusion, excitement, or anxiety.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 0:52",
          "type": "guest_call",
          "quote": "I just wanted to know, like that, is it for a certain time?",
          "insight": "Taline's emotional state is urgent and confused. The test validates that the redesigned discovery experience produces the opposite: calm and oriented."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 80",
          "type": "book",
          "quote": "When faced with an open-ended challenge that doesn't have one fixed, right solution, we can all feel like beginners.",
          "insight": "The test measures whether the beginner state is resolved within the first 3 seconds of visual contact."
        }
      ],
      "priority": "medium",
      "validation_method": "usability_test",
      "test_description": "Recruit 8 participants unfamiliar with Split Lease. Give them a scenario: 'You need housing near your workplace for weeknights. A friend texted you this link.' Show them the redesigned landing page for 10 seconds. Then ask: (1) 'In one word, how did that page make you feel?' (2) 'Do you know what this platform offers?' (3) 'Would you continue exploring or leave?' Record and code the one-word emotional responses. Compare against a control group shown a landing page with excitement-based copy ('Discover a new way to live!').",
      "success_criteria": "At least 5 of 8 in the redesigned group provide calm-associated words (calm, clear, simple, straightforward, easy). Zero participants report confusion-associated words (confused, lost, overwhelmed). At least 7 of 8 say they would continue exploring. The control group should show more varied emotional responses including confusion and skepticism.",
      "failure_meaning": "If calm-associated words are below 5 of 8, the landing page may still be too information-dense or the category label may compete with other visual elements. If any participant reports confusion, the label language needs simplification. If 'continue exploring' is below 7 of 8, the page may have a design element that triggers skepticism or feels untrustworthy.",
      "implementation_hint": "Create two prototype landing pages: (A) redesigned with category badge, plain-language label, static calendar visual, and warm neutral background, (B) control with excitement-based copy and brand storytelling. Use a survey tool (Maze, Lyssna) to present each version for 10 seconds, then collect responses. Code the one-word responses into categories: calm-associated, excitement-associated, confusion-associated, skepticism-associated. Report distributions."
    },
    {
      "id": "tests-015",
      "type": "validation_strategy",
      "title": "Adaptation-as-Gain Emotional Framing Validation",
      "validates_element": "feels-005",
      "journey_phases": ["negotiation", "proposal_creation"],
      "problem": "If guests who adapt their needs perceive the adapted pattern as settling or compromising, they will carry resentment into the active lease, reducing retention and satisfaction. The emotional framing must convert adaptation from loss to gain.",
      "solution": "Validate that guests who select an adapted pattern feel they found something that fits their life, not that they accepted something less than what they wanted.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, 3:37",
          "type": "guest_call",
          "quote": "Five nights and then I can do the weekends at my mom.",
          "insight": "Taline spontaneously reframed the adaptation positively. The test validates that the platform's framing produces this same reframe without requiring the guest's own emotional labor."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 75",
          "type": "book",
          "quote": "Each is meant to be tinkered with, adapted, and remixed.",
          "insight": "Adaptation should feel creative, not reductive. The test measures whether the platform's framing achieves this."
        }
      ],
      "priority": "medium",
      "validation_method": "usability_test",
      "test_description": "Recruit 6 participants. Give each the Taline scenario: 'You need full-time housing but found this part-time listing.' Walk them through the mismatch bridge and pattern adaptation flow. After selecting a M-F pattern, ask: (1) 'How do you feel about the arrangement you chose?' Open-ended. (2) 'Is this arrangement: (a) a compromise, (b) a good fit for your life, (c) better than what you originally wanted, (d) not sure?' (3) 'The price for M-F is lower than 7 nights. Does that feel like: (a) a discount because you got less, (b) savings because you only pay for what you need, (c) neither?' (4) Rate: 'I feel this arrangement was designed for someone like me' (1-5).",
      "success_criteria": "At least 4 of 6 select 'a good fit for my life' or 'better than what I originally wanted' (not 'a compromise'). At least 4 of 6 select 'savings because you only pay for what you need.' Mean rating on 'designed for someone like me' of 3.5 or higher.",
      "failure_meaning": "If 'compromise' is the dominant response, the framing copy and social proof are not strong enough. Check: (1) is the cost comparison (M-F vs. 7-night) visible? (2) is social proof ('most popular pattern') present? (3) does the copy reference what the guest gained ('weekends free') or only what the listing offers ('available M-F')? If 'discount because you got less' dominates, the cost framing positions the lower price as a reduction rather than a value -- reframe as 'you pay for exactly the nights you need.'",
      "implementation_hint": "Clickable prototype of the full flow: enter 7 nights -> bridge card appears -> tap 'Try this pattern' -> M-F pattern loads with cost and social proof -> confirmation screen. Conduct the interview immediately after the confirmation screen. Record and code responses. The prototype must include: cost comparison, 'most popular pattern' badge, and benefit framing ('weekends free')."
    },
    {
      "id": "tests-016",
      "type": "validation_strategy",
      "title": "End-to-End Guest Journey Arc Validation",
      "validates_element": "journey-level",
      "journey_phases": ["discovery", "search", "listing_evaluation", "negotiation", "proposal_creation", "acceptance"],
      "problem": "Individual elements may each pass validation while the overall journey feels fragmented, inconsistent, or emotionally incoherent. A guest who experiences calm at discovery, empowerment at evaluation, and then anxiety during the wait may perceive the platform as unstable rather than supportive.",
      "solution": "Validate the complete journey arc from discovery through proposal acceptance as a single coherent experience, measuring emotional consistency and cumulative trust.",
      "evidence": [
        {
          "source": "Taline  Bryant.txt, full transcript",
          "type": "guest_call",
          "quote": "The full journey from 'is it for a certain time?' (0:52) through 'I just really need a place' (4:14) to 'feel free to text me' (6:20).",
          "insight": "Taline's journey arc was: confusion -> urgency -> rejection -> adaptation -> hope -> anxiety. The redesigned journey must produce: calm -> confidence -> redirect -> momentum -> safety."
        },
        {
          "source": "creativeacts-dschool-exercises.txt, line 69",
          "type": "book",
          "quote": "But success is never about a single moment of insight.",
          "insight": "The journey is a sequence of moments. The test validates that the sequence produces a coherent emotional arc, not a collection of isolated interactions."
        }
      ],
      "priority": "high",
      "validation_method": "usability_test",
      "test_description": "Recruit 4 participants. Each walks through the complete prototype: (1) see the landing page (discovery), (2) view a listing card (search), (3) open a listing and encounter a mismatch (listing_evaluation), (4) interact with the bridge card and pattern builder (negotiation), (5) submit a stay pattern (proposal_creation), (6) receive a status tracker summary (post-interaction). After each phase, ask: 'In one word, how do you feel right now?' After the full journey, ask: (1) 'Did the experience feel like one continuous process or like separate disconnected steps?' (2) 'At any point did you feel lost, rejected, or abandoned?' (3) 'Would you trust this platform with your housing search?' (1-5). Map the per-phase emotions against the target arc (calm -> confidence -> redirect -> momentum -> safety).",
      "success_criteria": "At least 3 of 4 describe the experience as continuous (not disconnected). Zero participants report feeling rejected or abandoned at any phase. Mean trust rating of 4.0 or higher. Per-phase emotion words align with the target arc in at least 3 of 4 participants (calm-adjacent at discovery, confidence-adjacent at evaluation, momentum-adjacent at negotiation, safety-adjacent at proposal).",
      "failure_meaning": "If the experience feels disconnected, transitions between phases may lack visual or informational continuity -- check that the category badge, pattern builder, and price display maintain consistent visual language across phases. If any participant reports feeling rejected, the bridge card is not functioning as designed -- review its emotional tone and timing. If trust is below 4.0, there may be a credibility gap in the status tracker or pricing estimates. If the emotional arc does not track the targets, identify which phase breaks the arc and investigate that phase's elements specifically.",
      "implementation_hint": "Build a complete clickable prototype spanning all 6 phases with realistic content (actual listing data from North Bergen area, actual price ranges). Each phase should flow into the next without page reloads (single-page prototype). Record the session (screen + audio). After-session interview: 20 minutes max. Code the per-phase emotion words and map them to the target arc. Visualize as a line chart: target arc vs. actual emotional trajectory per participant."
    }
  ]
}