A NEW YORK TIMES B U S I N E S S B E S T S E L L E R "As entertaining and thought-provoking as The Tipping Point by
Malcolm Gladwell. . . . The Wisdom of Crowds ranges far and wide." --Tlte Boston Glohe
THE WISDOM OF CROWDS
JAMES SUROWIECKI
W I T H A N E W A F T E R W O R D BY T H E A U T H O R

Sociology/Economics

A BUSINESSWEEK BESTSELLER AND BEST
BOOK OF THE YEAR

AFORBES.COM BEST BOOK OF THE YEAR

"A fun, intriguing read--and a concept with enormous potential for CEOs and politicos
alike." -- N E W S W E E K
I n this fascinating book, New Yorker business columnist James Surowiecki explores a deceptively simple idea: Large groups of people are smarter than an elite few, no matter how brilliant-- better at solving problems, fostering innovation, coming to wise decisions, even predicting the future.
With boundless erudition and in delightfully clear prose, Surowiecki ranges across fields as diverse as popular culture, psychology, ant biology, behavioral economics, artificial intelligence, military history, and politics to show how this simple idea offers important lessons for how we live our lives, select our leaders, run our companies, and think about our world.
"This book is not just revolutionary but essential reading for everyone."
--THE CHRISTIAN SCIENCE MONITOR
"Provocative. . . . Musters ample proof that the payoff from heeding collective intelligence is greater than many of us imagine."
--BUSINESSWEEK
"There's no danger of dumbing down for the masses who read this singular book." --ENTERTAINMENT WEEKLY

Cover photograph Е Leo Mason/Getty Images Author photograph Е David Surowiecki Cover design by John Gail www.anchorbooks.com

U.S. $14.95 CAN. $19.95 ISBN 9 7 8 - 0 - 3 8 5 - 7 2 1 7 0 - 7

9 780385 721707

Praise for James Surowiecki's
THE WISDOM OF CROWDS

"Clearly and persuasively written." и :

r: --Newsday

"Convincingly argues that under the right circumstances, it's the crowd that's wiser than even society's smartest individuals. New Yorker business columnist Surowiecki enlivens his argument with dozens of illuminating anecdotes and case studies from business, social psychology, sports and everyday life."
--Entertainment Weekly

"Dazzling. . . . One of those books that will turn your world upside down. It's an adventure story, a manifesto, and the most brilliant book on business, society, and everyday life that I've read in years."
--Malcolm Gladwell, author of The Tipping Point

"Surowiecki's clear writing and well-chosen examples render com-

plicated mathematical and sociological theories easy to grasp. . . .

[His] accounts of how the wisdom of crowds has formed the world

we live in will thrill trivia mavens--and may make a better investor

(or football coach) out of anyone who takes its conclusions to

heart."

--Time Out New York

"This book should be in every thinking businessperson's library. Without exception."
--Po Bronson, author of What Should I Do with My Life?

"Drawing from biology, behavioral economics, and computer sci-

ence, Surowiecki offers answers to such timeless--and often

rhetorical--questions as "Why does the line you're standing in al-

ways seem to move the slowest?" and "Why is there so much

garbage on TV?" The result is a highly original set of conclusions

about how our world works."

--Seed, magazine

1 > : и , и"' - if . < . и r

"As readers of Surowiecki's writing in The New Yorker will know, he

has a rare gift for combining rigorous thought with entertaining ex-

ample. [The Wisdom of Crowds] is packed with amusing ideas that

leave the reader feeling better-educated."

--Financial Times (London)

"The book is deeply researched and well-written, and the result is

a fascinating read."

--Deseret Morning News

"Jim Surowiecki has done the near impossible. He's taken what in other hands would be a dense and difficult subject and given us a book that is engaging, surprising, and utterly persuasive. The Wisdom of Crowds will change the way you think about markets, economics, and a large swatch of everyday life."
--Joe Nocera, editorial director of Fortune magazine and author of A Piece of the Action

"Makes a compelling case."

, --The Gazette (Montreal)

"Deftly compressing a small library's worth of research into a single

slim and readable volume, 'The Financial Page' columnist at The

New Yorker makes his bid to capture the Zeitgeist as his colleague

Malcolm Gladwell did with The Tipping Point. . . . The author has

produced something surprising and new: a sociological tract as

gripping as a good novel."

--Best Life

"Surowiecki is a patient and vivid writer with a knack for telling ex-

amples."

--The Denver Post

"Most crowds of readers would agree that Jim Surowiecki is one of the most interesting journalists working today. Now he has written a book that will exceed even their expectations. Anyone open to rethinking their most basic assumptions--people who enjoyed The Tipping Point, say--will love this book."
--Michael Lewis, author of Moneyhall

"The author has a knack for translating the most algebraic of research papers into bright expository prose."
--The New York Times Book Review

"Surowiecki's is a big-idea book."

--Salon

"It has become increasingly recognized that the average opinions of groups is frequently more accurate than most individuals in the group. The author has written a most interesting survey of the many studies in this area and discussed the limits as well as the achievements of self-organization."
--Kenneth Arrow, winner of the Nobel Prize in Economics and Professor of Economics (Emeritus), Stanford University

"An illuminating book."

--Detroit Free Press

JAMES SUROWIECKI
THE WISDOM OF CROWDS
James Surowiecki is a staff writer at The New Yorker, where he writes the popular business column, "The Financial Page." His work has appeared in a wide range of publications, including The New York Times, The Wall Street Journal, Artforum, Wired, and Slate. He lives in Brooklyn, New York. For more information, visit www.wisdomofcrowds.com .

I

THE WISDOM OF CROWDS

THE WISDOM OF CROWDS
JAMES SUROWIECKI

«,....

ANCHOR BOOKS
A D i v i s i o n of R a n d o m H o u s e , New York

Inc.

FIRST ANCHOR BOOKS EDITION, AUGUST 2005
Copyright Е 2004, 2005 by James Surowiecki
All rights reserved. Published in the United States by Anchor Books, a division of Random House, Inc.,
New York, and in Canada by Random House of Canada Limited, Toronto. Originally published in hardcover in the United States in slightly different form
by Doubleday, a division of Random House, Inc., New York, in 2004.
Anchor Books and colophon are registered trademarks of Random House, Inc.
Some of the material in this book was originally published in different form in The New Yorker.
The Library of Congress has cataloged the Doubleday edition as follows: Surowiecki, James, 1967-
The wisdom of crowds : why the many are smarter than the few and how collective wisdom shapes business, economies, societies, and nations / James Surowiecki. p. cm. Includes bibliographical references. 1. Consensus (Social sciences) 2. Common good. I. Title. JC328.2.S87 2003 303.3'8--dc22 2003070095
Anchor ISBN: 0-385-72170-6
www.anchorbooks.com
Printed in the United States of America 10

To Mom and Dad

CONTENTS

Introduction

xi

PART I
1. The Wisdom of Crowds 3 2. The Difference Difference Makes: Waggle Dances, the Bay of
Pigs, and the Value of Diversity 23 3. Monkey See, Monkey Do: Imitation, Information Cascades,
and Independence 40 4. Putting the Pieces Together: The CIA, Linux, and the Art of
Decentralization 66 5. Shall We Dance?: Coordination in a Complex World 84 6. Society Does Exist: Taxes, Tipping, Television, and Trust 108

PART II 7. Traffic: What We Have Here Is a Failure to Coordinate 145 8. Science: Collaboration, Competition, and Reputation 158

9. Committees, Juries, and Teams: The Columbia Disaster and How Small Groups Can Be Made to Work 173
10. The Company: Meet the New Boss, Same as the Old Boss? 192 11. Markets: Beauty Contests, Bowling Alleys, and Stock
Prices 224 12. Democracy: Dreams of the Common Good 259

Afterword to the Anchor Books Edition 273

Acknowledgments

283

Notes 285

THE WISDOM OF CROWDS

INTRODUCTION
o
ne day in the fall of 1906, the British scientist Francis Galton left his home in the town of Plymouth and headed for a country fair. Galton was eighty-five years old and beginning to feel his age, but he was still brimming with the curiosity that had won him renown--and notoriety---for his work on statistics and the science of heredity. And on that particular day, what Galton was curious about was livestock.
Galton's destination was the annual West of England Fat Stock and Poultry Exhibition, a regional fair where the local farmers and townspeople gathered to appraise the quality of each other's cattle, sheep, chickens, horses, and pigs. Wandering through rows of stalls examining workhorses and prize hogs may seem to have been a strange way for a scientist (especially an elderly one) to spend an afternoon, but there was a certain logic to it. Galton was a man obsessed with two things: the measurement of physical and mental qualities, and breeding. And what, after all, is a livestock show but a big showcase for the effects of good and bad breeding?
Breeding mattered to Galton because he believed that only a very few people had the characteristics necessary to keep societies healthy. He had devoted much of his career to measuring those characteristics, in fact, in order to prove that the vast majority of

people did not have them. At the International Exhibition of 1884 in London, for instance, he set up an 'Anthropometric Laboratory," where he used devices of his own making to test exhibition-goers on, among other things, their "Keenness of Sight and of Hearing, Colour Sense, Judgment of Eye, [and] Reaction Time." His experiments left him with little faith in the intelligence of the average person, "the stupidity and wrong-headedness of many men and women being so great as to be scarcely credible." Only if power and control stayed in the hands of the select, well-bred few, Galton believed, could a society remain healthy and strong.
As he walked through the exhibition that day, Galton came across a weight-judging competition. A fat ox had been selected and placed on display, and members of a gathering crowd were lining up to place wagers on the weight of the ox. (Or rather, they were placing wagers on what the weight of the ox would be after it had been "slaughtered and dressed.") For sixpence, you could buy a stamped and numbered ticket, where you filled in your name, your address, and your estimate. The best guesses would receive prizes.
Eight hundred people tried their luck. They were a diverse lot. Many of them were butchers and farmers, who were presumably expert at judging the weight of livestock, but there were also quite a few people who had, as it were, no insider knowledge of cattle. "Many non-experts competed," Galton wrote later in the scientific journal Nature, "like those clerks and others who have no expert knowledge of horses, but who bet on races, guided by newspapers, friends, and their own fancies." The analogy to a democracy, in which people of radically different abilities and interests each get one vote, had suggested itself to Galton immediately. "The average competitor was probably as well fitted for making a just estimate of the dressed weight of the ox, as an average voter is of judging the merits of most political issues on which he votes," he wrote.
Galton was interested in figuring out what the "average voter" was capable of because he wanted to prove that the average voter was capable of very little. So he turned the competition into an im-

INTRODUCTION

promptu experiment. When the contest was over and the prizes

had been awarded, Galton borrowed the tickets from the organiz-

ers and ran a series of statistical tests on them. Galton arranged the

guesses (which totaled 787 in all, after he had to discard thirteen

because they were illegible) in order from highest to lowest and

graphed them to see if they would form a bell curve. Then, among

other things, he added all the contestants' estimates, and calcu-

lated the mean of the group's guesses. That number represented,

you could say, the collective wisdom of the Plymouth crowd. If the

crowd were a single person, that was how much it would have

guessed the ox weighed.

Galton undoubtedly thought that the average guess of the

group would be way off the mark. After all, mix a few very smart

people with some mediocre people and a lot of dumb people, and

it seems likely you'd end up with a dumb answer. But Galton was

wrong. The crowd had guessed that the ox, after it had been

slaughtered and dressed, would weigh 1,197 pounds. After it had

been slaughtered and dressed, the ox weighed 1,198 pounds. In

other words, the crowd's judgment was essentially perfect. Perhaps

breeding did not mean so much after all. Galton wrote later: "The

result seems more creditable to the trustworthiness of a democratic

judgment than might have been expected." That was, to say the

least, an understatement.

,и

Аb -r

i

ии.и'.и,!и и?,/(и .

II ; .,иии. ^

What Francis Galton stumbled on that day in Plymouth was the simple, but powerful, truth that is at the heart of this book: under the right circumstances, groups are remarkably intelligent, and are often smarter than the smartest people in them. Groups do not need to be dominated by exceptionally intelligent people in order to be smart. Even if most of the people within a group are not especially well-informed or rational, it can still reach a collectively wise

XIV

INTRODUCTION

decision. This is a good thing, since human beings are not perfectly

designed decision makers. Instead, we are what the economist Her-

bert Simon called "boundedly rational." We generally have less in-

formation than we'd like. We have limited foresight into the future.

Most of us lack the ability--and the desire--to make sophisticated

cost-benefit calculations. Instead of insisting on finding the best

possible decision, we will often accept one that seems good enough.

And we often let emotion affect our judgment. Yet despite all these

limitations, when our imperfect judgments are aggregated in the

right way, our collective intelligence is often excellent.

-А:.

This intelligence, or what I'll call "the wisdom of crowds," is at

work in the world in many different guises. It's the reason the Inter-

net search engine Google can scan a billion Web pages and find the

one page that has the exact piece of information you were looking

for. It's the reason it's so hard to make money betting on NFL

games, and it helps explain why, for the past fifteen years, a few

hundred amateur traders in the middle of Iowa have done a better

job of predicting election results than Gallup polls have. The wis-

dom of crowds has something to tell us about why the stock market

works (and about why, every so often, it stops working). The idea of

collective intelligence helps explain why, when you go to the con-

venience store in search of milk at two in the morning, there is a

carton of milk waiting there for you, and it even tells us something

important about why people pay their taxes and help coach Little

League. It's essential to good science. And it has the potential to

make a profound difference in the way companies do business.

In one sense, this book tries to describe the world as it is,

looking at things that at first glance may not seem similar but that

are ultimately very much alike. But this book is also about the

world as it might be. One of the striking things about the wisdom

of crowds is that even though its effects are all around us, it's easy

to miss, and, even when it's seen, it can be hard to accept. Most of

us, whether as voters or investors or consumers or managers, be-

lieve that valuable knowledge is concentrated in a very few hands

INTRODUCTION
(or, rather, in a very few heads). We assume that the key to solving problems or making good decisions is finding that one right person who will have the answer. Even when we see a large crowd of people, many of them not especially well-informed, do something amazing like, say, predict the outcomes of horse races, we are more likely to attribute that success to a few smart people in the crowd than to the crowd itself. As sociologists Jack B. Soil and Richard Larrick put it, we feel the need to "chase the expert." The argument of this book is that chasing the expert is a mistake, and a costly one at that. We should stop hunting and ask the crowd (which, of course, includes the geniuses as well as everyone else) instead. Chances are, it knows. .

=;

:

III

Charles Mackay would have scoffed at the idea that a crowd of people could know anything at all. Mackay was the Scottish journalist who, in 1841, published Extraordinary Popular Delusions and the Madness of Crowds, an endlessly entertaining chronicle of mass manias and collective follies, to which the title of my book pays homage. For Mackay, crowds were never wise. They were never even reasonable. Collective judgments were doomed to be extreme. "Men, it has been well said, think in herds," he wrote. "It will be seen that they go mad in herds, while they only recover their senses slowly, and one by one." Mackays take on collective madness is not an unusual one. In the popular imagination, groups tend to make people either dumb or crazy, or both. The speculator Bernard Baruch, for instance, famously said: "Anyone taken as an individual is tolerably sensible and reasonable--as a member of a crowd, he at once becomes a blockhead." Henry David Thoreau lamented: "The mass never comes up to the standard of its best member, but on the contrary degrades itself to a level with the lowest." Friedrich Nietzsche wrote, "Madness is the exception in indi-

XVI

INTRODUCTION

viduals but the rule in groups," while the English historian Thomas Carlyle put it succinctly: "I do not believe in the collective wisdom of individual ignorance."
Perhaps the most severe critic of the stupidity of groups was the French writer Gustave Le Bon, who in 1895 published the polemical classic The Crowd: A Study of the Popular Mind. Le Bon was appalled by the rise of democracy in the West in the nineteenth century, and dismayed by the idea that ordinary people had come to wield political and cultural power. But his disdain for groups went deeper than that. A crowd, Le Bon argued, was more than just the sum of its members. Instead, it was a kind of independent organism. It had an identity and a will of its own, and it often acted in ways that no one within the crowd intended. When the crowd did act, Le Bon argued, it invariably acted foolishly. A crowd might be brave or cowardly or cruel, but it could never be smart. As he wrote, "In crowds it is stupidity and not mother wit that is accumulated." Crowds "can never accomplish acts demanding a high degree of intelligence," and they are "always intellectually inferior to the isolated individual." Strikingly, for Le Bon, the idea of "the crowd" included not just obvious examples of collective wildness, like lynch mobs or rioters. It also included just about any kind of group that could make decisions.
So Le Bon lambasted juries, which "deliver verdicts of which each individual juror would disapprove." Parliaments, he argued, adopt laws that each of their members would normally reject. In fact, if you assembled smart people who were specialists in a host of different fields and asked them to "make decisions affecting matters of general interest," the decisions they would reach would be no better, on the whole, than those "adopted by a gathering of imbeciles."
Over the course of this book, I follow Le Bon's lead in giving the words "group" and "crowd" broad definitions, using the words to refer to everything from game-show audiences to multibillion-dollar corporations to a crowd of sports gamblers. Some of the groups in

INTRODUCTION
this book, like the management teams in Chapter 9, are tightly organized and very much aware of their identities as groups. Other crowds, like the herds of cars caught in traffic that I write about in Chapter 7, have no formal organization at all. And still others, like the stock market, exist mainly as an ever-changing collection of numbers and dollars. These groups are all different, but they have in common the ability to act collectively to make decisions and solve problems--even if the people in the groups aren't always aware that's what they're doing. And what is demonstrably true of some of these groups--namely, that they are smart and good at problem solving--is potentially true of most, if not all, of them. In that sense, Gustave Le Bon had things exactly backward. If you put together a big enough and diverse enough group of people and ask them to "make decisions affecting matters of general interest," that group's decisions will, over time, be "intellectually [superior] to the isolated individual," no matter how smart or well-informed he is.

'V;

IV

'

Judging the weight of an ox is hardly a complex task. But, as I suggested above, collective intelligence can be brought to bear on a wide variety of problems, and complexity is no bar. In this book, I concentrate on three kinds of problems. The first are what I'll call cognition problems. These are problems that have or will have definitive solutions. For example, "Who will win the Super Bowl this year?" and "How many copies of this new ink-jet printer will we sell in the next three months?" are cognition problems. So, too, is "How likely is it that this drug will be approved by the FDA?" Questions to which there may not be a single right answer, but to which some answers are certainly better than others--such as, "What would be the best place to build this new public swimming pool?"--are cognition problems, too.
The second kind of problem is what's usually called a coordi-

XVIII

INTRODUCTION

nation problem. Coordination problems require members of a

group (market, subway riders, college students looking for a party)

to figure out how to coordinate their behavior with each other,

knowing that everyone else is trying to do the same. How do buy-

ers and sellers find each other and trade at a fair price? How do

companies organize their operations? How can you drive safely in

heavy traffic? These are all problems of coordination.

The final kind of problem is a cooperation problem. As their

name suggests, cooperation problems involve the challenge of get-

ting self-interested, distrustful people to work together, even when

narrow self-interest would seem to dictate that no individual

should take part. Paying taxes, dealing with pollution, and agreeing

on definitions of what counts as reasonable pay are all examples of

cooperation problems.

A word about structure. The first half of this book is, you

might say, theory, although leavened by practical examples. There's

a chapter for each of the three problems (cognition, coordination,

and cooperation), and there are chapters covering the conditions

that are necessary for the crowd to be wise: diversity, indepen-

dence, and a particular kind of decentralization. The first half be-

gins with the wisdom of crowds, and then explores the three

conditions that make it possible, before moving on to deal with co-

ordination and cooperation.

. ' r;

The second part of the book consists of what are essentially

case studies. Each of the chapters is devoted to a different way of

organizing people toward a common (or at least loosely common)

goal, and each chapter is about the way collective intelligence ei-

ther flourishes or flounders. In the chapter about corporations, for

instance, the tension is between a system in which only a few peo-

ple exercise power and a system in which many have a voice. The

chapter about markets starts with the question of whether markets

can be collectively intelligent, and ends with a look at the dynam-

ics of a stock-market bubble.

> , ";

There are many stories in this book of groups making bad

INTRODUCTION

decisions, as well as groups making good ones. Why? Well, one

reason is that this is the way the world works. The wisdom of

crowds has a far more important and beneficial impact on our

everyday lives than we recognize, and its implications for the fu-

ture are immense. But in the present, many groups struggle to

make even mediocre decisions, while others wreak havoc with

their bad judgment. Groups work well under certain circum-

stances, and less well under others. Groups generally need rules

to maintain order and coherence, and when they're missing or

malfunctioning, the result is trouble. Groups benefit from mem-

bers talking to and learning from each other, but too much com-

munication, paradoxically, can actually make the group as a whole

less intelligent. While big groups are often good for solving cer-

tain kinds of problems, big groups can also be unmanageable and

inefficient. Conversely, small groups have the virtue of being easy

to run, but they risk having too little diversity of thought and too

much consensus. Finally, Mackay was right about the extremes of

collective behavior: there are times--think of a riot, or a stock-

market bubble--when aggregating individual decisions produces

a collective decision that is utterly irrational. The stories of these

kinds of mistakes are negative proofs of this book's argument, un-

derscoring the importance to good decision making of diversity

and independence by demonstrating what happens when they're

missing.

h'A' uv;

:

' '..',

Diversity and independence are important because the best

collective decisions are the product of disagreement and contest,

not consensus or compromise. An intelligent group, especially

when confronted with cognition problems, does not ask its mem-

bers to modify their positions in order to let the group reach a de-

cision everyone can be happy with. Instead, it figures out how to use

mechanisms--like market prices, or intelligent voting systems--

to aggregate and produce collective judgments that represent not

what any one person in the group thinks but rather, in some sense,

what they all think. Paradoxically, the best way for a group to be

XXINTRODUCTION

smart is for each person in it to think and act as independently as

possible.

......

.

ии...- 7 -V -i ' и ..

' >;ии

I began this Introduction with an example of a group solving a simple problem: figuring out the weight of an ox. I'll end it with an example of a group solving an incredibly complex problem: locating a lost submarine. The differences between the two cases are immense. But the principle in each is the same.
In May 1968, the U.S. submarine Scorpion disappeared on its way back to Newport News after a tour of duty in the North Atlantic. Although the navy knew the sub's last reported location, it had no idea what had happened to the Scorpion, and only the vaguest sense of how far it might have traveled after it had last made radio contact. As a result, the area where the navy began searching for the Scorpion was a circle twenty miles wide and many thousands of feet deep. You could not imagine a more hopeless task. The only possible solution, one might have thought, was to track down three or four top experts on submarines and ocean currents, ask them where they thought the Scorpion was, and search there. But, as Sherry Sontag and Christopher Drew recount in their book Blind Man's Bluff, a naval officer named John Craven had a different plan.
First, Craven concocted a series of scenarios--alternative explanations for what might have happened to the Scorpion. Then he assembled a team of men with a wide range of knowledge, including mathematicians, submarine specialists, and salvage men. Instead of asking them to consult with each other to come up with an answer, he asked each of them to offer his best guess about how likely each of the scenarios was. To keep things interesting, the guesses were in the form of wagers, with bottles of Chivas Regal as prizes. And so Craven's men bet on why the submarine ran into

INTRODUCTION
trouble, on its speed as it headed to the ocean bottom, on the steepness of its descent, and so forth.
Needless to say, no one of these pieces of information could tell Craven where the Scorpion was. But Craven believed that if he put all the answers together, building a composite picture of how the Scorpion died, he'd end up with a pretty good idea of where it was. And that's exactly what he did. He took all the guesses, and used a formula called Bayes's theorem to estimate the Scorpions final location. (Bayes's theorem is a way of calculating how new information about an event changes your preexisting expectations of how likely the event was.) When he was done, Craven had what was, roughly speaking, the group's collective estimate of where the submarine was.
The location that Craven came up with was not a spot that any individual member of the group had picked. In other words, not one of the members of the group had a picture in his head that matched the one Craven had constructed using the information gathered from all of them. The final estimate was a genuinely collective judgment that the group as a whole had made, as opposed to representing the individual judgment of the smartest people in it. It was also a genuinely brilliant judgment. Five months after the Scorpion disappeared, a navy ship found it. It was 220 yards from where Craven's group had said it would be.
What's astonishing about this story is that the evidence that the group was relying on in this case amounted to almost nothing. It was really just tiny scraps of data. No one knew why the submarine sank, no one had any idea how fast it was traveling or how steeply it fell to the ocean floor. And yet even though no one in the group knew any of these things, the group as a whole knew them all.

Hl
PARTI

O
1
!

THE W I S D O M OF C R O W D S

и.и!i ; -1 vj и;ии.и'ии;'и j L

.. и!iи

If, years hence, people remember anything about the TV game show Who Wants to Be a Millionaire?, they will probably remember the contestants' panicked phone calls to friends and relatives. Or they may have a faint memory of that short-lived moment when Regis Philbin became a fashion icon for his willingness to wear a dark blue tie with a dark blue shirt. What people probably won't remember is that every week Who Wants to Be a Millionaire? pitted group intelligence against individual intelligence, and that every week, group intelligence won.
Who Wants to Be a Millionaire? was a simple show in terms of structure: a contestant was asked multiple-choice questions, which got successively more difficult, and if she answered fifteen questions in a row correctly, she walked away with $ 1 million. The show's gimmick was that if a contestant got stumped by a question, she could pursue three avenues of assistance. First, she could have two of the four multiple-choice answers removed (so she'd have at least a fifty-fifty shot at the right response). Second, she could place a call to a friend or relative, a person whom, before the show, she had singled out as one of the smartest people she knew, and ask him or her for the answer. And third, she could poll the studio audience, which would immediately cast its votes by computer.

4

JAMES SUROWIECKI

Everything we think we know about intelligence suggests that the smart individual would offer the most help. And, in fact, the "experts" did okay, offering the right answer--under pressure--almost 65 percent of the time. But they paled in comparison to the audiences. Those random crowds of people with nothing better to do on a weekday afternoon than sit in a TV studio picked the right answer 91 percent of the time.
Now, the results of Who Wants to Be a Millionaire? would never stand up to scientific scrutiny. We don't know how smart the experts were, so we don't know how impressive outperforming them was. And since the experts and the audiences didn't always answer the same questions, it's possible, though not likely, 'that the audiences were asked easier questions. Even so, it's hard to resist the thought that the success of the Millionaire audience was a modern example of the same phenomenon that Francis Galton caught a glimpse of a century ago.
As it happens, the possibilities of group intelligence, at least when it came to judging questions of fact, were demonstrated by a host of experiments conducted by American sociologists and psychologists between 1920 and the mid-1950s, the heyday of research into group dynamics. Although in general, as we'll see, the bigger the crowd the better, the groups in most of these early experiments--which for some reason remained relatively unknown outside of academia--were relatively small. Yet they nonetheless performed very well. The Columbia sociologist Hazel Knight kicked things off with a series of studies in the early 1920s, the first of which had the virtue of simplicity. In that study Knight asked the students in her class to estimate the room's temperature, and then took a simple average of the estimates. The group guessed 72.4 degrees, while the actual temperature was 72 degrees. This was not, to be sure, the most auspicious beginning, since classroom temperatures are so stable that it's hard to imagine a class's estimate being too far off base. But in the years that followed, far more convincing evidence emerged, as students and soldiers across America

THE WISDOM OF CROWDS
were subjected to a barrage of puzzles, intelligence tests, and word games. The sociologist Kate H. Gordon asked two hundred students to rank items by weight, and found that the group's "estimate" was 94 percent accurate, which was better than all but five of the individual guesses. In another experiment students were asked to look at ten piles of buckshot--each a slightly different size than the rest--that had been glued to a piece of white cardboard, and rank them by size. This time, the group's guess was 94.5 percent accurate. A classic demonstration of group intelligence is the jelly-beans-in-the-jar experiment, in which invariably the group's estimate is superior to the vast majority of the individual guesses. When finance professor Jack Treynor ran the experiment in his class with ajar that held 850 beans, the group estimate was 871. Only one of the fifty-six people in the class made a better guess.
There are two lessons to draw from these experiments. First, in most of them the members of the group were not talking to each other or working on a problem together. They were making individual guesses, which were aggregated and then averaged. This is exactly what Galton did, and it is likely to produce excellent results. (In a later chapter, we'll see how having members interact changes things, sometimes for the better, sometimes for the worse.) Second, the group's guess will not be better than that of every single person in the group each time. In many (perhaps most) cases, there will be a few people who do better than the group. This is, in some sense, a good thing, since especially in situations where there is an incentive for doing well (like, say, the stock market) it gives people reason to keep participating. But there is no evidence in these studies that certain people consistently outperform the group. In other words, if you run ten different jelly-bean-counting experiments, it's likely that each time one or two students will outperform the group. But they will not be the same students each time. Over the ten experiments, the group's performance will almost certainly be the best possible. The simplest way to get reliably good answers is just to ask the group each time.

6

JAMES SUROWIECKI

A similarly blunt approach also seems to work when wrestling with other kinds of problems. The theoretical physicist Norman L. Johnson has demonstrated this using computer simulations of individual "agents" making their way through a maze. Johnson, who does his work at the Los Alamos National Laboratory, was interested in understanding how groups might be able to solve problems that individuals on their own found difficult. So he built a maze--one that could be navigated via many different paths, some shorter, and some longer--and sent a group of agents into the maze one by one. The first time through, they just wandered around, the way you would if you were looking for a particular cafe in a city where you'd never been before. Whenever they came to a turning point--what Johnson called a "node"--they would randomly choose to go right or left. Therefore some people found their way, by chance, to the exit quickly, others more slowly. Then Johnson sent the agents back into the maze, but this time he allowed them to use the information they'd learned on their first trip, as if they'd dropped bread crumbs behind them the first time around. Johnson wanted to know how well his agents would use their new information. Predictably enough, they used it well, and were much smarter the second time through. The average agent took 34.3 steps to find the exit the first time, and just 12.8 steps to find it the second.
The key to the experiment, though, was this: Johnson took the results of all the trips through the maze and used them to calculate what he called the group's "collective solution." He figured out what a majority of the group did at each node of the maze, and then plotted a path through the maze based on the majority's decisions. (If more people turned left than right at a given node, that was the direction he assumed the group took. Tie votes were broken randomly.) The group's path was just nine steps long, which was not only shorter than the path of the average individual (12.8 steps), but as short as the path that even the smartest individual had been able to come up with. It was also as good an answer as you could find. There was no way to get through the maze in fewer

THE WISDOM OF C R O W D S
than nine steps, so the group had discovered the optimal solution. The obvious question that follows, though, is: The judgment of crowds may be good in laboratory settings and classrooms, but what happens in the real world?

' <>:ии

и

II

и,, :

At 11:38 AM on January 28, 1986, the space shuttle Challenger

lifted off from its launch pad at Cape Canaveral. Seventy-four sec-

onds later, it was ten miles high and rising. Then it blew up. The

launch was televised, so news of the accident spread quickly. Eight

minutes after the explosion, the first story hit the Dow Jones News

Wire.

иФи ии? ╗ Mi'.iiv

. !иии,,и!.!

The stock market did not pause to mourn. Within minutes,

investors started dumping the stocks of the four major contractors

who had participated in the Challenger launch: Rockwell Interna-

tional, which built the shuttle and its main engines; Lockheed,

which managed ground support; Martin Marietta, which manufac-

tured the ship's external fuel tank; and Morton Thiokol, which built

the solid-fuel booster rocket. Twenty-one minutes after the explo-

sion, Lockheed's stock was down 5 percent, Martin Marietta's was

down 3 percent, and Rockwell was down 6 percent.

Morton Thiokol's stock was hit hardest of all. As the finance

professors Michael T. Maloney and J. Harold Mulherin report in

their fascinating study of the market's reaction to the Challenger

disaster, so many investors were trying to sell Thiokol stock and so

few people were interested in buying it that a trading halt was

called almost immediately. When the stock started trading again,

almost an hour after the explosion, it was down 6 percent. By the

end of the day, its decline had almost doubled, so that at market

close, Thiokol's stock was down nearly 12 percent. By contrast, the

stocks of the three other firms started to creep back up, and by the

end of the day their value had fallen only around 3 percent.

JAMES SUROWIECKI

What this means is that the stock market had, almost imme-

diately, labeled Morton Thiokol as the company that was responsi-

ble for the Challenger disaster. The stock market is, at least in

theory, a machine for calculating the present value of all the "free

cash flow" a company will earn in the future. (Free cash flow is the

money that's left over after a company has paid all its bills and its

taxes, has accounted for depreciation, and has invested in the busi-

ness. It's the money you'd get to take home and put in the bank if

you were the sole owner of the company.) The steep decline in

Thiokol's stock price--especially compared with the slight declines

in the stock prices of its competitors--was an unmistakable sign

that investors believed that Thiokol was responsible, and that the

consequences for its bottom line would be severe.

As Maloney and Mulherin point out, though, on the day of

the disaster there were no public comments singling out Thiokol as

the guilty party. While the New York Times article on the disaster

that appeared the next morning did mention two rumors that had

been making the rounds, neither of the rumors implicated Thiokol,

and the Times declared, "There are no clues to the cause of the ac-

cident."

Regardless, the market was right. Six months after the explo-

sion, the Presidential Commission on the Challenger revealed that

the O-ring seals on the booster rockets made by Thiokol--seals

that were supposed to prevent hot exhaust gases from escaping--

became less resilient in cold weather, creating gaps that allowed

the gases to leak out. (The physicist Richard Feynman famously

demonstrated this at a congressional hearing by dropping an O-ring

in a glass of ice water. When he pulled it out, the drop in temper-

ature had made it brittle.) In the case of the Challenger, the hot

gases had escaped and burned into the main fuel tank, causing the

cataclysmic explosion. Thiokol was held liable for the accident.

The other companies were exonerated. v

и>

In other words, within a half hour of the shuttle blowing up,

the stock market knew what company was responsible. To be sure,

THE WISDOM OF CROWDS
this was a single event, and it's possible that the market's singling out of Thiokol was just luck. Or perhaps the company's business seemed especially susceptible to a downturn in the space program. Possibly the trading halt had sent a signal to investors to be wary. These all are important cautions, but there is still something eerie about what the market did. That's especially true because in this case the stock market was working as a pure weighing machine, undistorted by the factors--media speculation, momentum trading, and Wall Street hype--that make it a peculiarly erratic mechanism for aggregating the collective wisdom of investors. That day, it was just buyers and sellers trying to figure out what happened and getting it right.
How did they get it right? That's the question that Maloney and Mulherin found so vexing. First, they looked at the records of insider trades to see if Thiokol executives, who might have known that their company was responsible, had dumped stock on January 28. They hadn't. Nor had executives at Thiokol's competitors, who might have heard about the O-rings and sold Thiokol's stock short. There was no evidence that anyone had dumped Thiokol stock while buying the stocks of the other three contractors (which would have been the logical trade for someone with inside information). Savvy insiders alone did not cause that first-day drop in Thiokol's price. It was all those investors--most of them relatively uninformed--who simply refused to buy the stock.
But why did they not want Thiokol's stock? Maloney and Mulherin were finally unable to come up with a convincing answer to that question. In the end, they assumed that insider information was responsible for the fall in Thiokol's price, but they could not explain how. Tellingly, they quoted the Cornell economist Maureen O'Hara, who has said, "While markets appear to work in practice, we are not sure how they work in theory."
Maybe. But it depends on what you mean by "theory." If you strip the story down to its basics, after all, what happened that January day was this: a large group of individuals (the actual and po-

JAMES SUROWIECKI
tential shareholders of Thiokol's stock, and the stocks of its competitors) was asked a question--"How much less are these four companies worth now that the Challenger has exploded?"--that had an objectively correct answer. Those are conditions under which a crowd's average estimate--which is, dollar weighted, what a stock price is--is likely to be accurate. Perhaps someone did, in fact, have inside knowledge of what had happened to the O-rings. But even if no one did, it's plausible that once you aggregated all the bits of information about the explosion that all the traders in the market had in their heads that day, it added up to something close to the truth. As was true of those who helped John Craven find the Scorpion, even if none of the traders was sure that Thiokol was responsible, collectively they were certain it was.
The market was smart that day because it satisfied the four conditions that characterize wise crowds: diversity of opinion (each person should have some private information, even if it's just an eccentric interpretation of the known facts), independence (people's opinions are not determined by the opinions of those around them), decentralization (people are able to specialize and draw on local knowledge), and aggregation (some mechanism exists for turning private judgments into a collective decision). If a group satisfies those conditions, its judgment is likely to be accurate. Why? At heart, the answer rests on a mathematical truism. If you ask a large enough group of diverse, independent people to make a prediction or estimate a probability, and then average those estimates, the errors each of them makes in coming up with an answer will cancel themselves out. Each person's guess, you might say, has two components: information and error. Subtract the error, and you're left with the information.
Now, even with the errors canceled out, it's possible that a group's judgment will be bad. For the group to be smart, there has to be at least some information in the "information" part of the "information minus error" equation. (If you'd asked a large group of

THE WISDOM OF C R O W D S

II

children to buy and sell stocks in the wake of the Challenger disaster, it's unlikely they would have picked out Thiokol as the culprit.) What is striking, though--and what makes a phrase like "the wisdom of crowds" meaningful--is just how much information a group's collective verdict so often contains. In cases like Francis Galton's experiment or the Challenger explosion, the crowd is holding a nearly complete picture of the world in its collective brain.
Perhaps this isn't surprising. After all, we are the products of evolution, and presumably we have been equipped to make sense of the world around us. But who knew that, given the chance, we can collectively make so much sense of the world. After all, think about what happens if you ask a hundred people to run a 100-meter race, and then average their times. The average time will not be better than the time of the fastest runners. It will be worse. It will be a mediocre time. But ask a hundred people to answer a question or solve a problem, and the average answer will often be at least as good as the answer of the smartest member. With most things, the average is mediocrity. With decision making, it's often excellence. You could say it's as if we've been programmed to be collectively smart. и

и-

.. и и> III

;

,Ф.<

v-. v

Truly successful decision making, of course, demands more than just a picture of the world as it is. It demands in addition a picture of the world as it will (or at least as it may) be. Any decision-making mechanism therefore has to be good under conditions of uncertainty. And what's more uncertain than the future? Group intelligence may be good at telling how many jelly beans are in a jar or remembering the year Nirvana released Nevermind. But how does it perform under conditions of true uncertainty, when the right answer is seemingly unknowable--because it hasn't happened yet?
Robert Walker's entire career depends on the answer to that

JAMES SUROWIECKI
question. Walker is the sports book director at the Mirage Hotel and Casino in Las Vegas, which means that every week he fields thousands of bets in sports ranging from pro football to Ivy League basketball. For all those games, Walker has to offer a line (or point spread), which lets bettors know which team is favored to win and by how many points. The way the line works is simple. Say the Giants are favored this week by three and a half points over the Rams. If you bet on the Giants, they have to win by four points or more for you to win the bet. Conversely, if you bet on the Rams, they have to lose by three points or less (or win), for you to walk away with the casino's money. In other sports, bets are framed in terms of odds: if you bet on the favorite, you might have to put down $150 to get $100 back, while if you bet on the underdog, you'd have to lay down $75 to win $100. и ' . w - .,ии; , i, '
As a bookmaker, Walker's job is not to try to pick what team will win. He leaves that to the gamblers, at least in theory. Instead, his job is to make sure that the gamblers bet roughly the same amount of money on one team as on the other. If he does that, then he knows that he will win half the bets he's taken in and lose the other half. Why would Walker be satisfied with just breaking even? Because bookies make more money on every bet they win than they lose on every bet they get wrong. If you place a point-spread bet with a bookie, you have to put up $11 to win $10. Imagine there are only two bettors, one who bets on the favorite and the other who bets on the underdog. Walker takes in $22 ($11 from each of them). He pays out $21 to the winner. The $1 he keeps is his profit. That slim advantage, which is known as the vigorish, or the vig, is what pays the bookie's bills. And the bookie keeps that advantage only when he avoids having too much money riding on one side of a bet.
To keep that from happening, Walker needs to massage the point spread so that bets keep coming in for both teams. "The line we want is the line that'll split the public, because that's when you

THE WISDOM OF C R O W D S

start earning that vig," he said. In the week before the 2001 Super

Bowl, for instance, the Mirage's opening line had the Baltimore

Ravens favored by two and a half points. But soon after the line was

posted, the Mirage booked a couple of early $3,000 bets on Balti-

more. That's not much money, but it was enough to convince

Walker to raise the point spread to three. If everyone wanted to bet

on Baltimore, chances were the line wasn't right. So the line

moved. The opening line is set by the bookmaker, but it shifts

largely in response to what bettors do--much as stock prices rise

and fall with investor demand.

-;

c

In theory, you could set the opening line wherever, and sim-

ply allow it to adjust from there automatically, so that the point

spread would rise or fall anytime there was a significant imbalance

between the amounts wagered on each side. The Mirage would

have no problem doing this; its computerized database tracks the

bets as they come in. But bookies place a premium on making the

opening line as accurate as possible, because if they set it badly

they're going to get stuck taking a lot of bad bets. Once a line

opens, though, it's out of the bookie's hands, and a game's point

spread ends up representing bettors' collective judgment of what

the final outcome of that game will be. As Bob Martin, who was es-

sentially the country's oddsmaker in the 1970s, said, "Once you put

a number on the board, it becomes public property."

The public, it turns out, is pretty smart. It does not have a

crystal ball: point spreads only weakly predict the final scores of

most NFL games, for instance. But it is very hard for even well-

informed gamblers to beat the final spread consistently. In about

half the games, favorites cover the spread, while in the other half

underdogs beat the spread. This is exactly what a bookie wants to

have happen. And there are no obvious mistakes in the market's

judgment--like, say, home teams winning more than the crowd

predicts they will, or road underdogs being consistently under-

valued. Flaws in the crowd's judgment are found occasionally, but

JAMES SUROWIECKI
when they are they're typically like the one documented in a recent paper that found that in weeks fifteen, sixteen, and seventeen of the NFL season, home underdogs have historically been a good bet. So you have to search hard to outperform the betting crowd. Roughly three-quarters of the time, the Mirage's final line will be the most reliable forecast of the outcomes of NFL games that you can find.
The same is true in many other sports. Because sports betting is a kind of ready-made laboratory to study predictions and their outcomes, a host of academics have perused gambling markets to see how efficient--that is, how good at capturing all the available information--they are. The results of their studies are consistent: in general, in most major sports the market is relatively efficient. In some cases, the crowd's performance is especially good: in horse racing, for instance, the final odds reliably predict the race's order of finish (that is, the favorite wins most often, the horse with the second-lowest odds is the second-most-often winner, and so on) and also provide, in economist Raymond D. Sauer's words, "reasonably good estimates of the probability of winning." In other words, a three-to-one horse will win roughly a quarter of the time. There are exceptions: odds are less accurate in those sports and games where the betting market is smaller and less liquid (meaning that the odds can change dramatically thanks to only a few bets), like hockey or golf or small-college basketball games. These are often the sports where professional gamblers can make real money, which makes sense given that we know the bigger the group, the more accurate it becomes. And there are also some interesting quirks: in horse racing, for instance, people tend to bet on long shots slightly more often than they should and bet on favorites slightly less often than they should. (This seems to be a case of risk-seeking behavior: bettors, especially bettors who have been losing, would rather take a flyer on a long shot that offers the possibility of big returns than grind it out by betting on short-odds fa-

THE WISDOM OF CROWDS

vorites.) But on the whole, if bettors aren't collectively foreseeing

the future, they're doing the next best thing.

┐v и';};ии!

Recently I decided I needed--this minute!--the exact text of Bill Murray's Caddyshack riff about toting the Dalai Lama's golf bag. The punch line of the riff is "So I got that going for me, which is nice" and the Dalai Lama, in Murray's telling, likes to say "Gunga galunga." So I went to Google, the Internet search engine, typed in "going for me" and "gunga," and hit the search button. A list of 695 Web pages came back. First on the list was an article from GolfOnline, which included the second half of the riff. That was okay, but third on the list was a Web site for something called the Penn State Soccer Club. The goalie, a guy named David Feist, had posted the entire monologue. The search took 0.18 seconds.
Then I needed to check out the Mulherin paper on the Challenger that I discuss above. I couldn't remember the author's name, so I typed in " 'stock market' challenger reaction": 2,370 pages came back. The first one was an article by Slates Daniel Gross about the Mulherin paper. The third was Mulherin's own Web site, with a link to his paper. That search--which, remember, did not include Mulherin's name--took 0.10 seconds. A few minutes later, my search for the lyrics to a Ramones song about Ronald Reagan visiting the Bitburg cemetery took 0.23 seconds, and the first item on the list had what I needed.
If you use the Internet regularly, these examples of Google's performance will not surprise you. This is what we have come to expect from Google: instantaneous responses with the exact page we need up high in the rankings. But if possible, it's worth letting yourself be a little amazed at what happened during those routine searches. Each time, Google surveyed billions of Web pages and

JAMES SUROWIECKI
picked exactly the pages that I would find most useful. The cumulative time for all the searches: about a minute and a half.
Google started in 1998, at a time when Yahoo! seemed to have a stranglehold on the search business--and if Yahoo! stumbled, then AltaVista or Lycos looked certain to be the last man standing. But within a couple of years, Google had become the default search engine for anyone who used the Internet regularly, simply because it was able to do a better job of finding the right page quickly. And the way it does that--and does it while surveying three billion Web pages--is built on the wisdom of crowds.
Google keeps the details of its technology to itself, but the core of the Google system is the PageRank algorithm, which was first defined by the company's founders, Sergey Brin and Lawrence Page, in a now-legendary 1998 paper called "The Anatomy of a Large-Scale Hypertextual Web Search Engine." PageRank is an algorithm--a calculating method--that attempts to let all the Web pages on the Internet decide which pages are most relevant to a particular search. Here's how Google puts it:
PageRank capitalizes on the uniquely democratic characteristic of the web by using its vast link structure as an organizational tool. In essence, Google interprets a link from page A to page B as a vote, by page A, for page B. Google assesses a page's importance by the votes it receives. But Google looks at more than sheer volume of votes, or links; it also analyzes the page that casts the vote. Votes cast by pages that are themselves "important" weigh more heavily and help to make other pages "important." :: f -oy
In that 0.12 seconds, what Google is doing is asking the entire Web to decide which page contains the most useful information, and the page that gets the most votes goes first on the list. And that page, or the one immediately beneath it, more often than not is in fact the one with the most useful information.

THE WISDOM OF CROWDS
Now, Google is a republic, not a perfect democracy. As the description says, the more people that have linked to a page, the more influence that page has on the final decision. The final vote is a "weighted average"--just as a stock price or an NFL point spread is--rather than a simple average like the ox-weighers' estimate. Nonetheless, the big sites that have more influence over the crowd's final verdict have that influence only because of all the votes that smaller sites have given them. If the smaller sites were giving the wrong sites too much influence, Google's search results would not be accurate. In the end, the crowd still rules. To be smart at the top, the system has to be smart all the way through.
If allowing people to bet on sporting events effectively creates a kind of machine that's good at predicting the outcome of those events, an obvious question follows: Wouldn't people betting on other kinds of events be equally good, as a group, at predicting them? Why confine ourselves to forecasting the results of basketball games if we could also come up with accurate predictions of, say, presidential elections?
Of course, we already have a well-established way of predicting presidential elections: the poll. If you want to know how people are going to vote, you just ask them. Polling is, relatively speaking, accurate. It has a solid methodology behind it, and is statistically rigorous. But there's reason to wonder if a market such as the betting market--one that allowed the people participating in it to rely on many different kinds of information, including but not limited to polls-- might at the very least offer a competitive alternative to Gallup. That's why the Iowa Electronic Markets (IEM) project was created.
Founded in 1988 and run by the College of Business at the University of Iowa, the IEM features a host of markets designed to predict the outcomes of elections--presidential, congressional, gu-

JAMES SUROWIECKI

bernatorial, and foreign. Open to anyone who wants to participate,

the IEM allows people to buy and sell futures "contracts" based on

how they think a given candidate will do in an upcoming election.

While the IEM offers many different types of contracts, two are most

common. One is designed to predict the winner of an election. In the

case of the California recall in 2003, for instance, you could have

bought an "Arnold Schwarzenegger to win" contract, which would

have paid you $ 1 when Schwarzenegger won. Had he lost, you would

have gotten nothing. The price you pay for this kind of contract re-

flects the market's judgment of a candidate's chances of victory. If a

candidate's contract costs 50 cents, it means, roughly speaking, that

the market thinks he has a 50 percent chance of winning. If it costs

80 cents, he has an 80 percent chance of winning, and so on.

The other major kind of IEM contract is set up to predict

what percentage of the final popular vote a candidate will get. In

this case, the payoffs are determined by the vote percentage: if

you'd bought a George W. Bush contract in 2004, you would have

received 51 cents (he got 51 percent of the vote) when the election

was over. ии^ииr.>

А, f А.- и -

If the IEM's predictions are accurate, the prices of these dif-

ferent contracts will be close to their true values. In the market to

predict election winners, the favorite should win more often, and

bigger favorites should win by bigger margins. Similarly, in the vote-

share market, if a candidate ends up getting 49 percent of the vote

in an election, then the price of his contract in the run-up to elec-

tion day should be close to 49 cents.

So how has the IEM done? Well, a study of the IEM's per-

formance in forty-nine different elections between 1988 and 2000

found that the election-eve prices in the IEM were, on average, off

by just 1.37 percent in presidential elections, 3.43 percent in other

U.S. elections, and 2.12 percent in foreign elections. (Those num-

bers are in absolute terms, meaning that the market would have

been off by 1.37 percent if, say, it had predicted that A1 Gore would

get 48.63 percent of the vote when in reality he got 50 percent.)

THE WISDOM OF CROWDS
The IEM has generally outperformed the major national polls, and has been more accurate than those polls even months in advance of the actual election. Over the course of the presidential elections between 1988 and 2000, for instance, 596 different polls were released. Three-fourths of the time, the IEM's market price on the day each of those polls was released was more accurate. Polls tend to be very volatile, with vote shares swinging wildly up and down. But the IEM forecasts, though ever-changing, are considerably less volatile, and tend to change dramatically only in response to new information. That makes them more reliable as forecasts.
What's especially interesting about this is that the IEM isn't very big--there have never been more than a few thousand traders in the market--and it doesn't, in any way, reflect the makeup of the electorate as a whole. The vast majority of traders are men, and a disproportionate--though shrinking--number of them are from Iowa. So the people in the market aren't predicting their own behavior. But their predictions of what the voters of the country will do are better than the predictions you get when you ask the voters themselves what they're going to do. And while the IEM traders undoubtedly get information from the polls, the superior accuracy of their collective forecasts suggests that the traders are also adding information to what's in the polls.
The IEM's success has helped inspire other similar markets, including the Hollywood Stock Exchange (HSX), which allows people to wager on box-office returns, opening-weekend performance, and the Oscars. The HSX enjoyed its most notable success in March of 2000. That was when a team of twelve reporters from The Wall Street Journal assiduously canvassed members of the Academy of Motion Pictures Arts and Sciences in order to find out how they had voted. The Academy was not happy about this. The organization's president publicly attacked the Journal for trying to "scoop us before Oscar night," and the Academy urged members not to talk to reporters. But with the Journal promising anonymity, more than a few people--356, or about 6 percent of all members--

